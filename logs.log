2024-07-04 11:39:08,639:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 11:39:08,639:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 11:39:08,639:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 11:39:08,639:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 12:48:50,402:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 12:48:50,404:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 12:48:50,404:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 12:48:50,404:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 12:52:13,112:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x0000020D06444140, file "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 164>')
  warnings.warn(

2024-07-04 12:52:50,013:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x0000020D06444140, file "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 164>')
  warnings.warn(

2024-07-04 12:53:14,288:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x0000020D06444140, file "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 164>')
  warnings.warn(

2024-07-04 12:54:21,540:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x0000020D06444140, file "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 164>')
  warnings.warn(

2024-07-04 13:07:43,204:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'France'')
  warnings.warn(

2024-07-04 13:07:52,168:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'France'')
  warnings.warn(

2024-07-04 13:08:23,048:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 13:08:23,049:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 13:08:23,049:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 13:08:23,050:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 13:09:40,125:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'France'')
  warnings.warn(

2024-07-04 13:10:26,273:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'France'')
  warnings.warn(

2024-07-04 13:10:30,986:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'France'')
  warnings.warn(

2024-07-04 13:11:20,284:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'France'')
  warnings.warn(

2024-07-04 13:11:37,352:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:11:37,352:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:11:37,469:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:11:37,469:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:11:37,582:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:11:37,583:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:11:37,683:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:11:37,683:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:11:37,795:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:11:37,797:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:11:37,883:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:11:37,883:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:11:37,999:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:11:37,999:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:11:39,912:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:11:39,912:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:11:40,028:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:11:40,028:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:12:09,170:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:12:25,799:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 13:12:25,832:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 13:12:25,844:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 13:12:25,898:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:12:25,898:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:12:25,901:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:12:25,903:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:12:25,903:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:12:25,903:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:12:25,928:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 13:12:25,928:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:12:25,928:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:12:25,928:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:12:25,934:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:12:25,934:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:12:25,934:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:12:25,934:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:12:25,934:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:12:25,934:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:12:25,945:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:12:25,945:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:12:25,945:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:12:25,945:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:12:25,949:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 13:12:25,958:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 13:12:25,971:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:12:25,978:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:12:26,089:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 13:12:26,162:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:12:26,162:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:12:26,162:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:12:26,172:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:12:26,172:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:12:26,172:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:12:26,186:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 13:12:26,201:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 13:12:26,204:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:12:26,272:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:12:26,272:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:12:26,273:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:12:26,278:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:12:26,278:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:12:26,278:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:12:26,290:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 13:12:26,303:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:12:26,538:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 13:12:26,601:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:12:26,602:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:12:26,602:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:12:26,605:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:12:26,605:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:12:26,606:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:12:26,611:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 13:12:26,613:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:12:28,009:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:12:28,033:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:12:28,062:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:12:28,108:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:12:28,345:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:12:28,360:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:12:28,483:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:12:28,600:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:12:29,045:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:12:29,063:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:12:50,801:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:12:50,825:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:12:50,856:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:12:50,988:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:12:51,116:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:12:51,130:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:12:51,239:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:12:51,312:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:12:51,751:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:12:51,758:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:12:51,959:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-07-04 13:12:52,197:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:14:05,059:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:14:05,059:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:14:05,189:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:14:05,364:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:14:05,690:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:14:05,761:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:14:06,078:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:14:06,189:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:14:06,604:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:14:06,645:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:14:07,756:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:14:08,381:INFO:Soft dependency imported: shap: 0.45.1
2024-07-04 13:15:13,130:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'France'')
  warnings.warn(

2024-07-04 13:16:20,279:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'France'')
  warnings.warn(

2024-07-04 13:22:07,332:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 13:22:07,332:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 13:22:07,332:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 13:22:07,332:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 13:22:25,444:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'France'')
  warnings.warn(

2024-07-04 13:23:23,276:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'France'')
  warnings.warn(

2024-07-04 13:23:47,143:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'France'')
  warnings.warn(

2024-07-04 13:24:05,831:INFO:PyCaret ClassificationExperiment
2024-07-04 13:24:05,833:INFO:Logging name: clf-default-name
2024-07-04 13:24:05,833:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-04 13:24:05,833:INFO:version 3.3.2
2024-07-04 13:24:05,834:INFO:Initializing setup()
2024-07-04 13:24:05,834:INFO:self.USI: e57f
2024-07-04 13:24:05,834:INFO:self._variable_keys: {'y_test', 'fold_generator', 'logging_param', 'fold_groups_param', 'fold_shuffle_param', 'idx', 'data', 'html_param', 'y_train', 'fix_imbalance', '_available_plots', 'n_jobs_param', 'log_plots_param', 'USI', 'exp_id', 'memory', 'X', 'y', 'is_multiclass', 'target_param', 'X_train', 'exp_name_log', '_ml_usecase', 'seed', 'gpu_n_jobs_param', 'pipeline', 'X_test', 'gpu_param'}
2024-07-04 13:24:05,834:INFO:Checking environment
2024-07-04 13:24:05,835:INFO:python_version: 3.11.3
2024-07-04 13:24:05,835:INFO:python_build: ('tags/v3.11.3:f3909b8', 'Apr  4 2023 23:49:59')
2024-07-04 13:24:05,835:INFO:machine: AMD64
2024-07-04 13:24:05,846:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-04 13:24:05,852:INFO:Memory: svmem(total=8179539968, available=1496952832, percent=81.7, used=6682587136, free=1496952832)
2024-07-04 13:24:05,852:INFO:Physical Core: 4
2024-07-04 13:24:05,852:INFO:Logical Core: 8
2024-07-04 13:24:05,852:INFO:Checking libraries
2024-07-04 13:24:05,852:INFO:System:
2024-07-04 13:24:05,852:INFO:    python: 3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]
2024-07-04 13:24:05,852:INFO:executable: C:\Program Files\Python311\python.exe
2024-07-04 13:24:05,852:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-04 13:24:05,852:INFO:PyCaret required dependencies:
2024-07-04 13:24:06,045:INFO:                 pip: 23.1.2
2024-07-04 13:24:06,045:INFO:          setuptools: 67.8.0
2024-07-04 13:24:06,045:INFO:             pycaret: 3.3.2
2024-07-04 13:24:06,045:INFO:             IPython: 8.14.0
2024-07-04 13:24:06,045:INFO:          ipywidgets: 8.0.6
2024-07-04 13:24:06,045:INFO:                tqdm: 4.65.0
2024-07-04 13:24:06,045:INFO:               numpy: 1.24.3
2024-07-04 13:24:06,045:INFO:              pandas: 2.1.4
2024-07-04 13:24:06,045:INFO:              jinja2: 3.1.2
2024-07-04 13:24:06,045:INFO:               scipy: 1.10.1
2024-07-04 13:24:06,045:INFO:              joblib: 1.3.2
2024-07-04 13:24:06,045:INFO:             sklearn: 1.4.2
2024-07-04 13:24:06,045:INFO:                pyod: 2.0.1
2024-07-04 13:24:06,046:INFO:            imblearn: 0.12.3
2024-07-04 13:24:06,046:INFO:   category_encoders: 2.6.3
2024-07-04 13:24:06,046:INFO:            lightgbm: 4.4.0
2024-07-04 13:24:06,046:INFO:               numba: 0.57.1
2024-07-04 13:24:06,046:INFO:            requests: 2.31.0
2024-07-04 13:24:06,046:INFO:          matplotlib: 3.7.5
2024-07-04 13:24:06,046:INFO:          scikitplot: 0.3.7
2024-07-04 13:24:06,046:INFO:         yellowbrick: 1.5
2024-07-04 13:24:06,046:INFO:              plotly: 5.15.0
2024-07-04 13:24:06,046:INFO:    plotly-resampler: Not installed
2024-07-04 13:24:06,046:INFO:             kaleido: 0.2.1
2024-07-04 13:24:06,046:INFO:           schemdraw: 0.15
2024-07-04 13:24:06,046:INFO:         statsmodels: 0.14.2
2024-07-04 13:24:06,046:INFO:              sktime: 0.26.0
2024-07-04 13:24:06,046:INFO:               tbats: 1.1.3
2024-07-04 13:24:06,046:INFO:            pmdarima: 2.0.4
2024-07-04 13:24:06,046:INFO:              psutil: 5.9.5
2024-07-04 13:24:06,046:INFO:          markupsafe: 2.1.3
2024-07-04 13:24:06,046:INFO:             pickle5: Not installed
2024-07-04 13:24:06,046:INFO:         cloudpickle: 3.0.0
2024-07-04 13:24:06,046:INFO:         deprecation: 2.1.0
2024-07-04 13:24:06,046:INFO:              xxhash: 3.4.1
2024-07-04 13:24:06,046:INFO:           wurlitzer: Not installed
2024-07-04 13:24:06,046:INFO:PyCaret optional dependencies:
2024-07-04 13:24:06,064:INFO:                shap: 0.45.1
2024-07-04 13:24:06,064:INFO:           interpret: Not installed
2024-07-04 13:24:06,064:INFO:                umap: Not installed
2024-07-04 13:24:06,065:INFO:     ydata_profiling: 4.8.3
2024-07-04 13:24:06,065:INFO:  explainerdashboard: Not installed
2024-07-04 13:24:06,065:INFO:             autoviz: Not installed
2024-07-04 13:24:06,065:INFO:           fairlearn: Not installed
2024-07-04 13:24:06,065:INFO:          deepchecks: Not installed
2024-07-04 13:24:06,065:INFO:             xgboost: Not installed
2024-07-04 13:24:06,065:INFO:            catboost: Not installed
2024-07-04 13:24:06,065:INFO:              kmodes: Not installed
2024-07-04 13:24:06,065:INFO:             mlxtend: Not installed
2024-07-04 13:24:06,065:INFO:       statsforecast: Not installed
2024-07-04 13:24:06,065:INFO:        tune_sklearn: Not installed
2024-07-04 13:24:06,065:INFO:                 ray: Not installed
2024-07-04 13:24:06,065:INFO:            hyperopt: Not installed
2024-07-04 13:24:06,066:INFO:              optuna: 3.2.0
2024-07-04 13:24:06,066:INFO:               skopt: Not installed
2024-07-04 13:24:06,066:INFO:              mlflow: Not installed
2024-07-04 13:24:06,066:INFO:              gradio: Not installed
2024-07-04 13:24:06,066:INFO:             fastapi: Not installed
2024-07-04 13:24:06,066:INFO:             uvicorn: Not installed
2024-07-04 13:24:06,066:INFO:              m2cgen: Not installed
2024-07-04 13:24:06,066:INFO:           evidently: Not installed
2024-07-04 13:24:06,066:INFO:               fugue: Not installed
2024-07-04 13:24:06,066:INFO:           streamlit: 1.36.0
2024-07-04 13:24:06,066:INFO:             prophet: Not installed
2024-07-04 13:24:06,066:INFO:None
2024-07-04 13:24:06,066:INFO:Set up data.
2024-07-04 13:24:06,079:INFO:Set up folding strategy.
2024-07-04 13:24:06,079:INFO:Set up train/test split.
2024-07-04 13:24:06,096:INFO:Set up index.
2024-07-04 13:24:06,097:INFO:Assigning column types.
2024-07-04 13:24:06,107:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-04 13:24:06,189:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-04 13:24:06,198:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-04 13:24:06,284:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:24:06,285:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:24:06,377:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-04 13:24:06,378:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-04 13:24:06,443:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:24:06,444:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:24:06,444:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-04 13:24:06,521:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-04 13:24:06,589:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:24:06,590:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:24:06,706:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-04 13:24:06,759:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:24:06,760:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:24:06,760:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-04 13:24:06,938:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:24:06,938:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:24:07,100:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:24:07,100:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:24:07,106:INFO:Preparing preprocessing pipeline...
2024-07-04 13:24:07,106:INFO:Set up simple imputation.
2024-07-04 13:24:07,116:INFO:Set up encoding of ordinal features.
2024-07-04 13:24:07,116:INFO:Set up encoding of categorical features.
2024-07-04 13:24:07,116:INFO:Set up imbalanced handling.
2024-07-04 13:24:07,116:INFO:Set up feature normalization.
2024-07-04 13:24:07,116:INFO:Set up feature selection.
2024-07-04 13:24:07,296:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:24:07,307:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:24:07,985:INFO:Finished creating preprocessing pipeline.
2024-07-04 13:24:08,016:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\PHYOSA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['customer_id', 'credit_score',
                                             'age', 'tenure', 'balance',
                                             'products_number', 'credit_card',
                                             'active_member',
                                             'estimated_salary', 'churn_x'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=N...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=2,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2024-07-04 13:24:08,016:INFO:Creating final display dataframe.
2024-07-04 13:24:08,801:INFO:Setup _display_container:                     Description             Value
0                    Session id              6212
1                        Target           churn_y
2                   Target type            Binary
3           Original data shape       (10000, 13)
4        Transformed data shape        (14148, 3)
5   Transformed train set shape        (11148, 3)
6    Transformed test set shape         (3000, 3)
7              Numeric features                10
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation            median
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17                    Normalize              True
18             Normalize method            robust
19            Feature selection              True
20     Feature selection method           classic
21  Feature selection estimator          lightgbm
22  Number of features selected               0.2
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              e57f
2024-07-04 13:24:08,901:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:24:08,901:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:24:09,018:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:24:09,018:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:24:09,018:INFO:setup() successfully completed in 3.3s...............
2024-07-04 13:24:09,018:INFO:Initializing compare_models()
2024-07-04 13:24:09,018:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000232286D4B10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000232286D4B10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-07-04 13:24:09,029:INFO:Checking exceptions
2024-07-04 13:24:09,038:INFO:Preparing display monitor
2024-07-04 13:24:09,040:INFO:Initializing Logistic Regression
2024-07-04 13:24:09,040:INFO:Total runtime is 0.0 minutes
2024-07-04 13:24:09,040:INFO:SubProcess create_model() called ==================================
2024-07-04 13:24:09,040:INFO:Initializing create_model()
2024-07-04 13:24:09,040:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000232286D4B10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023234D2EF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:24:09,040:INFO:Checking exceptions
2024-07-04 13:24:09,040:INFO:Importing libraries
2024-07-04 13:24:09,040:INFO:Copying training dataset
2024-07-04 13:24:09,056:INFO:Defining folds
2024-07-04 13:24:09,056:INFO:Declaring metric variables
2024-07-04 13:24:09,056:INFO:Importing untrained model
2024-07-04 13:24:09,056:INFO:Logistic Regression Imported successfully
2024-07-04 13:24:09,056:INFO:Starting cross validation
2024-07-04 13:24:09,056:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:24:22,705:INFO:Calculating mean and std
2024-07-04 13:24:22,705:INFO:Creating metrics dataframe
2024-07-04 13:24:22,705:INFO:Uploading results into container
2024-07-04 13:24:22,718:INFO:Uploading model into container now
2024-07-04 13:24:22,720:INFO:_master_model_container: 1
2024-07-04 13:24:22,720:INFO:_display_container: 2
2024-07-04 13:24:22,720:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6212, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-04 13:24:22,720:INFO:create_model() successfully completed......................................
2024-07-04 13:24:22,960:INFO:SubProcess create_model() end ==================================
2024-07-04 13:24:22,961:INFO:Creating metrics dataframe
2024-07-04 13:24:22,967:INFO:Initializing K Neighbors Classifier
2024-07-04 13:24:22,967:INFO:Total runtime is 0.23210873206456503 minutes
2024-07-04 13:24:22,968:INFO:SubProcess create_model() called ==================================
2024-07-04 13:24:22,968:INFO:Initializing create_model()
2024-07-04 13:24:22,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000232286D4B10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023234D2EF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:24:22,969:INFO:Checking exceptions
2024-07-04 13:24:22,969:INFO:Importing libraries
2024-07-04 13:24:22,969:INFO:Copying training dataset
2024-07-04 13:24:22,982:INFO:Defining folds
2024-07-04 13:24:22,982:INFO:Declaring metric variables
2024-07-04 13:24:22,982:INFO:Importing untrained model
2024-07-04 13:24:22,983:INFO:K Neighbors Classifier Imported successfully
2024-07-04 13:24:22,984:INFO:Starting cross validation
2024-07-04 13:24:22,994:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:24:25,218:INFO:Calculating mean and std
2024-07-04 13:24:25,218:INFO:Creating metrics dataframe
2024-07-04 13:24:25,218:INFO:Uploading results into container
2024-07-04 13:24:25,228:INFO:Uploading model into container now
2024-07-04 13:24:25,229:INFO:_master_model_container: 2
2024-07-04 13:24:25,229:INFO:_display_container: 2
2024-07-04 13:24:25,229:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-04 13:24:25,229:INFO:create_model() successfully completed......................................
2024-07-04 13:24:25,433:INFO:SubProcess create_model() end ==================================
2024-07-04 13:24:25,433:INFO:Creating metrics dataframe
2024-07-04 13:24:25,433:INFO:Initializing Naive Bayes
2024-07-04 13:24:25,433:INFO:Total runtime is 0.2732189138730367 minutes
2024-07-04 13:24:25,433:INFO:SubProcess create_model() called ==================================
2024-07-04 13:24:25,433:INFO:Initializing create_model()
2024-07-04 13:24:25,433:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000232286D4B10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023234D2EF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:24:25,433:INFO:Checking exceptions
2024-07-04 13:24:25,433:INFO:Importing libraries
2024-07-04 13:24:25,433:INFO:Copying training dataset
2024-07-04 13:24:25,462:INFO:Defining folds
2024-07-04 13:24:25,462:INFO:Declaring metric variables
2024-07-04 13:24:25,462:INFO:Importing untrained model
2024-07-04 13:24:25,462:INFO:Naive Bayes Imported successfully
2024-07-04 13:24:25,467:INFO:Starting cross validation
2024-07-04 13:24:25,477:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:24:27,383:INFO:Calculating mean and std
2024-07-04 13:24:27,383:INFO:Creating metrics dataframe
2024-07-04 13:24:27,383:INFO:Uploading results into container
2024-07-04 13:24:27,396:INFO:Uploading model into container now
2024-07-04 13:24:27,396:INFO:_master_model_container: 3
2024-07-04 13:24:27,396:INFO:_display_container: 2
2024-07-04 13:24:27,396:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-04 13:24:27,396:INFO:create_model() successfully completed......................................
2024-07-04 13:24:27,648:INFO:SubProcess create_model() end ==================================
2024-07-04 13:24:27,648:INFO:Creating metrics dataframe
2024-07-04 13:24:27,664:INFO:Initializing Decision Tree Classifier
2024-07-04 13:24:27,664:INFO:Total runtime is 0.31040470202763876 minutes
2024-07-04 13:24:27,664:INFO:SubProcess create_model() called ==================================
2024-07-04 13:24:27,664:INFO:Initializing create_model()
2024-07-04 13:24:27,664:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000232286D4B10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023234D2EF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:24:27,664:INFO:Checking exceptions
2024-07-04 13:24:27,664:INFO:Importing libraries
2024-07-04 13:24:27,664:INFO:Copying training dataset
2024-07-04 13:24:27,681:INFO:Defining folds
2024-07-04 13:24:27,681:INFO:Declaring metric variables
2024-07-04 13:24:27,681:INFO:Importing untrained model
2024-07-04 13:24:27,681:INFO:Decision Tree Classifier Imported successfully
2024-07-04 13:24:27,681:INFO:Starting cross validation
2024-07-04 13:24:27,697:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:24:29,826:INFO:Calculating mean and std
2024-07-04 13:24:29,826:INFO:Creating metrics dataframe
2024-07-04 13:24:29,832:INFO:Uploading results into container
2024-07-04 13:24:29,832:INFO:Uploading model into container now
2024-07-04 13:24:29,832:INFO:_master_model_container: 4
2024-07-04 13:24:29,832:INFO:_display_container: 2
2024-07-04 13:24:29,832:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=6212, splitter='best')
2024-07-04 13:24:29,832:INFO:create_model() successfully completed......................................
2024-07-04 13:24:30,057:INFO:SubProcess create_model() end ==================================
2024-07-04 13:24:30,057:INFO:Creating metrics dataframe
2024-07-04 13:24:30,057:INFO:Initializing SVM - Linear Kernel
2024-07-04 13:24:30,057:INFO:Total runtime is 0.350282613436381 minutes
2024-07-04 13:24:30,057:INFO:SubProcess create_model() called ==================================
2024-07-04 13:24:30,057:INFO:Initializing create_model()
2024-07-04 13:24:30,057:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000232286D4B10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023234D2EF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:24:30,057:INFO:Checking exceptions
2024-07-04 13:24:30,057:INFO:Importing libraries
2024-07-04 13:24:30,057:INFO:Copying training dataset
2024-07-04 13:24:30,073:INFO:Defining folds
2024-07-04 13:24:30,073:INFO:Declaring metric variables
2024-07-04 13:24:30,073:INFO:Importing untrained model
2024-07-04 13:24:30,088:INFO:SVM - Linear Kernel Imported successfully
2024-07-04 13:24:30,088:INFO:Starting cross validation
2024-07-04 13:24:30,088:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:24:32,493:INFO:Calculating mean and std
2024-07-04 13:24:32,493:INFO:Creating metrics dataframe
2024-07-04 13:24:32,504:INFO:Uploading results into container
2024-07-04 13:24:32,509:INFO:Uploading model into container now
2024-07-04 13:24:32,509:INFO:_master_model_container: 5
2024-07-04 13:24:32,509:INFO:_display_container: 2
2024-07-04 13:24:32,509:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=6212, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-04 13:24:32,509:INFO:create_model() successfully completed......................................
2024-07-04 13:24:32,759:INFO:SubProcess create_model() end ==================================
2024-07-04 13:24:32,759:INFO:Creating metrics dataframe
2024-07-04 13:24:32,768:INFO:Initializing Ridge Classifier
2024-07-04 13:24:32,768:INFO:Total runtime is 0.3954695145289103 minutes
2024-07-04 13:24:32,769:INFO:SubProcess create_model() called ==================================
2024-07-04 13:24:32,769:INFO:Initializing create_model()
2024-07-04 13:24:32,770:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000232286D4B10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023234D2EF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:24:32,770:INFO:Checking exceptions
2024-07-04 13:24:32,770:INFO:Importing libraries
2024-07-04 13:24:32,770:INFO:Copying training dataset
2024-07-04 13:24:32,790:INFO:Defining folds
2024-07-04 13:24:32,791:INFO:Declaring metric variables
2024-07-04 13:24:32,791:INFO:Importing untrained model
2024-07-04 13:24:32,791:INFO:Ridge Classifier Imported successfully
2024-07-04 13:24:32,791:INFO:Starting cross validation
2024-07-04 13:24:32,808:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:24:35,052:INFO:Calculating mean and std
2024-07-04 13:24:35,053:INFO:Creating metrics dataframe
2024-07-04 13:24:35,053:INFO:Uploading results into container
2024-07-04 13:24:35,053:INFO:Uploading model into container now
2024-07-04 13:24:35,053:INFO:_master_model_container: 6
2024-07-04 13:24:35,053:INFO:_display_container: 2
2024-07-04 13:24:35,053:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6212, solver='auto',
                tol=0.0001)
2024-07-04 13:24:35,053:INFO:create_model() successfully completed......................................
2024-07-04 13:24:35,313:INFO:SubProcess create_model() end ==================================
2024-07-04 13:24:35,313:INFO:Creating metrics dataframe
2024-07-04 13:24:35,330:INFO:Initializing Random Forest Classifier
2024-07-04 13:24:35,330:INFO:Total runtime is 0.43816206057866414 minutes
2024-07-04 13:24:35,330:INFO:SubProcess create_model() called ==================================
2024-07-04 13:24:35,330:INFO:Initializing create_model()
2024-07-04 13:24:35,330:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000232286D4B10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023234D2EF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:24:35,330:INFO:Checking exceptions
2024-07-04 13:24:35,330:INFO:Importing libraries
2024-07-04 13:24:35,330:INFO:Copying training dataset
2024-07-04 13:24:35,339:INFO:Defining folds
2024-07-04 13:24:35,339:INFO:Declaring metric variables
2024-07-04 13:24:35,339:INFO:Importing untrained model
2024-07-04 13:24:35,339:INFO:Random Forest Classifier Imported successfully
2024-07-04 13:24:35,339:INFO:Starting cross validation
2024-07-04 13:24:35,371:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:24:41,559:INFO:Calculating mean and std
2024-07-04 13:24:41,561:INFO:Creating metrics dataframe
2024-07-04 13:24:41,566:INFO:Uploading results into container
2024-07-04 13:24:41,568:INFO:Uploading model into container now
2024-07-04 13:24:41,569:INFO:_master_model_container: 7
2024-07-04 13:24:41,569:INFO:_display_container: 2
2024-07-04 13:24:41,570:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=6212, verbose=0,
                       warm_start=False)
2024-07-04 13:24:41,570:INFO:create_model() successfully completed......................................
2024-07-04 13:24:41,779:INFO:SubProcess create_model() end ==================================
2024-07-04 13:24:41,779:INFO:Creating metrics dataframe
2024-07-04 13:24:41,782:INFO:Initializing Quadratic Discriminant Analysis
2024-07-04 13:24:41,782:INFO:Total runtime is 0.5456927498181661 minutes
2024-07-04 13:24:41,782:INFO:SubProcess create_model() called ==================================
2024-07-04 13:24:41,782:INFO:Initializing create_model()
2024-07-04 13:24:41,782:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000232286D4B10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023234D2EF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:24:41,782:INFO:Checking exceptions
2024-07-04 13:24:41,782:INFO:Importing libraries
2024-07-04 13:24:41,782:INFO:Copying training dataset
2024-07-04 13:24:41,795:INFO:Defining folds
2024-07-04 13:24:41,795:INFO:Declaring metric variables
2024-07-04 13:24:41,811:INFO:Importing untrained model
2024-07-04 13:24:41,811:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-04 13:24:41,811:INFO:Starting cross validation
2024-07-04 13:24:41,811:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:24:43,364:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 13:24:43,421:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 13:24:43,472:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:24:43,472:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:24:43,472:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:24:43,472:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:24:43,472:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:24:43,482:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:24:43,502:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 13:24:43,519:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:24:43,519:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:24:43,519:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:24:43,524:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:24:43,524:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:24:43,524:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:24:43,524:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:24:43,555:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 13:24:43,574:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:24:43,694:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 13:24:43,775:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:24:43,776:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:24:43,777:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:24:43,780:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:24:43,780:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:24:43,780:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:24:43,787:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 13:24:43,807:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:24:44,519:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 13:24:44,600:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:24:44,600:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:24:44,600:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:24:44,600:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:24:44,600:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:24:44,600:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:24:44,613:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 13:24:44,627:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:24:44,641:INFO:Calculating mean and std
2024-07-04 13:24:44,641:INFO:Creating metrics dataframe
2024-07-04 13:24:44,646:INFO:Uploading results into container
2024-07-04 13:24:44,646:INFO:Uploading model into container now
2024-07-04 13:24:44,646:INFO:_master_model_container: 8
2024-07-04 13:24:44,646:INFO:_display_container: 2
2024-07-04 13:24:44,646:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-04 13:24:44,646:INFO:create_model() successfully completed......................................
2024-07-04 13:24:44,928:INFO:SubProcess create_model() end ==================================
2024-07-04 13:24:44,929:INFO:Creating metrics dataframe
2024-07-04 13:24:44,931:INFO:Initializing Ada Boost Classifier
2024-07-04 13:24:44,931:INFO:Total runtime is 0.5981829643249511 minutes
2024-07-04 13:24:44,931:INFO:SubProcess create_model() called ==================================
2024-07-04 13:24:44,931:INFO:Initializing create_model()
2024-07-04 13:24:44,931:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000232286D4B10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023234D2EF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:24:44,931:INFO:Checking exceptions
2024-07-04 13:24:44,931:INFO:Importing libraries
2024-07-04 13:24:44,931:INFO:Copying training dataset
2024-07-04 13:24:44,970:INFO:Defining folds
2024-07-04 13:24:44,970:INFO:Declaring metric variables
2024-07-04 13:24:44,971:INFO:Importing untrained model
2024-07-04 13:24:44,972:INFO:Ada Boost Classifier Imported successfully
2024-07-04 13:24:44,973:INFO:Starting cross validation
2024-07-04 13:24:44,978:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:24:46,509:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:24:46,549:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:24:46,613:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:24:46,995:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:24:47,185:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:24:47,335:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:24:47,534:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:24:47,767:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:24:48,312:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:24:48,362:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:24:49,303:INFO:Calculating mean and std
2024-07-04 13:24:49,303:INFO:Creating metrics dataframe
2024-07-04 13:24:49,303:INFO:Uploading results into container
2024-07-04 13:24:49,303:INFO:Uploading model into container now
2024-07-04 13:24:49,303:INFO:_master_model_container: 9
2024-07-04 13:24:49,303:INFO:_display_container: 2
2024-07-04 13:24:49,303:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=6212)
2024-07-04 13:24:49,303:INFO:create_model() successfully completed......................................
2024-07-04 13:24:49,490:INFO:SubProcess create_model() end ==================================
2024-07-04 13:24:49,490:INFO:Creating metrics dataframe
2024-07-04 13:24:49,499:INFO:Initializing Gradient Boosting Classifier
2024-07-04 13:24:49,499:INFO:Total runtime is 0.6743128816286722 minutes
2024-07-04 13:24:49,499:INFO:SubProcess create_model() called ==================================
2024-07-04 13:24:49,499:INFO:Initializing create_model()
2024-07-04 13:24:49,499:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000232286D4B10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023234D2EF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:24:49,499:INFO:Checking exceptions
2024-07-04 13:24:49,499:INFO:Importing libraries
2024-07-04 13:24:49,499:INFO:Copying training dataset
2024-07-04 13:24:49,516:INFO:Defining folds
2024-07-04 13:24:49,516:INFO:Declaring metric variables
2024-07-04 13:24:49,516:INFO:Importing untrained model
2024-07-04 13:24:49,516:INFO:Gradient Boosting Classifier Imported successfully
2024-07-04 13:24:49,516:INFO:Starting cross validation
2024-07-04 13:24:49,523:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:24:54,713:INFO:Calculating mean and std
2024-07-04 13:24:54,713:INFO:Creating metrics dataframe
2024-07-04 13:24:54,721:INFO:Uploading results into container
2024-07-04 13:24:54,721:INFO:Uploading model into container now
2024-07-04 13:24:54,721:INFO:_master_model_container: 10
2024-07-04 13:24:54,721:INFO:_display_container: 2
2024-07-04 13:24:54,721:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-04 13:24:54,721:INFO:create_model() successfully completed......................................
2024-07-04 13:24:54,936:INFO:SubProcess create_model() end ==================================
2024-07-04 13:24:54,936:INFO:Creating metrics dataframe
2024-07-04 13:24:54,936:INFO:Initializing Linear Discriminant Analysis
2024-07-04 13:24:54,936:INFO:Total runtime is 0.7649345556894938 minutes
2024-07-04 13:24:54,936:INFO:SubProcess create_model() called ==================================
2024-07-04 13:24:54,936:INFO:Initializing create_model()
2024-07-04 13:24:54,936:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000232286D4B10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023234D2EF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:24:54,936:INFO:Checking exceptions
2024-07-04 13:24:54,936:INFO:Importing libraries
2024-07-04 13:24:54,936:INFO:Copying training dataset
2024-07-04 13:24:54,969:INFO:Defining folds
2024-07-04 13:24:54,969:INFO:Declaring metric variables
2024-07-04 13:24:54,969:INFO:Importing untrained model
2024-07-04 13:24:54,969:INFO:Linear Discriminant Analysis Imported successfully
2024-07-04 13:24:54,969:INFO:Starting cross validation
2024-07-04 13:24:54,969:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:24:57,342:INFO:Calculating mean and std
2024-07-04 13:24:57,342:INFO:Creating metrics dataframe
2024-07-04 13:24:57,350:INFO:Uploading results into container
2024-07-04 13:24:57,350:INFO:Uploading model into container now
2024-07-04 13:24:57,350:INFO:_master_model_container: 11
2024-07-04 13:24:57,350:INFO:_display_container: 2
2024-07-04 13:24:57,350:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-04 13:24:57,350:INFO:create_model() successfully completed......................................
2024-07-04 13:24:57,616:INFO:SubProcess create_model() end ==================================
2024-07-04 13:24:57,616:INFO:Creating metrics dataframe
2024-07-04 13:24:57,616:INFO:Initializing Extra Trees Classifier
2024-07-04 13:24:57,616:INFO:Total runtime is 0.8095996618270873 minutes
2024-07-04 13:24:57,616:INFO:SubProcess create_model() called ==================================
2024-07-04 13:24:57,616:INFO:Initializing create_model()
2024-07-04 13:24:57,616:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000232286D4B10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023234D2EF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:24:57,616:INFO:Checking exceptions
2024-07-04 13:24:57,616:INFO:Importing libraries
2024-07-04 13:24:57,616:INFO:Copying training dataset
2024-07-04 13:24:57,633:INFO:Defining folds
2024-07-04 13:24:57,633:INFO:Declaring metric variables
2024-07-04 13:24:57,633:INFO:Importing untrained model
2024-07-04 13:24:57,633:INFO:Extra Trees Classifier Imported successfully
2024-07-04 13:24:57,648:INFO:Starting cross validation
2024-07-04 13:24:57,663:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:25:04,583:INFO:Calculating mean and std
2024-07-04 13:25:04,583:INFO:Creating metrics dataframe
2024-07-04 13:25:04,583:INFO:Uploading results into container
2024-07-04 13:25:04,583:INFO:Uploading model into container now
2024-07-04 13:25:04,583:INFO:_master_model_container: 12
2024-07-04 13:25:04,583:INFO:_display_container: 2
2024-07-04 13:25:04,589:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=6212, verbose=0,
                     warm_start=False)
2024-07-04 13:25:04,589:INFO:create_model() successfully completed......................................
2024-07-04 13:25:04,869:INFO:SubProcess create_model() end ==================================
2024-07-04 13:25:04,869:INFO:Creating metrics dataframe
2024-07-04 13:25:04,874:INFO:Initializing Light Gradient Boosting Machine
2024-07-04 13:25:04,874:INFO:Total runtime is 0.930569847424825 minutes
2024-07-04 13:25:04,874:INFO:SubProcess create_model() called ==================================
2024-07-04 13:25:04,874:INFO:Initializing create_model()
2024-07-04 13:25:04,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000232286D4B10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023234D2EF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:25:04,874:INFO:Checking exceptions
2024-07-04 13:25:04,874:INFO:Importing libraries
2024-07-04 13:25:04,874:INFO:Copying training dataset
2024-07-04 13:25:04,890:INFO:Defining folds
2024-07-04 13:25:04,890:INFO:Declaring metric variables
2024-07-04 13:25:04,890:INFO:Importing untrained model
2024-07-04 13:25:04,890:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-04 13:25:04,905:INFO:Starting cross validation
2024-07-04 13:25:04,906:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:25:08,844:INFO:Calculating mean and std
2024-07-04 13:25:08,844:INFO:Creating metrics dataframe
2024-07-04 13:25:08,844:INFO:Uploading results into container
2024-07-04 13:25:08,844:INFO:Uploading model into container now
2024-07-04 13:25:08,844:INFO:_master_model_container: 13
2024-07-04 13:25:08,844:INFO:_display_container: 2
2024-07-04 13:25:08,844:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-04 13:25:08,844:INFO:create_model() successfully completed......................................
2024-07-04 13:25:09,102:INFO:SubProcess create_model() end ==================================
2024-07-04 13:25:09,102:INFO:Creating metrics dataframe
2024-07-04 13:25:09,102:INFO:Initializing Dummy Classifier
2024-07-04 13:25:09,102:INFO:Total runtime is 1.0010325630505879 minutes
2024-07-04 13:25:09,102:INFO:SubProcess create_model() called ==================================
2024-07-04 13:25:09,117:INFO:Initializing create_model()
2024-07-04 13:25:09,117:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000232286D4B10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023234D2EF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:25:09,117:INFO:Checking exceptions
2024-07-04 13:25:09,117:INFO:Importing libraries
2024-07-04 13:25:09,118:INFO:Copying training dataset
2024-07-04 13:25:09,136:INFO:Defining folds
2024-07-04 13:25:09,136:INFO:Declaring metric variables
2024-07-04 13:25:09,136:INFO:Importing untrained model
2024-07-04 13:25:09,136:INFO:Dummy Classifier Imported successfully
2024-07-04 13:25:09,136:INFO:Starting cross validation
2024-07-04 13:25:09,154:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:25:10,519:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:25:10,523:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:25:10,669:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:25:10,669:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:25:10,815:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:25:10,835:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:25:10,938:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:25:11,003:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:25:11,269:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:25:11,299:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:25:11,321:INFO:Calculating mean and std
2024-07-04 13:25:11,321:INFO:Creating metrics dataframe
2024-07-04 13:25:11,321:INFO:Uploading results into container
2024-07-04 13:25:11,321:INFO:Uploading model into container now
2024-07-04 13:25:11,333:INFO:_master_model_container: 14
2024-07-04 13:25:11,333:INFO:_display_container: 2
2024-07-04 13:25:11,334:INFO:DummyClassifier(constant=None, random_state=6212, strategy='prior')
2024-07-04 13:25:11,334:INFO:create_model() successfully completed......................................
2024-07-04 13:25:11,583:INFO:SubProcess create_model() end ==================================
2024-07-04 13:25:11,583:INFO:Creating metrics dataframe
2024-07-04 13:25:11,601:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-07-04 13:25:11,603:INFO:Initializing create_model()
2024-07-04 13:25:11,603:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000232286D4B10>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6212, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:25:11,603:INFO:Checking exceptions
2024-07-04 13:25:11,603:INFO:Importing libraries
2024-07-04 13:25:11,603:INFO:Copying training dataset
2024-07-04 13:25:11,619:INFO:Defining folds
2024-07-04 13:25:11,619:INFO:Declaring metric variables
2024-07-04 13:25:11,619:INFO:Importing untrained model
2024-07-04 13:25:11,619:INFO:Declaring custom model
2024-07-04 13:25:11,619:INFO:Ridge Classifier Imported successfully
2024-07-04 13:25:11,634:INFO:Cross validation set to False
2024-07-04 13:25:11,634:INFO:Fitting Model
2024-07-04 13:25:11,915:INFO:[LightGBM] [Info] Number of positive: 5574, number of negative: 5574
2024-07-04 13:25:11,915:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001249 seconds.
2024-07-04 13:25:11,915:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-04 13:25:11,915:INFO:[LightGBM] [Info] Total Bins 3318
2024-07-04 13:25:11,915:INFO:[LightGBM] [Info] Number of data points in the train set: 11148, number of used features: 14
2024-07-04 13:25:11,915:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-07-04 13:25:11,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:11,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:12,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:12,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:12,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:12,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:12,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:12,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:12,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:12,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:12,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:12,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:12,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:12,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:12,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:12,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:12,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:12,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:12,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:12,034:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6212, solver='auto',
                tol=0.0001)
2024-07-04 13:25:12,034:INFO:create_model() successfully completed......................................
2024-07-04 13:25:12,250:INFO:_master_model_container: 14
2024-07-04 13:25:12,250:INFO:_display_container: 2
2024-07-04 13:25:12,250:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6212, solver='auto',
                tol=0.0001)
2024-07-04 13:25:12,250:INFO:compare_models() successfully completed......................................
2024-07-04 13:25:12,266:INFO:Initializing tune_model()
2024-07-04 13:25:12,266:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000232286D4B10>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6212, solver='auto',
                tol=0.0001), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-04 13:25:12,266:INFO:Checking exceptions
2024-07-04 13:25:12,277:INFO:Copying training dataset
2024-07-04 13:25:12,293:INFO:Checking base model
2024-07-04 13:25:12,293:INFO:Base model : Ridge Classifier
2024-07-04 13:25:12,294:INFO:Declaring metric variables
2024-07-04 13:25:12,294:INFO:Defining Hyperparameters
2024-07-04 13:25:12,550:INFO:Tuning with n_jobs=-1
2024-07-04 13:25:12,550:INFO:Initializing RandomizedSearchCV
2024-07-04 13:25:38,466:INFO:best_params: {'actual_estimator__fit_intercept': True, 'actual_estimator__alpha': 0.59}
2024-07-04 13:25:38,466:INFO:Hyperparameter search completed
2024-07-04 13:25:38,469:INFO:SubProcess create_model() called ==================================
2024-07-04 13:25:38,469:INFO:Initializing create_model()
2024-07-04 13:25:38,470:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000232286D4B10>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6212, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002323701EF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': True, 'alpha': 0.59})
2024-07-04 13:25:38,470:INFO:Checking exceptions
2024-07-04 13:25:38,470:INFO:Importing libraries
2024-07-04 13:25:38,470:INFO:Copying training dataset
2024-07-04 13:25:38,492:INFO:Defining folds
2024-07-04 13:25:38,493:INFO:Declaring metric variables
2024-07-04 13:25:38,493:INFO:Importing untrained model
2024-07-04 13:25:38,494:INFO:Declaring custom model
2024-07-04 13:25:38,496:INFO:Ridge Classifier Imported successfully
2024-07-04 13:25:38,497:INFO:Starting cross validation
2024-07-04 13:25:38,512:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:25:40,952:INFO:Calculating mean and std
2024-07-04 13:25:40,954:INFO:Creating metrics dataframe
2024-07-04 13:25:40,954:INFO:Finalizing model
2024-07-04 13:25:41,249:INFO:[LightGBM] [Info] Number of positive: 5574, number of negative: 5574
2024-07-04 13:25:41,249:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000807 seconds.
2024-07-04 13:25:41,249:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-04 13:25:41,249:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-04 13:25:41,249:INFO:[LightGBM] [Info] Total Bins 3318
2024-07-04 13:25:41,249:INFO:[LightGBM] [Info] Number of data points in the train set: 11148, number of used features: 14
2024-07-04 13:25:41,249:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-07-04 13:25:41,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,316:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:41,403:INFO:Uploading results into container
2024-07-04 13:25:41,403:INFO:Uploading model into container now
2024-07-04 13:25:41,415:INFO:_master_model_container: 15
2024-07-04 13:25:41,415:INFO:_display_container: 3
2024-07-04 13:25:41,416:INFO:RidgeClassifier(alpha=0.59, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6212, solver='auto',
                tol=0.0001)
2024-07-04 13:25:41,416:INFO:create_model() successfully completed......................................
2024-07-04 13:25:41,703:INFO:SubProcess create_model() end ==================================
2024-07-04 13:25:41,703:INFO:choose_better activated
2024-07-04 13:25:41,703:INFO:SubProcess create_model() called ==================================
2024-07-04 13:25:41,703:INFO:Initializing create_model()
2024-07-04 13:25:41,703:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000232286D4B10>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6212, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:25:41,703:INFO:Checking exceptions
2024-07-04 13:25:41,703:INFO:Importing libraries
2024-07-04 13:25:41,703:INFO:Copying training dataset
2024-07-04 13:25:41,733:INFO:Defining folds
2024-07-04 13:25:41,733:INFO:Declaring metric variables
2024-07-04 13:25:41,733:INFO:Importing untrained model
2024-07-04 13:25:41,733:INFO:Declaring custom model
2024-07-04 13:25:41,733:INFO:Ridge Classifier Imported successfully
2024-07-04 13:25:41,733:INFO:Starting cross validation
2024-07-04 13:25:41,749:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:25:45,028:INFO:Calculating mean and std
2024-07-04 13:25:45,028:INFO:Creating metrics dataframe
2024-07-04 13:25:45,028:INFO:Finalizing model
2024-07-04 13:25:45,309:INFO:[LightGBM] [Info] Number of positive: 5574, number of negative: 5574
2024-07-04 13:25:45,312:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001453 seconds.
2024-07-04 13:25:45,312:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-04 13:25:45,312:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-04 13:25:45,312:INFO:[LightGBM] [Info] Total Bins 3318
2024-07-04 13:25:45,312:INFO:[LightGBM] [Info] Number of data points in the train set: 11148, number of used features: 14
2024-07-04 13:25:45,312:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-07-04 13:25:45,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:25:45,435:INFO:Uploading results into container
2024-07-04 13:25:45,435:INFO:Uploading model into container now
2024-07-04 13:25:45,435:INFO:_master_model_container: 16
2024-07-04 13:25:45,435:INFO:_display_container: 4
2024-07-04 13:25:45,435:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6212, solver='auto',
                tol=0.0001)
2024-07-04 13:25:45,435:INFO:create_model() successfully completed......................................
2024-07-04 13:25:45,645:INFO:SubProcess create_model() end ==================================
2024-07-04 13:25:45,645:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6212, solver='auto',
                tol=0.0001) result for Accuracy is 0.9491
2024-07-04 13:25:45,645:INFO:RidgeClassifier(alpha=0.59, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6212, solver='auto',
                tol=0.0001) result for Accuracy is 0.8094
2024-07-04 13:25:45,645:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6212, solver='auto',
                tol=0.0001) is best model
2024-07-04 13:25:45,645:INFO:choose_better completed
2024-07-04 13:25:45,645:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-04 13:25:45,672:INFO:_master_model_container: 16
2024-07-04 13:25:45,672:INFO:_display_container: 3
2024-07-04 13:25:45,672:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6212, solver='auto',
                tol=0.0001)
2024-07-04 13:25:45,672:INFO:tune_model() successfully completed......................................
2024-07-04 13:25:45,878:INFO:Initializing plot_model()
2024-07-04 13:25:45,894:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000232286D4B10>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6212, solver='auto',
                tol=0.0001), plot=class_report, scale=0.75, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2024-07-04 13:25:45,895:INFO:Checking exceptions
2024-07-04 13:25:45,895:INFO:Soft dependency imported: streamlit: 1.36.0
2024-07-04 13:25:45,896:INFO:Preloading libraries
2024-07-04 13:25:45,896:INFO:Copying training dataset
2024-07-04 13:25:45,896:INFO:Plot type: class_report
2024-07-04 13:25:46,072:INFO:Fitting Model
2024-07-04 13:25:46,072:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names
  warnings.warn(

2024-07-04 13:25:46,072:INFO:Scoring test/hold-out set
2024-07-04 13:25:46,815:INFO:Visual Rendered Successfully
2024-07-04 13:25:47,010:INFO:plot_model() successfully completed......................................
2024-07-04 13:25:47,010:INFO:Initializing plot_model()
2024-07-04 13:25:47,010:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000232286D4B10>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6212, solver='auto',
                tol=0.0001), plot=confusion_matrix, scale=0.75, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2024-07-04 13:25:47,010:INFO:Checking exceptions
2024-07-04 13:25:47,010:INFO:Soft dependency imported: streamlit: 1.36.0
2024-07-04 13:25:47,010:INFO:Preloading libraries
2024-07-04 13:25:47,010:INFO:Copying training dataset
2024-07-04 13:25:47,010:INFO:Plot type: confusion_matrix
2024-07-04 13:25:47,187:INFO:Fitting Model
2024-07-04 13:25:47,187:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names
  warnings.warn(

2024-07-04 13:25:47,187:INFO:Scoring test/hold-out set
2024-07-04 13:25:47,687:INFO:Visual Rendered Successfully
2024-07-04 13:25:47,859:INFO:plot_model() successfully completed......................................
2024-07-04 13:25:47,859:INFO:Initializing plot_model()
2024-07-04 13:25:47,859:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000232286D4B10>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6212, solver='auto',
                tol=0.0001), plot=auc, scale=0.75, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2024-07-04 13:25:47,859:INFO:Checking exceptions
2024-07-04 13:25:47,859:INFO:Soft dependency imported: streamlit: 1.36.0
2024-07-04 13:39:51,161:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 13:39:51,161:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 13:39:51,161:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 13:39:51,161:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 13:40:39,182:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'France'')
  warnings.warn(

2024-07-04 13:41:18,071:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'France'')
  warnings.warn(

2024-07-04 13:41:20,765:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'France'')
  warnings.warn(

2024-07-04 13:41:50,088:INFO:PyCaret ClassificationExperiment
2024-07-04 13:41:50,088:INFO:Logging name: clf-default-name
2024-07-04 13:41:50,088:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-04 13:41:50,088:INFO:version 3.3.2
2024-07-04 13:41:50,088:INFO:Initializing setup()
2024-07-04 13:41:50,088:INFO:self.USI: 6dc8
2024-07-04 13:41:50,088:INFO:self._variable_keys: {'_available_plots', 'USI', 'exp_name_log', 'n_jobs_param', 'gpu_n_jobs_param', '_ml_usecase', 'log_plots_param', 'seed', 'y', 'target_param', 'fold_groups_param', 'X_train', 'X', 'y_test', 'fold_shuffle_param', 'gpu_param', 'X_test', 'logging_param', 'is_multiclass', 'y_train', 'idx', 'pipeline', 'html_param', 'fold_generator', 'fix_imbalance', 'exp_id', 'data', 'memory'}
2024-07-04 13:41:50,088:INFO:Checking environment
2024-07-04 13:41:50,088:INFO:python_version: 3.11.3
2024-07-04 13:41:50,088:INFO:python_build: ('tags/v3.11.3:f3909b8', 'Apr  4 2023 23:49:59')
2024-07-04 13:41:50,088:INFO:machine: AMD64
2024-07-04 13:41:50,101:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-04 13:41:50,119:INFO:Memory: svmem(total=8179539968, available=1227665408, percent=85.0, used=6951874560, free=1227665408)
2024-07-04 13:41:50,120:INFO:Physical Core: 4
2024-07-04 13:41:50,120:INFO:Logical Core: 8
2024-07-04 13:41:50,120:INFO:Checking libraries
2024-07-04 13:41:50,120:INFO:System:
2024-07-04 13:41:50,120:INFO:    python: 3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]
2024-07-04 13:41:50,120:INFO:executable: C:\Program Files\Python311\python.exe
2024-07-04 13:41:50,120:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-04 13:41:50,120:INFO:PyCaret required dependencies:
2024-07-04 13:41:50,229:INFO:                 pip: 23.1.2
2024-07-04 13:41:50,229:INFO:          setuptools: 67.8.0
2024-07-04 13:41:50,229:INFO:             pycaret: 3.3.2
2024-07-04 13:41:50,229:INFO:             IPython: 8.14.0
2024-07-04 13:41:50,229:INFO:          ipywidgets: 8.0.6
2024-07-04 13:41:50,229:INFO:                tqdm: 4.65.0
2024-07-04 13:41:50,229:INFO:               numpy: 1.24.3
2024-07-04 13:41:50,229:INFO:              pandas: 2.1.4
2024-07-04 13:41:50,229:INFO:              jinja2: 3.1.2
2024-07-04 13:41:50,229:INFO:               scipy: 1.10.1
2024-07-04 13:41:50,229:INFO:              joblib: 1.3.2
2024-07-04 13:41:50,229:INFO:             sklearn: 1.4.2
2024-07-04 13:41:50,229:INFO:                pyod: 2.0.1
2024-07-04 13:41:50,229:INFO:            imblearn: 0.12.3
2024-07-04 13:41:50,229:INFO:   category_encoders: 2.6.3
2024-07-04 13:41:50,229:INFO:            lightgbm: 4.4.0
2024-07-04 13:41:50,229:INFO:               numba: 0.57.1
2024-07-04 13:41:50,229:INFO:            requests: 2.31.0
2024-07-04 13:41:50,229:INFO:          matplotlib: 3.7.5
2024-07-04 13:41:50,229:INFO:          scikitplot: 0.3.7
2024-07-04 13:41:50,229:INFO:         yellowbrick: 1.5
2024-07-04 13:41:50,229:INFO:              plotly: 5.15.0
2024-07-04 13:41:50,229:INFO:    plotly-resampler: Not installed
2024-07-04 13:41:50,229:INFO:             kaleido: 0.2.1
2024-07-04 13:41:50,229:INFO:           schemdraw: 0.15
2024-07-04 13:41:50,229:INFO:         statsmodels: 0.14.2
2024-07-04 13:41:50,229:INFO:              sktime: 0.26.0
2024-07-04 13:41:50,229:INFO:               tbats: 1.1.3
2024-07-04 13:41:50,229:INFO:            pmdarima: 2.0.4
2024-07-04 13:41:50,229:INFO:              psutil: 5.9.5
2024-07-04 13:41:50,229:INFO:          markupsafe: 2.1.3
2024-07-04 13:41:50,229:INFO:             pickle5: Not installed
2024-07-04 13:41:50,229:INFO:         cloudpickle: 3.0.0
2024-07-04 13:41:50,229:INFO:         deprecation: 2.1.0
2024-07-04 13:41:50,229:INFO:              xxhash: 3.4.1
2024-07-04 13:41:50,229:INFO:           wurlitzer: Not installed
2024-07-04 13:41:50,229:INFO:PyCaret optional dependencies:
2024-07-04 13:41:50,244:INFO:                shap: 0.45.1
2024-07-04 13:41:50,244:INFO:           interpret: Not installed
2024-07-04 13:41:50,244:INFO:                umap: Not installed
2024-07-04 13:41:50,244:INFO:     ydata_profiling: 4.8.3
2024-07-04 13:41:50,244:INFO:  explainerdashboard: Not installed
2024-07-04 13:41:50,244:INFO:             autoviz: Not installed
2024-07-04 13:41:50,244:INFO:           fairlearn: Not installed
2024-07-04 13:41:50,244:INFO:          deepchecks: Not installed
2024-07-04 13:41:50,244:INFO:             xgboost: Not installed
2024-07-04 13:41:50,244:INFO:            catboost: Not installed
2024-07-04 13:41:50,244:INFO:              kmodes: Not installed
2024-07-04 13:41:50,244:INFO:             mlxtend: Not installed
2024-07-04 13:41:50,244:INFO:       statsforecast: Not installed
2024-07-04 13:41:50,244:INFO:        tune_sklearn: Not installed
2024-07-04 13:41:50,244:INFO:                 ray: Not installed
2024-07-04 13:41:50,244:INFO:            hyperopt: Not installed
2024-07-04 13:41:50,244:INFO:              optuna: 3.2.0
2024-07-04 13:41:50,244:INFO:               skopt: 0.10.2
2024-07-04 13:41:50,244:INFO:              mlflow: Not installed
2024-07-04 13:41:50,244:INFO:              gradio: Not installed
2024-07-04 13:41:50,244:INFO:             fastapi: Not installed
2024-07-04 13:41:50,244:INFO:             uvicorn: Not installed
2024-07-04 13:41:50,244:INFO:              m2cgen: Not installed
2024-07-04 13:41:50,244:INFO:           evidently: Not installed
2024-07-04 13:41:50,244:INFO:               fugue: Not installed
2024-07-04 13:41:50,244:INFO:           streamlit: 1.36.0
2024-07-04 13:41:50,244:INFO:             prophet: Not installed
2024-07-04 13:41:50,244:INFO:None
2024-07-04 13:41:50,244:INFO:Set up data.
2024-07-04 13:41:50,244:INFO:Set up folding strategy.
2024-07-04 13:41:50,244:INFO:Set up train/test split.
2024-07-04 13:41:50,259:INFO:Set up index.
2024-07-04 13:41:50,259:INFO:Assigning column types.
2024-07-04 13:41:50,259:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-04 13:41:50,307:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-04 13:41:50,322:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-04 13:41:50,354:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:41:50,354:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:41:50,401:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-04 13:41:50,401:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-04 13:41:50,433:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:41:50,433:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:41:50,433:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-04 13:41:50,488:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-04 13:41:50,511:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:41:50,511:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:41:50,559:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-04 13:41:50,590:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:41:50,590:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:41:50,590:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-04 13:41:50,670:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:41:50,670:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:41:50,748:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:41:50,748:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:41:50,748:INFO:Preparing preprocessing pipeline...
2024-07-04 13:41:50,748:INFO:Set up simple imputation.
2024-07-04 13:41:50,748:INFO:Set up encoding of ordinal features.
2024-07-04 13:41:50,748:INFO:Set up encoding of categorical features.
2024-07-04 13:41:50,748:INFO:Set up imbalanced handling.
2024-07-04 13:41:50,748:INFO:Set up feature normalization.
2024-07-04 13:41:50,748:INFO:Set up feature selection.
2024-07-04 13:41:50,840:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:41:50,840:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:41:51,648:INFO:Finished creating preprocessing pipeline.
2024-07-04 13:41:51,710:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\PHYOSA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['customer_id', 'credit_score',
                                             'age', 'tenure', 'balance',
                                             'products_number', 'credit_card',
                                             'active_member',
                                             'estimated_salary', 'churn_x'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=N...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=2,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2024-07-04 13:41:51,711:INFO:Creating final display dataframe.
2024-07-04 13:41:52,310:INFO:Setup _display_container:                     Description             Value
0                    Session id              5090
1                        Target           churn_y
2                   Target type            Binary
3           Original data shape       (10000, 13)
4        Transformed data shape        (14148, 3)
5   Transformed train set shape        (11148, 3)
6    Transformed test set shape         (3000, 3)
7              Numeric features                10
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation            median
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17                    Normalize              True
18             Normalize method            robust
19            Feature selection              True
20     Feature selection method           classic
21  Feature selection estimator          lightgbm
22  Number of features selected               0.2
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              6dc8
2024-07-04 13:41:52,483:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:41:52,483:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:41:52,578:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:41:52,578:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:41:52,578:INFO:setup() successfully completed in 2.55s...............
2024-07-04 13:41:52,591:INFO:Initializing compare_models()
2024-07-04 13:41:52,591:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A52425210>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000017A52425210>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-07-04 13:41:52,591:INFO:Checking exceptions
2024-07-04 13:41:52,596:INFO:Preparing display monitor
2024-07-04 13:41:52,596:INFO:Initializing Logistic Regression
2024-07-04 13:41:52,596:INFO:Total runtime is 0.0 minutes
2024-07-04 13:41:52,596:INFO:SubProcess create_model() called ==================================
2024-07-04 13:41:52,596:INFO:Initializing create_model()
2024-07-04 13:41:52,596:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A52425210>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A60E8D890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:41:52,596:INFO:Checking exceptions
2024-07-04 13:41:52,596:INFO:Importing libraries
2024-07-04 13:41:52,596:INFO:Copying training dataset
2024-07-04 13:41:52,614:INFO:Defining folds
2024-07-04 13:41:52,614:INFO:Declaring metric variables
2024-07-04 13:41:52,614:INFO:Importing untrained model
2024-07-04 13:41:52,615:INFO:Logistic Regression Imported successfully
2024-07-04 13:41:52,616:INFO:Starting cross validation
2024-07-04 13:41:52,623:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:42:10,173:INFO:Calculating mean and std
2024-07-04 13:42:10,173:INFO:Creating metrics dataframe
2024-07-04 13:42:10,181:INFO:Uploading results into container
2024-07-04 13:42:10,183:INFO:Uploading model into container now
2024-07-04 13:42:10,183:INFO:_master_model_container: 1
2024-07-04 13:42:10,183:INFO:_display_container: 2
2024-07-04 13:42:10,183:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5090, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-04 13:42:10,183:INFO:create_model() successfully completed......................................
2024-07-04 13:42:10,396:INFO:SubProcess create_model() end ==================================
2024-07-04 13:42:10,396:INFO:Creating metrics dataframe
2024-07-04 13:42:10,397:INFO:Initializing K Neighbors Classifier
2024-07-04 13:42:10,397:INFO:Total runtime is 0.29667840003967283 minutes
2024-07-04 13:42:10,397:INFO:SubProcess create_model() called ==================================
2024-07-04 13:42:10,397:INFO:Initializing create_model()
2024-07-04 13:42:10,397:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A52425210>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A60E8D890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:42:10,397:INFO:Checking exceptions
2024-07-04 13:42:10,397:INFO:Importing libraries
2024-07-04 13:42:10,397:INFO:Copying training dataset
2024-07-04 13:42:10,417:INFO:Defining folds
2024-07-04 13:42:10,417:INFO:Declaring metric variables
2024-07-04 13:42:10,418:INFO:Importing untrained model
2024-07-04 13:42:10,418:INFO:K Neighbors Classifier Imported successfully
2024-07-04 13:42:10,419:INFO:Starting cross validation
2024-07-04 13:42:10,429:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:42:12,750:INFO:Calculating mean and std
2024-07-04 13:42:12,750:INFO:Creating metrics dataframe
2024-07-04 13:42:12,750:INFO:Uploading results into container
2024-07-04 13:42:12,750:INFO:Uploading model into container now
2024-07-04 13:42:12,755:INFO:_master_model_container: 2
2024-07-04 13:42:12,755:INFO:_display_container: 2
2024-07-04 13:42:12,755:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-04 13:42:12,755:INFO:create_model() successfully completed......................................
2024-07-04 13:42:12,916:INFO:SubProcess create_model() end ==================================
2024-07-04 13:42:12,916:INFO:Creating metrics dataframe
2024-07-04 13:42:12,919:INFO:Initializing Naive Bayes
2024-07-04 13:42:12,919:INFO:Total runtime is 0.33870766957600906 minutes
2024-07-04 13:42:12,919:INFO:SubProcess create_model() called ==================================
2024-07-04 13:42:12,920:INFO:Initializing create_model()
2024-07-04 13:42:12,920:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A52425210>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A60E8D890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:42:12,920:INFO:Checking exceptions
2024-07-04 13:42:12,920:INFO:Importing libraries
2024-07-04 13:42:12,920:INFO:Copying training dataset
2024-07-04 13:42:12,929:INFO:Defining folds
2024-07-04 13:42:12,929:INFO:Declaring metric variables
2024-07-04 13:42:12,929:INFO:Importing untrained model
2024-07-04 13:42:12,929:INFO:Naive Bayes Imported successfully
2024-07-04 13:42:12,929:INFO:Starting cross validation
2024-07-04 13:42:12,944:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:42:15,109:INFO:Calculating mean and std
2024-07-04 13:42:15,109:INFO:Creating metrics dataframe
2024-07-04 13:42:15,109:INFO:Uploading results into container
2024-07-04 13:42:15,109:INFO:Uploading model into container now
2024-07-04 13:42:15,109:INFO:_master_model_container: 3
2024-07-04 13:42:15,109:INFO:_display_container: 2
2024-07-04 13:42:15,109:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-04 13:42:15,109:INFO:create_model() successfully completed......................................
2024-07-04 13:42:15,255:INFO:SubProcess create_model() end ==================================
2024-07-04 13:42:15,255:INFO:Creating metrics dataframe
2024-07-04 13:42:15,270:INFO:Initializing Decision Tree Classifier
2024-07-04 13:42:15,270:INFO:Total runtime is 0.377888532479604 minutes
2024-07-04 13:42:15,271:INFO:SubProcess create_model() called ==================================
2024-07-04 13:42:15,272:INFO:Initializing create_model()
2024-07-04 13:42:15,272:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A52425210>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A60E8D890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:42:15,272:INFO:Checking exceptions
2024-07-04 13:42:15,272:INFO:Importing libraries
2024-07-04 13:42:15,272:INFO:Copying training dataset
2024-07-04 13:42:15,272:INFO:Defining folds
2024-07-04 13:42:15,272:INFO:Declaring metric variables
2024-07-04 13:42:15,272:INFO:Importing untrained model
2024-07-04 13:42:15,272:INFO:Decision Tree Classifier Imported successfully
2024-07-04 13:42:15,272:INFO:Starting cross validation
2024-07-04 13:42:15,289:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:42:17,673:INFO:Calculating mean and std
2024-07-04 13:42:17,673:INFO:Creating metrics dataframe
2024-07-04 13:42:17,673:INFO:Uploading results into container
2024-07-04 13:42:17,673:INFO:Uploading model into container now
2024-07-04 13:42:17,673:INFO:_master_model_container: 4
2024-07-04 13:42:17,673:INFO:_display_container: 2
2024-07-04 13:42:17,673:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=5090, splitter='best')
2024-07-04 13:42:17,673:INFO:create_model() successfully completed......................................
2024-07-04 13:42:17,854:INFO:SubProcess create_model() end ==================================
2024-07-04 13:42:17,854:INFO:Creating metrics dataframe
2024-07-04 13:42:17,854:INFO:Initializing SVM - Linear Kernel
2024-07-04 13:42:17,854:INFO:Total runtime is 0.42095723152160636 minutes
2024-07-04 13:42:17,854:INFO:SubProcess create_model() called ==================================
2024-07-04 13:42:17,854:INFO:Initializing create_model()
2024-07-04 13:42:17,854:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A52425210>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A60E8D890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:42:17,854:INFO:Checking exceptions
2024-07-04 13:42:17,854:INFO:Importing libraries
2024-07-04 13:42:17,854:INFO:Copying training dataset
2024-07-04 13:42:17,869:INFO:Defining folds
2024-07-04 13:42:17,869:INFO:Declaring metric variables
2024-07-04 13:42:17,869:INFO:Importing untrained model
2024-07-04 13:42:17,869:INFO:SVM - Linear Kernel Imported successfully
2024-07-04 13:42:17,869:INFO:Starting cross validation
2024-07-04 13:42:17,869:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:42:19,787:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:42:20,351:INFO:Calculating mean and std
2024-07-04 13:42:20,352:INFO:Creating metrics dataframe
2024-07-04 13:42:20,355:INFO:Uploading results into container
2024-07-04 13:42:20,355:INFO:Uploading model into container now
2024-07-04 13:42:20,356:INFO:_master_model_container: 5
2024-07-04 13:42:20,356:INFO:_display_container: 2
2024-07-04 13:42:20,356:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5090, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-04 13:42:20,357:INFO:create_model() successfully completed......................................
2024-07-04 13:42:20,499:INFO:SubProcess create_model() end ==================================
2024-07-04 13:42:20,499:INFO:Creating metrics dataframe
2024-07-04 13:42:20,499:INFO:Initializing Ridge Classifier
2024-07-04 13:42:20,499:INFO:Total runtime is 0.4650434454282124 minutes
2024-07-04 13:42:20,499:INFO:SubProcess create_model() called ==================================
2024-07-04 13:42:20,499:INFO:Initializing create_model()
2024-07-04 13:42:20,499:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A52425210>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A60E8D890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:42:20,514:INFO:Checking exceptions
2024-07-04 13:42:20,514:INFO:Importing libraries
2024-07-04 13:42:20,514:INFO:Copying training dataset
2024-07-04 13:42:20,523:INFO:Defining folds
2024-07-04 13:42:20,523:INFO:Declaring metric variables
2024-07-04 13:42:20,523:INFO:Importing untrained model
2024-07-04 13:42:20,523:INFO:Ridge Classifier Imported successfully
2024-07-04 13:42:20,523:INFO:Starting cross validation
2024-07-04 13:42:20,532:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:42:22,814:INFO:Calculating mean and std
2024-07-04 13:42:22,814:INFO:Creating metrics dataframe
2024-07-04 13:42:22,814:INFO:Uploading results into container
2024-07-04 13:42:22,814:INFO:Uploading model into container now
2024-07-04 13:42:22,814:INFO:_master_model_container: 6
2024-07-04 13:42:22,814:INFO:_display_container: 2
2024-07-04 13:42:22,814:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5090, solver='auto',
                tol=0.0001)
2024-07-04 13:42:22,814:INFO:create_model() successfully completed......................................
2024-07-04 13:42:22,971:INFO:SubProcess create_model() end ==================================
2024-07-04 13:42:22,971:INFO:Creating metrics dataframe
2024-07-04 13:42:22,974:INFO:Initializing Random Forest Classifier
2024-07-04 13:42:22,974:INFO:Total runtime is 0.5062985897064208 minutes
2024-07-04 13:42:22,974:INFO:SubProcess create_model() called ==================================
2024-07-04 13:42:22,974:INFO:Initializing create_model()
2024-07-04 13:42:22,974:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A52425210>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A60E8D890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:42:22,974:INFO:Checking exceptions
2024-07-04 13:42:22,974:INFO:Importing libraries
2024-07-04 13:42:22,974:INFO:Copying training dataset
2024-07-04 13:42:22,980:INFO:Defining folds
2024-07-04 13:42:22,980:INFO:Declaring metric variables
2024-07-04 13:42:22,980:INFO:Importing untrained model
2024-07-04 13:42:22,980:INFO:Random Forest Classifier Imported successfully
2024-07-04 13:42:22,980:INFO:Starting cross validation
2024-07-04 13:42:22,997:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:42:31,107:INFO:Calculating mean and std
2024-07-04 13:42:31,107:INFO:Creating metrics dataframe
2024-07-04 13:42:31,107:INFO:Uploading results into container
2024-07-04 13:42:31,107:INFO:Uploading model into container now
2024-07-04 13:42:31,107:INFO:_master_model_container: 7
2024-07-04 13:42:31,107:INFO:_display_container: 2
2024-07-04 13:42:31,107:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=5090, verbose=0,
                       warm_start=False)
2024-07-04 13:42:31,107:INFO:create_model() successfully completed......................................
2024-07-04 13:42:31,389:INFO:SubProcess create_model() end ==================================
2024-07-04 13:42:31,389:INFO:Creating metrics dataframe
2024-07-04 13:42:31,389:INFO:Initializing Quadratic Discriminant Analysis
2024-07-04 13:42:31,389:INFO:Total runtime is 0.6465484023094177 minutes
2024-07-04 13:42:31,403:INFO:SubProcess create_model() called ==================================
2024-07-04 13:42:31,405:INFO:Initializing create_model()
2024-07-04 13:42:31,405:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A52425210>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A60E8D890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:42:31,405:INFO:Checking exceptions
2024-07-04 13:42:31,405:INFO:Importing libraries
2024-07-04 13:42:31,406:INFO:Copying training dataset
2024-07-04 13:42:31,423:INFO:Defining folds
2024-07-04 13:42:31,423:INFO:Declaring metric variables
2024-07-04 13:42:31,423:INFO:Importing untrained model
2024-07-04 13:42:31,423:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-04 13:42:31,423:INFO:Starting cross validation
2024-07-04 13:42:31,443:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:42:32,713:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 13:42:32,724:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 13:42:32,809:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 13:42:32,847:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:42:32,847:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:42:32,849:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:42:32,849:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:42:32,849:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:42:32,851:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:42:32,856:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:42:32,856:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:42:32,857:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:42:32,863:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:42:32,863:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:42:32,864:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:42:32,877:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 13:42:32,882:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 13:42:32,965:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:42:32,975:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:42:33,007:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:42:33,007:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:42:33,007:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:42:33,007:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 13:42:33,007:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:42:33,007:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:42:33,042:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:42:33,054:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 13:42:33,069:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:42:33,141:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:42:33,141:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:42:33,141:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:42:33,154:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:42:33,154:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:42:33,154:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:42:33,172:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 13:42:33,188:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:42:33,332:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 13:42:33,410:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:42:33,410:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:42:33,410:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:42:33,421:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:42:33,421:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:42:33,421:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:42:33,441:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 13:42:33,458:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:42:33,805:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 13:42:33,876:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:42:33,876:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:42:33,876:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:42:33,876:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:42:33,876:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:42:33,876:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:42:33,886:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 13:42:33,886:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:42:33,917:INFO:Calculating mean and std
2024-07-04 13:42:33,917:INFO:Creating metrics dataframe
2024-07-04 13:42:33,917:INFO:Uploading results into container
2024-07-04 13:42:33,917:INFO:Uploading model into container now
2024-07-04 13:42:33,917:INFO:_master_model_container: 8
2024-07-04 13:42:33,917:INFO:_display_container: 2
2024-07-04 13:42:33,917:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-04 13:42:33,917:INFO:create_model() successfully completed......................................
2024-07-04 13:42:34,177:INFO:SubProcess create_model() end ==================================
2024-07-04 13:42:34,177:INFO:Creating metrics dataframe
2024-07-04 13:42:34,177:INFO:Initializing Ada Boost Classifier
2024-07-04 13:42:34,177:INFO:Total runtime is 0.6930083155632019 minutes
2024-07-04 13:42:34,177:INFO:SubProcess create_model() called ==================================
2024-07-04 13:42:34,177:INFO:Initializing create_model()
2024-07-04 13:42:34,177:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A52425210>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A60E8D890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:42:34,177:INFO:Checking exceptions
2024-07-04 13:42:34,177:INFO:Importing libraries
2024-07-04 13:42:34,177:INFO:Copying training dataset
2024-07-04 13:42:34,209:INFO:Defining folds
2024-07-04 13:42:34,209:INFO:Declaring metric variables
2024-07-04 13:42:34,209:INFO:Importing untrained model
2024-07-04 13:42:34,209:INFO:Ada Boost Classifier Imported successfully
2024-07-04 13:42:34,209:INFO:Starting cross validation
2024-07-04 13:42:34,224:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:42:35,765:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:42:35,798:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:42:35,812:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:42:35,840:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:42:36,040:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:42:36,270:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:42:36,357:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:42:36,502:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:42:37,175:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:42:37,343:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:42:38,506:INFO:Calculating mean and std
2024-07-04 13:42:38,507:INFO:Creating metrics dataframe
2024-07-04 13:42:38,510:INFO:Uploading results into container
2024-07-04 13:42:38,511:INFO:Uploading model into container now
2024-07-04 13:42:38,513:INFO:_master_model_container: 9
2024-07-04 13:42:38,513:INFO:_display_container: 2
2024-07-04 13:42:38,514:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5090)
2024-07-04 13:42:38,514:INFO:create_model() successfully completed......................................
2024-07-04 13:42:38,749:INFO:SubProcess create_model() end ==================================
2024-07-04 13:42:38,749:INFO:Creating metrics dataframe
2024-07-04 13:42:38,749:INFO:Initializing Gradient Boosting Classifier
2024-07-04 13:42:38,749:INFO:Total runtime is 0.7692026694615681 minutes
2024-07-04 13:42:38,749:INFO:SubProcess create_model() called ==================================
2024-07-04 13:42:38,762:INFO:Initializing create_model()
2024-07-04 13:42:38,762:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A52425210>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A60E8D890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:42:38,762:INFO:Checking exceptions
2024-07-04 13:42:38,762:INFO:Importing libraries
2024-07-04 13:42:38,762:INFO:Copying training dataset
2024-07-04 13:42:38,781:INFO:Defining folds
2024-07-04 13:42:38,781:INFO:Declaring metric variables
2024-07-04 13:42:38,781:INFO:Importing untrained model
2024-07-04 13:42:38,781:INFO:Gradient Boosting Classifier Imported successfully
2024-07-04 13:42:38,781:INFO:Starting cross validation
2024-07-04 13:42:38,795:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:42:45,594:INFO:Calculating mean and std
2024-07-04 13:42:45,594:INFO:Creating metrics dataframe
2024-07-04 13:42:45,594:INFO:Uploading results into container
2024-07-04 13:42:45,594:INFO:Uploading model into container now
2024-07-04 13:42:45,594:INFO:_master_model_container: 10
2024-07-04 13:42:45,594:INFO:_display_container: 2
2024-07-04 13:42:45,594:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5090, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-04 13:42:45,594:INFO:create_model() successfully completed......................................
2024-07-04 13:42:45,773:INFO:SubProcess create_model() end ==================================
2024-07-04 13:42:45,773:INFO:Creating metrics dataframe
2024-07-04 13:42:45,773:INFO:Initializing Linear Discriminant Analysis
2024-07-04 13:42:45,773:INFO:Total runtime is 0.8862769762674967 minutes
2024-07-04 13:42:45,773:INFO:SubProcess create_model() called ==================================
2024-07-04 13:42:45,773:INFO:Initializing create_model()
2024-07-04 13:42:45,773:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A52425210>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A60E8D890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:42:45,773:INFO:Checking exceptions
2024-07-04 13:42:45,773:INFO:Importing libraries
2024-07-04 13:42:45,773:INFO:Copying training dataset
2024-07-04 13:42:45,786:INFO:Defining folds
2024-07-04 13:42:45,786:INFO:Declaring metric variables
2024-07-04 13:42:45,788:INFO:Importing untrained model
2024-07-04 13:42:45,789:INFO:Linear Discriminant Analysis Imported successfully
2024-07-04 13:42:45,789:INFO:Starting cross validation
2024-07-04 13:42:45,789:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:42:48,646:INFO:Calculating mean and std
2024-07-04 13:42:48,646:INFO:Creating metrics dataframe
2024-07-04 13:42:48,649:INFO:Uploading results into container
2024-07-04 13:42:48,652:INFO:Uploading model into container now
2024-07-04 13:42:48,652:INFO:_master_model_container: 11
2024-07-04 13:42:48,652:INFO:_display_container: 2
2024-07-04 13:42:48,652:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-04 13:42:48,652:INFO:create_model() successfully completed......................................
2024-07-04 13:42:48,811:INFO:SubProcess create_model() end ==================================
2024-07-04 13:42:48,811:INFO:Creating metrics dataframe
2024-07-04 13:42:48,814:INFO:Initializing Extra Trees Classifier
2024-07-04 13:42:48,815:INFO:Total runtime is 0.936980132261912 minutes
2024-07-04 13:42:48,815:INFO:SubProcess create_model() called ==================================
2024-07-04 13:42:48,815:INFO:Initializing create_model()
2024-07-04 13:42:48,815:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A52425210>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A60E8D890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:42:48,815:INFO:Checking exceptions
2024-07-04 13:42:48,815:INFO:Importing libraries
2024-07-04 13:42:48,815:INFO:Copying training dataset
2024-07-04 13:42:48,827:INFO:Defining folds
2024-07-04 13:42:48,827:INFO:Declaring metric variables
2024-07-04 13:42:48,828:INFO:Importing untrained model
2024-07-04 13:42:48,828:INFO:Extra Trees Classifier Imported successfully
2024-07-04 13:42:48,828:INFO:Starting cross validation
2024-07-04 13:42:48,838:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:42:53,291:INFO:Calculating mean and std
2024-07-04 13:42:53,291:INFO:Creating metrics dataframe
2024-07-04 13:42:53,296:INFO:Uploading results into container
2024-07-04 13:42:53,296:INFO:Uploading model into container now
2024-07-04 13:42:53,301:INFO:_master_model_container: 12
2024-07-04 13:42:53,301:INFO:_display_container: 2
2024-07-04 13:42:53,301:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=5090, verbose=0,
                     warm_start=False)
2024-07-04 13:42:53,301:INFO:create_model() successfully completed......................................
2024-07-04 13:42:53,486:INFO:SubProcess create_model() end ==================================
2024-07-04 13:42:53,486:INFO:Creating metrics dataframe
2024-07-04 13:42:53,490:INFO:Initializing Light Gradient Boosting Machine
2024-07-04 13:42:53,490:INFO:Total runtime is 1.0148869117101034 minutes
2024-07-04 13:42:53,490:INFO:SubProcess create_model() called ==================================
2024-07-04 13:42:53,490:INFO:Initializing create_model()
2024-07-04 13:42:53,491:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A52425210>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A60E8D890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:42:53,491:INFO:Checking exceptions
2024-07-04 13:42:53,491:INFO:Importing libraries
2024-07-04 13:42:53,491:INFO:Copying training dataset
2024-07-04 13:42:53,500:INFO:Defining folds
2024-07-04 13:42:53,500:INFO:Declaring metric variables
2024-07-04 13:42:53,500:INFO:Importing untrained model
2024-07-04 13:42:53,500:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-04 13:42:53,500:INFO:Starting cross validation
2024-07-04 13:42:53,500:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:42:57,360:INFO:Calculating mean and std
2024-07-04 13:42:57,362:INFO:Creating metrics dataframe
2024-07-04 13:42:57,365:INFO:Uploading results into container
2024-07-04 13:42:57,365:INFO:Uploading model into container now
2024-07-04 13:42:57,365:INFO:_master_model_container: 13
2024-07-04 13:42:57,365:INFO:_display_container: 2
2024-07-04 13:42:57,365:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5090, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-04 13:42:57,365:INFO:create_model() successfully completed......................................
2024-07-04 13:42:57,595:INFO:SubProcess create_model() end ==================================
2024-07-04 13:42:57,595:INFO:Creating metrics dataframe
2024-07-04 13:42:57,607:INFO:Initializing Dummy Classifier
2024-07-04 13:42:57,609:INFO:Total runtime is 1.0835448225339255 minutes
2024-07-04 13:42:57,611:INFO:SubProcess create_model() called ==================================
2024-07-04 13:42:57,612:INFO:Initializing create_model()
2024-07-04 13:42:57,612:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A52425210>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A60E8D890>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:42:57,612:INFO:Checking exceptions
2024-07-04 13:42:57,612:INFO:Importing libraries
2024-07-04 13:42:57,612:INFO:Copying training dataset
2024-07-04 13:42:57,625:INFO:Defining folds
2024-07-04 13:42:57,625:INFO:Declaring metric variables
2024-07-04 13:42:57,626:INFO:Importing untrained model
2024-07-04 13:42:57,627:INFO:Dummy Classifier Imported successfully
2024-07-04 13:42:57,629:INFO:Starting cross validation
2024-07-04 13:42:57,635:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:42:59,271:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:42:59,283:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:42:59,376:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:42:59,396:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:42:59,544:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:42:59,564:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:42:59,720:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:42:59,723:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:43:00,044:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:43:00,047:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:43:00,071:INFO:Calculating mean and std
2024-07-04 13:43:00,074:INFO:Creating metrics dataframe
2024-07-04 13:43:00,074:INFO:Uploading results into container
2024-07-04 13:43:00,074:INFO:Uploading model into container now
2024-07-04 13:43:00,074:INFO:_master_model_container: 14
2024-07-04 13:43:00,074:INFO:_display_container: 2
2024-07-04 13:43:00,074:INFO:DummyClassifier(constant=None, random_state=5090, strategy='prior')
2024-07-04 13:43:00,074:INFO:create_model() successfully completed......................................
2024-07-04 13:43:00,289:INFO:SubProcess create_model() end ==================================
2024-07-04 13:43:00,290:INFO:Creating metrics dataframe
2024-07-04 13:43:00,299:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-07-04 13:43:00,302:INFO:Initializing create_model()
2024-07-04 13:43:00,302:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A52425210>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5090, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:43:00,302:INFO:Checking exceptions
2024-07-04 13:43:00,304:INFO:Importing libraries
2024-07-04 13:43:00,305:INFO:Copying training dataset
2024-07-04 13:43:00,314:INFO:Defining folds
2024-07-04 13:43:00,314:INFO:Declaring metric variables
2024-07-04 13:43:00,314:INFO:Importing untrained model
2024-07-04 13:43:00,314:INFO:Declaring custom model
2024-07-04 13:43:00,315:INFO:SVM - Linear Kernel Imported successfully
2024-07-04 13:43:00,322:INFO:Cross validation set to False
2024-07-04 13:43:00,322:INFO:Fitting Model
2024-07-04 13:43:00,517:INFO:[LightGBM] [Info] Number of positive: 5574, number of negative: 5574
2024-07-04 13:43:00,518:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000945 seconds.
2024-07-04 13:43:00,518:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-04 13:43:00,518:INFO:[LightGBM] [Info] Total Bins 3318
2024-07-04 13:43:00,518:INFO:[LightGBM] [Info] Number of data points in the train set: 11148, number of used features: 14
2024-07-04 13:43:00,520:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-07-04 13:43:00,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:00,622:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5090, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-04 13:43:00,622:INFO:create_model() successfully completed......................................
2024-07-04 13:43:00,783:INFO:_master_model_container: 14
2024-07-04 13:43:00,783:INFO:_display_container: 2
2024-07-04 13:43:00,785:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5090, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-04 13:43:00,785:INFO:compare_models() successfully completed......................................
2024-07-04 13:43:00,796:INFO:Initializing tune_model()
2024-07-04 13:43:00,796:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A52425210>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5090, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=bayesian, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-04 13:43:00,796:INFO:Checking exceptions
2024-07-04 13:43:00,796:INFO:Soft dependency imported: skopt: 0.10.2
2024-07-04 13:43:00,863:INFO:Copying training dataset
2024-07-04 13:43:00,868:INFO:Checking base model
2024-07-04 13:43:00,868:INFO:Base model : SVM - Linear Kernel
2024-07-04 13:43:00,868:INFO:Declaring metric variables
2024-07-04 13:43:00,868:INFO:Defining Hyperparameters
2024-07-04 13:43:01,050:INFO:Tuning with n_jobs=-1
2024-07-04 13:43:01,058:INFO:Initializing skopt.BayesSearchCV
2024-07-04 13:43:23,610:INFO:best_params: OrderedDict([('actual_estimator__alpha', 3.250029917915847e-09), ('actual_estimator__eta0', 0.0345163503135231), ('actual_estimator__fit_intercept', True), ('actual_estimator__l1_ratio', 0.2281443010253207), ('actual_estimator__learning_rate', 'invscaling'), ('actual_estimator__penalty', 'l2')])
2024-07-04 13:43:23,610:INFO:Hyperparameter search completed
2024-07-04 13:43:23,610:INFO:SubProcess create_model() called ==================================
2024-07-04 13:43:23,611:INFO:Initializing create_model()
2024-07-04 13:43:23,611:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A52425210>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5090, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A6149BA90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'alpha': 3.250029917915847e-09, 'eta0': 0.0345163503135231, 'fit_intercept': True, 'l1_ratio': 0.2281443010253207, 'learning_rate': 'invscaling', 'penalty': 'l2'})
2024-07-04 13:43:23,612:INFO:Checking exceptions
2024-07-04 13:43:23,612:INFO:Importing libraries
2024-07-04 13:43:23,612:INFO:Copying training dataset
2024-07-04 13:43:23,621:INFO:Defining folds
2024-07-04 13:43:23,621:INFO:Declaring metric variables
2024-07-04 13:43:23,621:INFO:Importing untrained model
2024-07-04 13:43:23,621:INFO:Declaring custom model
2024-07-04 13:43:23,622:INFO:SVM - Linear Kernel Imported successfully
2024-07-04 13:43:23,622:INFO:Starting cross validation
2024-07-04 13:43:23,631:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:43:25,920:INFO:Calculating mean and std
2024-07-04 13:43:25,921:INFO:Creating metrics dataframe
2024-07-04 13:43:25,923:INFO:Finalizing model
2024-07-04 13:43:26,107:INFO:[LightGBM] [Info] Number of positive: 5574, number of negative: 5574
2024-07-04 13:43:26,109:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001372 seconds.
2024-07-04 13:43:26,109:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-04 13:43:26,110:INFO:[LightGBM] [Info] Total Bins 3318
2024-07-04 13:43:26,110:INFO:[LightGBM] [Info] Number of data points in the train set: 11148, number of used features: 14
2024-07-04 13:43:26,110:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-07-04 13:43:26,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:26,202:INFO:Uploading results into container
2024-07-04 13:43:26,203:INFO:Uploading model into container now
2024-07-04 13:43:26,204:INFO:_master_model_container: 15
2024-07-04 13:43:26,204:INFO:_display_container: 3
2024-07-04 13:43:26,205:INFO:SGDClassifier(alpha=3.250029917915847e-09, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.0345163503135231,
              fit_intercept=True, l1_ratio=0.2281443010253207,
              learning_rate='invscaling', loss='hinge', max_iter=1000,
              n_iter_no_change=5, n_jobs=-1, penalty='l2', power_t=0.5,
              random_state=5090, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-04 13:43:26,205:INFO:create_model() successfully completed......................................
2024-07-04 13:43:26,357:INFO:SubProcess create_model() end ==================================
2024-07-04 13:43:26,357:INFO:choose_better activated
2024-07-04 13:43:26,358:INFO:SubProcess create_model() called ==================================
2024-07-04 13:43:26,359:INFO:Initializing create_model()
2024-07-04 13:43:26,359:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A52425210>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5090, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:43:26,359:INFO:Checking exceptions
2024-07-04 13:43:26,360:INFO:Importing libraries
2024-07-04 13:43:26,361:INFO:Copying training dataset
2024-07-04 13:43:26,368:INFO:Defining folds
2024-07-04 13:43:26,368:INFO:Declaring metric variables
2024-07-04 13:43:26,369:INFO:Importing untrained model
2024-07-04 13:43:26,369:INFO:Declaring custom model
2024-07-04 13:43:26,370:INFO:SVM - Linear Kernel Imported successfully
2024-07-04 13:43:26,370:INFO:Starting cross validation
2024-07-04 13:43:26,376:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:43:28,692:INFO:Calculating mean and std
2024-07-04 13:43:28,692:INFO:Creating metrics dataframe
2024-07-04 13:43:28,692:INFO:Finalizing model
2024-07-04 13:43:28,857:INFO:[LightGBM] [Info] Number of positive: 5574, number of negative: 5574
2024-07-04 13:43:28,857:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000964 seconds.
2024-07-04 13:43:28,857:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-04 13:43:28,857:INFO:[LightGBM] [Info] Total Bins 3318
2024-07-04 13:43:28,857:INFO:[LightGBM] [Info] Number of data points in the train set: 11148, number of used features: 14
2024-07-04 13:43:28,857:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-07-04 13:43:28,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 13:43:28,959:INFO:Uploading results into container
2024-07-04 13:43:28,959:INFO:Uploading model into container now
2024-07-04 13:43:28,959:INFO:_master_model_container: 16
2024-07-04 13:43:28,959:INFO:_display_container: 4
2024-07-04 13:43:28,959:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5090, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-04 13:43:28,959:INFO:create_model() successfully completed......................................
2024-07-04 13:43:29,102:INFO:SubProcess create_model() end ==================================
2024-07-04 13:43:29,102:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5090, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False) result for Accuracy is 0.7051
2024-07-04 13:43:29,102:INFO:SGDClassifier(alpha=3.250029917915847e-09, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.0345163503135231,
              fit_intercept=True, l1_ratio=0.2281443010253207,
              learning_rate='invscaling', loss='hinge', max_iter=1000,
              n_iter_no_change=5, n_jobs=-1, penalty='l2', power_t=0.5,
              random_state=5090, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False) result for Accuracy is 0.8151
2024-07-04 13:43:29,102:INFO:SGDClassifier(alpha=3.250029917915847e-09, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.0345163503135231,
              fit_intercept=True, l1_ratio=0.2281443010253207,
              learning_rate='invscaling', loss='hinge', max_iter=1000,
              n_iter_no_change=5, n_jobs=-1, penalty='l2', power_t=0.5,
              random_state=5090, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False) is best model
2024-07-04 13:43:29,102:INFO:choose_better completed
2024-07-04 13:43:29,134:INFO:_master_model_container: 16
2024-07-04 13:43:29,134:INFO:_display_container: 3
2024-07-04 13:43:29,134:INFO:SGDClassifier(alpha=3.250029917915847e-09, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.0345163503135231,
              fit_intercept=True, l1_ratio=0.2281443010253207,
              learning_rate='invscaling', loss='hinge', max_iter=1000,
              n_iter_no_change=5, n_jobs=-1, penalty='l2', power_t=0.5,
              random_state=5090, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-04 13:43:29,134:INFO:tune_model() successfully completed......................................
2024-07-04 13:43:29,273:INFO:Initializing plot_model()
2024-07-04 13:43:29,273:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A52425210>, estimator=SGDClassifier(alpha=3.250029917915847e-09, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.0345163503135231,
              fit_intercept=True, l1_ratio=0.2281443010253207,
              learning_rate='invscaling', loss='hinge', max_iter=1000,
              n_iter_no_change=5, n_jobs=-1, penalty='l2', power_t=0.5,
              random_state=5090, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), plot=class_report, scale=0.75, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2024-07-04 13:43:29,273:INFO:Checking exceptions
2024-07-04 13:43:29,273:INFO:Soft dependency imported: streamlit: 1.36.0
2024-07-04 13:43:29,290:INFO:Preloading libraries
2024-07-04 13:43:29,291:INFO:Copying training dataset
2024-07-04 13:43:29,291:INFO:Plot type: class_report
2024-07-04 13:43:29,607:INFO:Fitting Model
2024-07-04 13:43:29,610:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names
  warnings.warn(

2024-07-04 13:43:29,611:INFO:Scoring test/hold-out set
2024-07-04 13:43:30,012:INFO:Visual Rendered Successfully
2024-07-04 13:43:30,159:INFO:plot_model() successfully completed......................................
2024-07-04 13:43:30,159:INFO:Initializing plot_model()
2024-07-04 13:43:30,159:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A52425210>, estimator=SGDClassifier(alpha=3.250029917915847e-09, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.0345163503135231,
              fit_intercept=True, l1_ratio=0.2281443010253207,
              learning_rate='invscaling', loss='hinge', max_iter=1000,
              n_iter_no_change=5, n_jobs=-1, penalty='l2', power_t=0.5,
              random_state=5090, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), plot=confusion_matrix, scale=0.75, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2024-07-04 13:43:30,159:INFO:Checking exceptions
2024-07-04 13:43:30,159:INFO:Soft dependency imported: streamlit: 1.36.0
2024-07-04 13:43:30,163:INFO:Preloading libraries
2024-07-04 13:43:30,163:INFO:Copying training dataset
2024-07-04 13:43:30,163:INFO:Plot type: confusion_matrix
2024-07-04 13:43:30,486:INFO:Fitting Model
2024-07-04 13:43:30,486:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names
  warnings.warn(

2024-07-04 13:43:30,488:INFO:Scoring test/hold-out set
2024-07-04 13:43:30,840:INFO:Visual Rendered Successfully
2024-07-04 13:43:30,966:INFO:plot_model() successfully completed......................................
2024-07-04 13:45:02,436:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'France'')
  warnings.warn(

2024-07-04 13:49:40,959:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'France'')
  warnings.warn(

2024-07-04 13:49:59,006:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'France'')
  warnings.warn(

2024-07-04 13:50:19,025:INFO:PyCaret ClassificationExperiment
2024-07-04 13:50:19,026:INFO:Logging name: clf-default-name
2024-07-04 13:50:19,026:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-04 13:50:19,026:INFO:version 3.3.2
2024-07-04 13:50:19,026:INFO:Initializing setup()
2024-07-04 13:50:19,026:INFO:self.USI: 8a75
2024-07-04 13:50:19,026:INFO:self._variable_keys: {'_available_plots', 'USI', 'exp_name_log', 'n_jobs_param', 'gpu_n_jobs_param', '_ml_usecase', 'log_plots_param', 'seed', 'y', 'target_param', 'fold_groups_param', 'X_train', 'X', 'y_test', 'fold_shuffle_param', 'gpu_param', 'X_test', 'logging_param', 'is_multiclass', 'y_train', 'idx', 'pipeline', 'html_param', 'fold_generator', 'fix_imbalance', 'exp_id', 'data', 'memory'}
2024-07-04 13:50:19,026:INFO:Checking environment
2024-07-04 13:50:19,027:INFO:python_version: 3.11.3
2024-07-04 13:50:19,027:INFO:python_build: ('tags/v3.11.3:f3909b8', 'Apr  4 2023 23:49:59')
2024-07-04 13:50:19,027:INFO:machine: AMD64
2024-07-04 13:50:19,028:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-04 13:50:19,039:INFO:Memory: svmem(total=8179539968, available=1486295040, percent=81.8, used=6693244928, free=1486295040)
2024-07-04 13:50:19,040:INFO:Physical Core: 4
2024-07-04 13:50:19,040:INFO:Logical Core: 8
2024-07-04 13:50:19,040:INFO:Checking libraries
2024-07-04 13:50:19,041:INFO:System:
2024-07-04 13:50:19,041:INFO:    python: 3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]
2024-07-04 13:50:19,041:INFO:executable: C:\Program Files\Python311\python.exe
2024-07-04 13:50:19,041:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-04 13:50:19,042:INFO:PyCaret required dependencies:
2024-07-04 13:50:19,042:INFO:                 pip: 23.1.2
2024-07-04 13:50:19,042:INFO:          setuptools: 67.8.0
2024-07-04 13:50:19,042:INFO:             pycaret: 3.3.2
2024-07-04 13:50:19,042:INFO:             IPython: 8.14.0
2024-07-04 13:50:19,042:INFO:          ipywidgets: 8.0.6
2024-07-04 13:50:19,042:INFO:                tqdm: 4.65.0
2024-07-04 13:50:19,043:INFO:               numpy: 1.24.3
2024-07-04 13:50:19,043:INFO:              pandas: 2.1.4
2024-07-04 13:50:19,043:INFO:              jinja2: 3.1.2
2024-07-04 13:50:19,043:INFO:               scipy: 1.10.1
2024-07-04 13:50:19,044:INFO:              joblib: 1.3.2
2024-07-04 13:50:19,044:INFO:             sklearn: 1.4.2
2024-07-04 13:50:19,044:INFO:                pyod: 2.0.1
2024-07-04 13:50:19,044:INFO:            imblearn: 0.12.3
2024-07-04 13:50:19,044:INFO:   category_encoders: 2.6.3
2024-07-04 13:50:19,045:INFO:            lightgbm: 4.4.0
2024-07-04 13:50:19,045:INFO:               numba: 0.57.1
2024-07-04 13:50:19,045:INFO:            requests: 2.31.0
2024-07-04 13:50:19,045:INFO:          matplotlib: 3.7.5
2024-07-04 13:50:19,045:INFO:          scikitplot: 0.3.7
2024-07-04 13:50:19,046:INFO:         yellowbrick: 1.5
2024-07-04 13:50:19,046:INFO:              plotly: 5.15.0
2024-07-04 13:50:19,046:INFO:    plotly-resampler: Not installed
2024-07-04 13:50:19,046:INFO:             kaleido: 0.2.1
2024-07-04 13:50:19,046:INFO:           schemdraw: 0.15
2024-07-04 13:50:19,046:INFO:         statsmodels: 0.14.2
2024-07-04 13:50:19,046:INFO:              sktime: 0.26.0
2024-07-04 13:50:19,046:INFO:               tbats: 1.1.3
2024-07-04 13:50:19,046:INFO:            pmdarima: 2.0.4
2024-07-04 13:50:19,046:INFO:              psutil: 5.9.5
2024-07-04 13:50:19,046:INFO:          markupsafe: 2.1.3
2024-07-04 13:50:19,048:INFO:             pickle5: Not installed
2024-07-04 13:50:19,048:INFO:         cloudpickle: 3.0.0
2024-07-04 13:50:19,048:INFO:         deprecation: 2.1.0
2024-07-04 13:50:19,048:INFO:              xxhash: 3.4.1
2024-07-04 13:50:19,049:INFO:           wurlitzer: Not installed
2024-07-04 13:50:19,049:INFO:PyCaret optional dependencies:
2024-07-04 13:50:19,049:INFO:                shap: 0.45.1
2024-07-04 13:50:19,050:INFO:           interpret: Not installed
2024-07-04 13:50:19,050:INFO:                umap: Not installed
2024-07-04 13:50:19,050:INFO:     ydata_profiling: 4.8.3
2024-07-04 13:50:19,050:INFO:  explainerdashboard: Not installed
2024-07-04 13:50:19,050:INFO:             autoviz: Not installed
2024-07-04 13:50:19,051:INFO:           fairlearn: Not installed
2024-07-04 13:50:19,051:INFO:          deepchecks: Not installed
2024-07-04 13:50:19,051:INFO:             xgboost: Not installed
2024-07-04 13:50:19,051:INFO:            catboost: Not installed
2024-07-04 13:50:19,051:INFO:              kmodes: Not installed
2024-07-04 13:50:19,051:INFO:             mlxtend: Not installed
2024-07-04 13:50:19,053:INFO:       statsforecast: Not installed
2024-07-04 13:50:19,053:INFO:        tune_sklearn: Not installed
2024-07-04 13:50:19,053:INFO:                 ray: Not installed
2024-07-04 13:50:19,053:INFO:            hyperopt: Not installed
2024-07-04 13:50:19,053:INFO:              optuna: 3.2.0
2024-07-04 13:50:19,053:INFO:               skopt: 0.10.2
2024-07-04 13:50:19,053:INFO:              mlflow: Not installed
2024-07-04 13:50:19,053:INFO:              gradio: Not installed
2024-07-04 13:50:19,054:INFO:             fastapi: Not installed
2024-07-04 13:50:19,054:INFO:             uvicorn: Not installed
2024-07-04 13:50:19,056:INFO:              m2cgen: Not installed
2024-07-04 13:50:19,056:INFO:           evidently: Not installed
2024-07-04 13:50:19,056:INFO:               fugue: Not installed
2024-07-04 13:50:19,057:INFO:           streamlit: 1.36.0
2024-07-04 13:50:19,058:INFO:             prophet: Not installed
2024-07-04 13:50:19,059:INFO:None
2024-07-04 13:50:19,060:INFO:Set up data.
2024-07-04 13:50:19,086:INFO:Set up folding strategy.
2024-07-04 13:50:19,086:INFO:Set up train/test split.
2024-07-04 13:50:19,113:INFO:Set up index.
2024-07-04 13:50:19,114:INFO:Assigning column types.
2024-07-04 13:50:19,124:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-04 13:50:19,206:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-04 13:50:19,206:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-04 13:50:19,272:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:50:19,272:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:50:19,373:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-04 13:50:19,374:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-04 13:50:19,405:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:50:19,405:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:50:19,405:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-04 13:50:19,506:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-04 13:50:19,579:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:50:19,587:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:50:19,649:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-04 13:50:19,699:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:50:19,700:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:50:19,701:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-04 13:50:19,867:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:50:19,868:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:50:20,009:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:50:20,009:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:50:20,012:INFO:Preparing preprocessing pipeline...
2024-07-04 13:50:20,014:INFO:Set up simple imputation.
2024-07-04 13:50:20,020:INFO:Set up encoding of ordinal features.
2024-07-04 13:50:20,025:INFO:Set up encoding of categorical features.
2024-07-04 13:50:20,025:INFO:Set up imbalanced handling.
2024-07-04 13:50:20,025:INFO:Set up feature normalization.
2024-07-04 13:50:20,026:INFO:Set up feature selection.
2024-07-04 13:50:20,173:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:50:20,173:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:50:20,765:INFO:Finished creating preprocessing pipeline.
2024-07-04 13:50:20,807:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\PHYOSA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['customer_id', 'credit_score',
                                             'age', 'tenure', 'balance',
                                             'products_number', 'credit_card',
                                             'active_member',
                                             'estimated_salary', 'churn_x'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=N...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=2,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2024-07-04 13:50:20,807:INFO:Creating final display dataframe.
2024-07-04 13:50:21,326:INFO:Setup _display_container:                     Description             Value
0                    Session id              8306
1                        Target           churn_y
2                   Target type            Binary
3           Original data shape       (10000, 13)
4        Transformed data shape        (14148, 3)
5   Transformed train set shape        (11148, 3)
6    Transformed test set shape         (3000, 3)
7              Numeric features                10
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation            median
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17                    Normalize              True
18             Normalize method            robust
19            Feature selection              True
20     Feature selection method           classic
21  Feature selection estimator          lightgbm
22  Number of features selected               0.2
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              8a75
2024-07-04 13:50:21,444:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:50:21,444:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:50:21,613:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:50:21,615:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 13:50:21,617:INFO:setup() successfully completed in 2.64s...............
2024-07-04 13:50:21,630:INFO:Initializing compare_models()
2024-07-04 13:50:21,631:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A5F38D750>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000017A5F38D750>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-07-04 13:50:21,631:INFO:Checking exceptions
2024-07-04 13:50:21,642:INFO:Preparing display monitor
2024-07-04 13:50:21,647:INFO:Initializing Logistic Regression
2024-07-04 13:50:21,647:INFO:Total runtime is 0.0 minutes
2024-07-04 13:50:21,648:INFO:SubProcess create_model() called ==================================
2024-07-04 13:50:21,648:INFO:Initializing create_model()
2024-07-04 13:50:21,648:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A5F38D750>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A5E2E3ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:50:21,649:INFO:Checking exceptions
2024-07-04 13:50:21,649:INFO:Importing libraries
2024-07-04 13:50:21,649:INFO:Copying training dataset
2024-07-04 13:50:21,661:INFO:Defining folds
2024-07-04 13:50:21,661:INFO:Declaring metric variables
2024-07-04 13:50:21,662:INFO:Importing untrained model
2024-07-04 13:50:21,662:INFO:Logistic Regression Imported successfully
2024-07-04 13:50:21,663:INFO:Starting cross validation
2024-07-04 13:50:21,673:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:50:35,903:INFO:Calculating mean and std
2024-07-04 13:50:35,905:INFO:Creating metrics dataframe
2024-07-04 13:50:35,905:INFO:Uploading results into container
2024-07-04 13:50:35,905:INFO:Uploading model into container now
2024-07-04 13:50:35,905:INFO:_master_model_container: 1
2024-07-04 13:50:35,905:INFO:_display_container: 2
2024-07-04 13:50:35,905:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8306, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-04 13:50:35,905:INFO:create_model() successfully completed......................................
2024-07-04 13:50:36,158:INFO:SubProcess create_model() end ==================================
2024-07-04 13:50:36,158:INFO:Creating metrics dataframe
2024-07-04 13:50:36,158:INFO:Initializing K Neighbors Classifier
2024-07-04 13:50:36,158:INFO:Total runtime is 0.24185463587443035 minutes
2024-07-04 13:50:36,158:INFO:SubProcess create_model() called ==================================
2024-07-04 13:50:36,158:INFO:Initializing create_model()
2024-07-04 13:50:36,158:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A5F38D750>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A5E2E3ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:50:36,158:INFO:Checking exceptions
2024-07-04 13:50:36,158:INFO:Importing libraries
2024-07-04 13:50:36,158:INFO:Copying training dataset
2024-07-04 13:50:36,170:INFO:Defining folds
2024-07-04 13:50:36,170:INFO:Declaring metric variables
2024-07-04 13:50:36,170:INFO:Importing untrained model
2024-07-04 13:50:36,170:INFO:K Neighbors Classifier Imported successfully
2024-07-04 13:50:36,170:INFO:Starting cross validation
2024-07-04 13:50:36,190:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:50:38,580:INFO:Calculating mean and std
2024-07-04 13:50:38,580:INFO:Creating metrics dataframe
2024-07-04 13:50:38,585:INFO:Uploading results into container
2024-07-04 13:50:38,585:INFO:Uploading model into container now
2024-07-04 13:50:38,585:INFO:_master_model_container: 2
2024-07-04 13:50:38,585:INFO:_display_container: 2
2024-07-04 13:50:38,585:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-04 13:50:38,585:INFO:create_model() successfully completed......................................
2024-07-04 13:50:38,800:INFO:SubProcess create_model() end ==================================
2024-07-04 13:50:38,800:INFO:Creating metrics dataframe
2024-07-04 13:50:38,800:INFO:Initializing Naive Bayes
2024-07-04 13:50:38,800:INFO:Total runtime is 0.28588501214981077 minutes
2024-07-04 13:50:38,800:INFO:SubProcess create_model() called ==================================
2024-07-04 13:50:38,800:INFO:Initializing create_model()
2024-07-04 13:50:38,800:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A5F38D750>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A5E2E3ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:50:38,800:INFO:Checking exceptions
2024-07-04 13:50:38,800:INFO:Importing libraries
2024-07-04 13:50:38,800:INFO:Copying training dataset
2024-07-04 13:50:38,818:INFO:Defining folds
2024-07-04 13:50:38,818:INFO:Declaring metric variables
2024-07-04 13:50:38,818:INFO:Importing untrained model
2024-07-04 13:50:38,818:INFO:Naive Bayes Imported successfully
2024-07-04 13:50:38,818:INFO:Starting cross validation
2024-07-04 13:50:38,869:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:50:41,168:INFO:Calculating mean and std
2024-07-04 13:50:41,170:INFO:Creating metrics dataframe
2024-07-04 13:50:41,177:INFO:Uploading results into container
2024-07-04 13:50:41,179:INFO:Uploading model into container now
2024-07-04 13:50:41,181:INFO:_master_model_container: 3
2024-07-04 13:50:41,181:INFO:_display_container: 2
2024-07-04 13:50:41,181:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-04 13:50:41,181:INFO:create_model() successfully completed......................................
2024-07-04 13:50:41,449:INFO:SubProcess create_model() end ==================================
2024-07-04 13:50:41,449:INFO:Creating metrics dataframe
2024-07-04 13:50:41,465:INFO:Initializing Decision Tree Classifier
2024-07-04 13:50:41,465:INFO:Total runtime is 0.3303011655807495 minutes
2024-07-04 13:50:41,465:INFO:SubProcess create_model() called ==================================
2024-07-04 13:50:41,465:INFO:Initializing create_model()
2024-07-04 13:50:41,465:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A5F38D750>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A5E2E3ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:50:41,465:INFO:Checking exceptions
2024-07-04 13:50:41,465:INFO:Importing libraries
2024-07-04 13:50:41,465:INFO:Copying training dataset
2024-07-04 13:50:41,483:INFO:Defining folds
2024-07-04 13:50:41,483:INFO:Declaring metric variables
2024-07-04 13:50:41,483:INFO:Importing untrained model
2024-07-04 13:50:41,483:INFO:Decision Tree Classifier Imported successfully
2024-07-04 13:50:41,483:INFO:Starting cross validation
2024-07-04 13:50:41,499:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:50:44,091:INFO:Calculating mean and std
2024-07-04 13:50:44,094:INFO:Creating metrics dataframe
2024-07-04 13:50:44,096:INFO:Uploading results into container
2024-07-04 13:50:44,096:INFO:Uploading model into container now
2024-07-04 13:50:44,096:INFO:_master_model_container: 4
2024-07-04 13:50:44,096:INFO:_display_container: 2
2024-07-04 13:50:44,096:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8306, splitter='best')
2024-07-04 13:50:44,096:INFO:create_model() successfully completed......................................
2024-07-04 13:50:44,346:INFO:SubProcess create_model() end ==================================
2024-07-04 13:50:44,346:INFO:Creating metrics dataframe
2024-07-04 13:50:44,346:INFO:Initializing SVM - Linear Kernel
2024-07-04 13:50:44,346:INFO:Total runtime is 0.3783260226249695 minutes
2024-07-04 13:50:44,346:INFO:SubProcess create_model() called ==================================
2024-07-04 13:50:44,346:INFO:Initializing create_model()
2024-07-04 13:50:44,346:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A5F38D750>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A5E2E3ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:50:44,346:INFO:Checking exceptions
2024-07-04 13:50:44,346:INFO:Importing libraries
2024-07-04 13:50:44,346:INFO:Copying training dataset
2024-07-04 13:50:44,367:INFO:Defining folds
2024-07-04 13:50:44,367:INFO:Declaring metric variables
2024-07-04 13:50:44,367:INFO:Importing untrained model
2024-07-04 13:50:44,367:INFO:SVM - Linear Kernel Imported successfully
2024-07-04 13:50:44,367:INFO:Starting cross validation
2024-07-04 13:50:44,377:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:50:46,394:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:50:47,057:INFO:Calculating mean and std
2024-07-04 13:50:47,059:INFO:Creating metrics dataframe
2024-07-04 13:50:47,059:INFO:Uploading results into container
2024-07-04 13:50:47,059:INFO:Uploading model into container now
2024-07-04 13:50:47,059:INFO:_master_model_container: 5
2024-07-04 13:50:47,059:INFO:_display_container: 2
2024-07-04 13:50:47,059:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8306, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-04 13:50:47,059:INFO:create_model() successfully completed......................................
2024-07-04 13:50:47,326:INFO:SubProcess create_model() end ==================================
2024-07-04 13:50:47,326:INFO:Creating metrics dataframe
2024-07-04 13:50:47,329:INFO:Initializing Ridge Classifier
2024-07-04 13:50:47,330:INFO:Total runtime is 0.42805432478586836 minutes
2024-07-04 13:50:47,330:INFO:SubProcess create_model() called ==================================
2024-07-04 13:50:47,330:INFO:Initializing create_model()
2024-07-04 13:50:47,330:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A5F38D750>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A5E2E3ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:50:47,330:INFO:Checking exceptions
2024-07-04 13:50:47,330:INFO:Importing libraries
2024-07-04 13:50:47,330:INFO:Copying training dataset
2024-07-04 13:50:47,340:INFO:Defining folds
2024-07-04 13:50:47,341:INFO:Declaring metric variables
2024-07-04 13:50:47,341:INFO:Importing untrained model
2024-07-04 13:50:47,342:INFO:Ridge Classifier Imported successfully
2024-07-04 13:50:47,343:INFO:Starting cross validation
2024-07-04 13:50:47,356:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:50:49,397:INFO:Calculating mean and std
2024-07-04 13:50:49,397:INFO:Creating metrics dataframe
2024-07-04 13:50:49,408:INFO:Uploading results into container
2024-07-04 13:50:49,409:INFO:Uploading model into container now
2024-07-04 13:50:49,411:INFO:_master_model_container: 6
2024-07-04 13:50:49,411:INFO:_display_container: 2
2024-07-04 13:50:49,412:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8306, solver='auto',
                tol=0.0001)
2024-07-04 13:50:49,412:INFO:create_model() successfully completed......................................
2024-07-04 13:50:49,672:INFO:SubProcess create_model() end ==================================
2024-07-04 13:50:49,672:INFO:Creating metrics dataframe
2024-07-04 13:50:49,672:INFO:Initializing Random Forest Classifier
2024-07-04 13:50:49,672:INFO:Total runtime is 0.4670889496803284 minutes
2024-07-04 13:50:49,672:INFO:SubProcess create_model() called ==================================
2024-07-04 13:50:49,672:INFO:Initializing create_model()
2024-07-04 13:50:49,687:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A5F38D750>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A5E2E3ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:50:49,687:INFO:Checking exceptions
2024-07-04 13:50:49,687:INFO:Importing libraries
2024-07-04 13:50:49,687:INFO:Copying training dataset
2024-07-04 13:50:49,704:INFO:Defining folds
2024-07-04 13:50:49,704:INFO:Declaring metric variables
2024-07-04 13:50:49,705:INFO:Importing untrained model
2024-07-04 13:50:49,705:INFO:Random Forest Classifier Imported successfully
2024-07-04 13:50:49,705:INFO:Starting cross validation
2024-07-04 13:50:49,720:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:50:55,902:INFO:Calculating mean and std
2024-07-04 13:50:55,902:INFO:Creating metrics dataframe
2024-07-04 13:50:55,902:INFO:Uploading results into container
2024-07-04 13:50:55,902:INFO:Uploading model into container now
2024-07-04 13:50:55,902:INFO:_master_model_container: 7
2024-07-04 13:50:55,902:INFO:_display_container: 2
2024-07-04 13:50:55,902:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8306, verbose=0,
                       warm_start=False)
2024-07-04 13:50:55,902:INFO:create_model() successfully completed......................................
2024-07-04 13:50:56,132:INFO:SubProcess create_model() end ==================================
2024-07-04 13:50:56,132:INFO:Creating metrics dataframe
2024-07-04 13:50:56,149:INFO:Initializing Quadratic Discriminant Analysis
2024-07-04 13:50:56,149:INFO:Total runtime is 0.5750369469324748 minutes
2024-07-04 13:50:56,149:INFO:SubProcess create_model() called ==================================
2024-07-04 13:50:56,149:INFO:Initializing create_model()
2024-07-04 13:50:56,149:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A5F38D750>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A5E2E3ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:50:56,149:INFO:Checking exceptions
2024-07-04 13:50:56,149:INFO:Importing libraries
2024-07-04 13:50:56,149:INFO:Copying training dataset
2024-07-04 13:50:56,165:INFO:Defining folds
2024-07-04 13:50:56,165:INFO:Declaring metric variables
2024-07-04 13:50:56,165:INFO:Importing untrained model
2024-07-04 13:50:56,165:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-04 13:50:56,165:INFO:Starting cross validation
2024-07-04 13:50:56,182:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:50:57,313:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 13:50:57,348:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 13:50:57,412:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:50:57,416:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:50:57,416:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:50:57,420:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:50:57,420:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:50:57,421:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:50:57,440:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 13:50:57,451:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:50:57,451:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:50:57,451:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:50:57,451:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:50:57,451:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:50:57,451:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:50:57,451:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:50:57,466:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 13:50:57,486:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:50:58,116:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 13:50:58,134:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 13:50:58,212:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:50:58,212:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:50:58,218:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:50:58,222:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:50:58,222:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:50:58,222:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:50:58,222:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:50:58,222:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:50:58,222:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:50:58,229:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:50:58,229:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 13:50:58,230:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 13:50:58,230:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 13:50:58,238:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 13:50:58,250:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:50:58,260:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:50:58,290:INFO:Calculating mean and std
2024-07-04 13:50:58,290:INFO:Creating metrics dataframe
2024-07-04 13:50:58,296:INFO:Uploading results into container
2024-07-04 13:50:58,296:INFO:Uploading model into container now
2024-07-04 13:50:58,296:INFO:_master_model_container: 8
2024-07-04 13:50:58,296:INFO:_display_container: 2
2024-07-04 13:50:58,296:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-04 13:50:58,296:INFO:create_model() successfully completed......................................
2024-07-04 13:50:58,595:INFO:SubProcess create_model() end ==================================
2024-07-04 13:50:58,595:INFO:Creating metrics dataframe
2024-07-04 13:50:58,595:INFO:Initializing Ada Boost Classifier
2024-07-04 13:50:58,595:INFO:Total runtime is 0.6158016204833984 minutes
2024-07-04 13:50:58,595:INFO:SubProcess create_model() called ==================================
2024-07-04 13:50:58,595:INFO:Initializing create_model()
2024-07-04 13:50:58,595:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A5F38D750>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A5E2E3ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:50:58,595:INFO:Checking exceptions
2024-07-04 13:50:58,595:INFO:Importing libraries
2024-07-04 13:50:58,595:INFO:Copying training dataset
2024-07-04 13:50:58,611:INFO:Defining folds
2024-07-04 13:50:58,611:INFO:Declaring metric variables
2024-07-04 13:50:58,611:INFO:Importing untrained model
2024-07-04 13:50:58,611:INFO:Ada Boost Classifier Imported successfully
2024-07-04 13:50:58,611:INFO:Starting cross validation
2024-07-04 13:50:58,629:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:50:59,746:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:50:59,799:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:50:59,883:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:50:59,932:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:51:00,183:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:51:00,373:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:51:00,645:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:51:00,882:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:51:01,683:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:51:01,717:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 13:51:02,040:INFO:Calculating mean and std
2024-07-04 13:51:02,040:INFO:Creating metrics dataframe
2024-07-04 13:51:02,042:INFO:Uploading results into container
2024-07-04 13:51:02,042:INFO:Uploading model into container now
2024-07-04 13:51:02,042:INFO:_master_model_container: 9
2024-07-04 13:51:02,042:INFO:_display_container: 2
2024-07-04 13:51:02,042:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8306)
2024-07-04 13:51:02,042:INFO:create_model() successfully completed......................................
2024-07-04 13:51:02,291:INFO:SubProcess create_model() end ==================================
2024-07-04 13:51:02,291:INFO:Creating metrics dataframe
2024-07-04 13:51:02,291:INFO:Initializing Gradient Boosting Classifier
2024-07-04 13:51:02,291:INFO:Total runtime is 0.6774001638094583 minutes
2024-07-04 13:51:02,291:INFO:SubProcess create_model() called ==================================
2024-07-04 13:51:02,291:INFO:Initializing create_model()
2024-07-04 13:51:02,291:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A5F38D750>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A5E2E3ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:51:02,291:INFO:Checking exceptions
2024-07-04 13:51:02,291:INFO:Importing libraries
2024-07-04 13:51:02,291:INFO:Copying training dataset
2024-07-04 13:51:02,322:INFO:Defining folds
2024-07-04 13:51:02,323:INFO:Declaring metric variables
2024-07-04 13:51:02,324:INFO:Importing untrained model
2024-07-04 13:51:02,324:INFO:Gradient Boosting Classifier Imported successfully
2024-07-04 13:51:02,324:INFO:Starting cross validation
2024-07-04 13:51:02,341:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:51:07,544:INFO:Calculating mean and std
2024-07-04 13:51:07,544:INFO:Creating metrics dataframe
2024-07-04 13:51:07,544:INFO:Uploading results into container
2024-07-04 13:51:07,551:INFO:Uploading model into container now
2024-07-04 13:51:07,553:INFO:_master_model_container: 10
2024-07-04 13:51:07,553:INFO:_display_container: 2
2024-07-04 13:51:07,553:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8306, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-04 13:51:07,553:INFO:create_model() successfully completed......................................
2024-07-04 13:51:07,740:INFO:SubProcess create_model() end ==================================
2024-07-04 13:51:07,740:INFO:Creating metrics dataframe
2024-07-04 13:51:07,752:INFO:Initializing Linear Discriminant Analysis
2024-07-04 13:51:07,752:INFO:Total runtime is 0.7684207518895466 minutes
2024-07-04 13:51:07,752:INFO:SubProcess create_model() called ==================================
2024-07-04 13:51:07,752:INFO:Initializing create_model()
2024-07-04 13:51:07,752:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A5F38D750>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A5E2E3ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:51:07,752:INFO:Checking exceptions
2024-07-04 13:51:07,752:INFO:Importing libraries
2024-07-04 13:51:07,752:INFO:Copying training dataset
2024-07-04 13:51:07,752:INFO:Defining folds
2024-07-04 13:51:07,767:INFO:Declaring metric variables
2024-07-04 13:51:07,767:INFO:Importing untrained model
2024-07-04 13:51:07,771:INFO:Linear Discriminant Analysis Imported successfully
2024-07-04 13:51:07,771:INFO:Starting cross validation
2024-07-04 13:51:07,771:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:51:09,716:INFO:Calculating mean and std
2024-07-04 13:51:09,716:INFO:Creating metrics dataframe
2024-07-04 13:51:09,716:INFO:Uploading results into container
2024-07-04 13:51:09,716:INFO:Uploading model into container now
2024-07-04 13:51:09,716:INFO:_master_model_container: 11
2024-07-04 13:51:09,716:INFO:_display_container: 2
2024-07-04 13:51:09,716:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-04 13:51:09,716:INFO:create_model() successfully completed......................................
2024-07-04 13:51:09,982:INFO:SubProcess create_model() end ==================================
2024-07-04 13:51:09,982:INFO:Creating metrics dataframe
2024-07-04 13:51:09,999:INFO:Initializing Extra Trees Classifier
2024-07-04 13:51:09,999:INFO:Total runtime is 0.8058697819709777 minutes
2024-07-04 13:51:09,999:INFO:SubProcess create_model() called ==================================
2024-07-04 13:51:09,999:INFO:Initializing create_model()
2024-07-04 13:51:09,999:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A5F38D750>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A5E2E3ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:51:09,999:INFO:Checking exceptions
2024-07-04 13:51:09,999:INFO:Importing libraries
2024-07-04 13:51:09,999:INFO:Copying training dataset
2024-07-04 13:51:10,016:INFO:Defining folds
2024-07-04 13:51:10,016:INFO:Declaring metric variables
2024-07-04 13:51:10,016:INFO:Importing untrained model
2024-07-04 13:51:10,016:INFO:Extra Trees Classifier Imported successfully
2024-07-04 13:51:10,016:INFO:Starting cross validation
2024-07-04 13:51:10,034:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:51:15,379:INFO:Calculating mean and std
2024-07-04 13:51:15,379:INFO:Creating metrics dataframe
2024-07-04 13:51:15,379:INFO:Uploading results into container
2024-07-04 13:51:15,379:INFO:Uploading model into container now
2024-07-04 13:51:15,379:INFO:_master_model_container: 12
2024-07-04 13:51:15,379:INFO:_display_container: 2
2024-07-04 13:51:15,379:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8306, verbose=0,
                     warm_start=False)
2024-07-04 13:51:15,379:INFO:create_model() successfully completed......................................
2024-07-04 13:51:15,627:INFO:SubProcess create_model() end ==================================
2024-07-04 13:51:15,627:INFO:Creating metrics dataframe
2024-07-04 13:51:15,643:INFO:Initializing Light Gradient Boosting Machine
2024-07-04 13:51:15,643:INFO:Total runtime is 0.8999376614888508 minutes
2024-07-04 13:51:15,643:INFO:SubProcess create_model() called ==================================
2024-07-04 13:51:15,643:INFO:Initializing create_model()
2024-07-04 13:51:15,643:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A5F38D750>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A5E2E3ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:51:15,643:INFO:Checking exceptions
2024-07-04 13:51:15,643:INFO:Importing libraries
2024-07-04 13:51:15,643:INFO:Copying training dataset
2024-07-04 13:51:15,659:INFO:Defining folds
2024-07-04 13:51:15,659:INFO:Declaring metric variables
2024-07-04 13:51:15,659:INFO:Importing untrained model
2024-07-04 13:51:15,659:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-04 13:51:15,659:INFO:Starting cross validation
2024-07-04 13:51:15,677:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:51:18,997:INFO:Calculating mean and std
2024-07-04 13:51:18,997:INFO:Creating metrics dataframe
2024-07-04 13:51:18,997:INFO:Uploading results into container
2024-07-04 13:51:18,997:INFO:Uploading model into container now
2024-07-04 13:51:19,004:INFO:_master_model_container: 13
2024-07-04 13:51:19,005:INFO:_display_container: 2
2024-07-04 13:51:19,006:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8306, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-04 13:51:19,007:INFO:create_model() successfully completed......................................
2024-07-04 13:51:19,258:INFO:SubProcess create_model() end ==================================
2024-07-04 13:51:19,258:INFO:Creating metrics dataframe
2024-07-04 13:51:19,274:INFO:Initializing Dummy Classifier
2024-07-04 13:51:19,274:INFO:Total runtime is 0.9604524453481037 minutes
2024-07-04 13:51:19,274:INFO:SubProcess create_model() called ==================================
2024-07-04 13:51:19,274:INFO:Initializing create_model()
2024-07-04 13:51:19,274:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A5F38D750>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A5E2E3ED0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:51:19,274:INFO:Checking exceptions
2024-07-04 13:51:19,274:INFO:Importing libraries
2024-07-04 13:51:19,274:INFO:Copying training dataset
2024-07-04 13:51:19,289:INFO:Defining folds
2024-07-04 13:51:19,289:INFO:Declaring metric variables
2024-07-04 13:51:19,289:INFO:Importing untrained model
2024-07-04 13:51:19,289:INFO:Dummy Classifier Imported successfully
2024-07-04 13:51:19,289:INFO:Starting cross validation
2024-07-04 13:51:19,306:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:51:20,531:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:51:20,563:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:51:20,563:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:51:20,705:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:51:20,756:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:51:20,907:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:51:20,907:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:51:20,957:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:51:21,258:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:51:21,310:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 13:51:21,341:INFO:Calculating mean and std
2024-07-04 13:51:21,341:INFO:Creating metrics dataframe
2024-07-04 13:51:21,341:INFO:Uploading results into container
2024-07-04 13:51:21,341:INFO:Uploading model into container now
2024-07-04 13:51:21,354:INFO:_master_model_container: 14
2024-07-04 13:51:21,355:INFO:_display_container: 2
2024-07-04 13:51:21,356:INFO:DummyClassifier(constant=None, random_state=8306, strategy='prior')
2024-07-04 13:51:21,356:INFO:create_model() successfully completed......................................
2024-07-04 13:51:21,606:INFO:SubProcess create_model() end ==================================
2024-07-04 13:51:21,606:INFO:Creating metrics dataframe
2024-07-04 13:51:21,606:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-07-04 13:51:21,619:INFO:Initializing create_model()
2024-07-04 13:51:21,619:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A5F38D750>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8306, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:51:21,619:INFO:Checking exceptions
2024-07-04 13:51:21,619:INFO:Importing libraries
2024-07-04 13:51:21,619:INFO:Copying training dataset
2024-07-04 13:51:21,637:INFO:Defining folds
2024-07-04 13:51:21,637:INFO:Declaring metric variables
2024-07-04 13:51:21,637:INFO:Importing untrained model
2024-07-04 13:51:21,637:INFO:Declaring custom model
2024-07-04 13:51:21,637:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-04 13:51:21,654:INFO:Cross validation set to False
2024-07-04 13:51:21,654:INFO:Fitting Model
2024-07-04 13:51:22,138:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8306, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-04 13:51:22,138:INFO:create_model() successfully completed......................................
2024-07-04 13:51:22,408:INFO:_master_model_container: 14
2024-07-04 13:51:22,408:INFO:_display_container: 2
2024-07-04 13:51:22,408:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8306, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-04 13:51:22,408:INFO:compare_models() successfully completed......................................
2024-07-04 13:51:22,437:INFO:Initializing tune_model()
2024-07-04 13:51:22,437:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A5F38D750>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8306, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=bayesian, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-04 13:51:22,437:INFO:Checking exceptions
2024-07-04 13:51:22,437:INFO:Soft dependency imported: skopt: 0.10.2
2024-07-04 13:51:22,452:INFO:Copying training dataset
2024-07-04 13:51:22,464:INFO:Checking base model
2024-07-04 13:51:22,465:INFO:Base model : Light Gradient Boosting Machine
2024-07-04 13:51:22,467:INFO:Declaring metric variables
2024-07-04 13:51:22,467:INFO:Defining Hyperparameters
2024-07-04 13:51:22,752:INFO:Tuning with n_jobs=-1
2024-07-04 13:51:22,768:INFO:Initializing skopt.BayesSearchCV
2024-07-04 13:52:53,224:INFO:best_params: OrderedDict([('actual_estimator__bagging_fraction', 0.5188639013981128), ('actual_estimator__bagging_freq', 4), ('actual_estimator__feature_fraction', 0.7196080503988944), ('actual_estimator__learning_rate', 0.00045280594779894206), ('actual_estimator__min_child_samples', 10), ('actual_estimator__min_split_gain', 0.7496117466792741), ('actual_estimator__n_estimators', 190), ('actual_estimator__num_leaves', 251), ('actual_estimator__reg_alpha', 2.4309055801067476), ('actual_estimator__reg_lambda', 3.6162459990053506e-09)])
2024-07-04 13:52:53,224:INFO:Hyperparameter search completed
2024-07-04 13:52:53,224:INFO:SubProcess create_model() called ==================================
2024-07-04 13:52:53,224:INFO:Initializing create_model()
2024-07-04 13:52:53,224:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A5F38D750>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8306, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000017A54E06710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'bagging_fraction': 0.5188639013981128, 'bagging_freq': 4, 'feature_fraction': 0.7196080503988944, 'learning_rate': 0.00045280594779894206, 'min_child_samples': 10, 'min_split_gain': 0.7496117466792741, 'n_estimators': 190, 'num_leaves': 251, 'reg_alpha': 2.4309055801067476, 'reg_lambda': 3.6162459990053506e-09})
2024-07-04 13:52:53,224:INFO:Checking exceptions
2024-07-04 13:52:53,224:INFO:Importing libraries
2024-07-04 13:52:53,224:INFO:Copying training dataset
2024-07-04 13:52:53,235:INFO:Defining folds
2024-07-04 13:52:53,235:INFO:Declaring metric variables
2024-07-04 13:52:53,235:INFO:Importing untrained model
2024-07-04 13:52:53,235:INFO:Declaring custom model
2024-07-04 13:52:53,252:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-04 13:52:53,252:INFO:Starting cross validation
2024-07-04 13:52:53,252:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:52:59,896:INFO:Calculating mean and std
2024-07-04 13:52:59,896:INFO:Creating metrics dataframe
2024-07-04 13:52:59,901:INFO:Finalizing model
2024-07-04 13:53:01,077:INFO:Uploading results into container
2024-07-04 13:53:01,077:INFO:Uploading model into container now
2024-07-04 13:53:01,077:INFO:_master_model_container: 15
2024-07-04 13:53:01,077:INFO:_display_container: 3
2024-07-04 13:53:01,077:INFO:LGBMClassifier(bagging_fraction=0.5188639013981128, bagging_freq=4,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.7196080503988944, importance_type='split',
               learning_rate=0.00045280594779894206, max_depth=-1,
               min_child_samples=10, min_child_weight=0.001,
               min_split_gain=0.7496117466792741, n_estimators=190, n_jobs=-1,
               num_leaves=251, objective=None, random_state=8306,
               reg_alpha=2.4309055801067476, reg_lambda=3.6162459990053506e-09,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-07-04 13:53:01,077:INFO:create_model() successfully completed......................................
2024-07-04 13:53:01,326:INFO:SubProcess create_model() end ==================================
2024-07-04 13:53:01,326:INFO:choose_better activated
2024-07-04 13:53:01,326:INFO:SubProcess create_model() called ==================================
2024-07-04 13:53:01,343:INFO:Initializing create_model()
2024-07-04 13:53:01,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A5F38D750>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8306, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 13:53:01,343:INFO:Checking exceptions
2024-07-04 13:53:01,343:INFO:Importing libraries
2024-07-04 13:53:01,343:INFO:Copying training dataset
2024-07-04 13:53:01,359:INFO:Defining folds
2024-07-04 13:53:01,359:INFO:Declaring metric variables
2024-07-04 13:53:01,359:INFO:Importing untrained model
2024-07-04 13:53:01,359:INFO:Declaring custom model
2024-07-04 13:53:01,359:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-04 13:53:01,359:INFO:Starting cross validation
2024-07-04 13:53:01,377:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 13:53:05,194:INFO:Calculating mean and std
2024-07-04 13:53:05,194:INFO:Creating metrics dataframe
2024-07-04 13:53:05,196:INFO:Finalizing model
2024-07-04 13:53:05,807:INFO:Uploading results into container
2024-07-04 13:53:05,807:INFO:Uploading model into container now
2024-07-04 13:53:05,807:INFO:_master_model_container: 16
2024-07-04 13:53:05,807:INFO:_display_container: 4
2024-07-04 13:53:05,807:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8306, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-04 13:53:05,807:INFO:create_model() successfully completed......................................
2024-07-04 13:53:06,039:INFO:SubProcess create_model() end ==================================
2024-07-04 13:53:06,039:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8306, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.7124
2024-07-04 13:53:06,039:INFO:LGBMClassifier(bagging_fraction=0.5188639013981128, bagging_freq=4,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.7196080503988944, importance_type='split',
               learning_rate=0.00045280594779894206, max_depth=-1,
               min_child_samples=10, min_child_weight=0.001,
               min_split_gain=0.7496117466792741, n_estimators=190, n_jobs=-1,
               num_leaves=251, objective=None, random_state=8306,
               reg_alpha=2.4309055801067476, reg_lambda=3.6162459990053506e-09,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8057
2024-07-04 13:53:06,039:INFO:LGBMClassifier(bagging_fraction=0.5188639013981128, bagging_freq=4,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.7196080503988944, importance_type='split',
               learning_rate=0.00045280594779894206, max_depth=-1,
               min_child_samples=10, min_child_weight=0.001,
               min_split_gain=0.7496117466792741, n_estimators=190, n_jobs=-1,
               num_leaves=251, objective=None, random_state=8306,
               reg_alpha=2.4309055801067476, reg_lambda=3.6162459990053506e-09,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2024-07-04 13:53:06,039:INFO:choose_better completed
2024-07-04 13:53:06,088:INFO:_master_model_container: 16
2024-07-04 13:53:06,088:INFO:_display_container: 3
2024-07-04 13:53:06,091:INFO:LGBMClassifier(bagging_fraction=0.5188639013981128, bagging_freq=4,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.7196080503988944, importance_type='split',
               learning_rate=0.00045280594779894206, max_depth=-1,
               min_child_samples=10, min_child_weight=0.001,
               min_split_gain=0.7496117466792741, n_estimators=190, n_jobs=-1,
               num_leaves=251, objective=None, random_state=8306,
               reg_alpha=2.4309055801067476, reg_lambda=3.6162459990053506e-09,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-07-04 13:53:06,091:INFO:tune_model() successfully completed......................................
2024-07-04 13:53:06,346:INFO:Initializing plot_model()
2024-07-04 13:53:06,346:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A5F38D750>, estimator=LGBMClassifier(bagging_fraction=0.5188639013981128, bagging_freq=4,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.7196080503988944, importance_type='split',
               learning_rate=0.00045280594779894206, max_depth=-1,
               min_child_samples=10, min_child_weight=0.001,
               min_split_gain=0.7496117466792741, n_estimators=190, n_jobs=-1,
               num_leaves=251, objective=None, random_state=8306,
               reg_alpha=2.4309055801067476, reg_lambda=3.6162459990053506e-09,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=class_report, scale=0.75, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2024-07-04 13:53:06,347:INFO:Checking exceptions
2024-07-04 13:53:06,347:INFO:Soft dependency imported: streamlit: 1.36.0
2024-07-04 13:53:06,362:INFO:Preloading libraries
2024-07-04 13:53:06,372:INFO:Copying training dataset
2024-07-04 13:53:06,372:INFO:Plot type: class_report
2024-07-04 13:53:06,949:INFO:Fitting Model
2024-07-04 13:53:06,949:INFO:Scoring test/hold-out set
2024-07-04 13:53:07,750:INFO:Visual Rendered Successfully
2024-07-04 13:53:07,945:INFO:plot_model() successfully completed......................................
2024-07-04 13:53:07,962:INFO:Initializing plot_model()
2024-07-04 13:53:07,962:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A5F38D750>, estimator=LGBMClassifier(bagging_fraction=0.5188639013981128, bagging_freq=4,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.7196080503988944, importance_type='split',
               learning_rate=0.00045280594779894206, max_depth=-1,
               min_child_samples=10, min_child_weight=0.001,
               min_split_gain=0.7496117466792741, n_estimators=190, n_jobs=-1,
               num_leaves=251, objective=None, random_state=8306,
               reg_alpha=2.4309055801067476, reg_lambda=3.6162459990053506e-09,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=confusion_matrix, scale=0.75, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2024-07-04 13:53:07,962:INFO:Checking exceptions
2024-07-04 13:53:07,962:INFO:Soft dependency imported: streamlit: 1.36.0
2024-07-04 13:53:07,975:INFO:Preloading libraries
2024-07-04 13:53:07,994:INFO:Copying training dataset
2024-07-04 13:53:07,994:INFO:Plot type: confusion_matrix
2024-07-04 13:53:08,129:INFO:Fitting Model
2024-07-04 13:53:08,129:INFO:Scoring test/hold-out set
2024-07-04 13:53:08,851:INFO:Visual Rendered Successfully
2024-07-04 13:53:09,034:INFO:plot_model() successfully completed......................................
2024-07-04 13:53:09,049:INFO:Initializing plot_model()
2024-07-04 13:53:09,049:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017A5F38D750>, estimator=LGBMClassifier(bagging_fraction=0.5188639013981128, bagging_freq=4,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.7196080503988944, importance_type='split',
               learning_rate=0.00045280594779894206, max_depth=-1,
               min_child_samples=10, min_child_weight=0.001,
               min_split_gain=0.7496117466792741, n_estimators=190, n_jobs=-1,
               num_leaves=251, objective=None, random_state=8306,
               reg_alpha=2.4309055801067476, reg_lambda=3.6162459990053506e-09,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), plot=auc, scale=0.75, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2024-07-04 13:53:09,049:INFO:Checking exceptions
2024-07-04 13:53:09,049:INFO:Soft dependency imported: streamlit: 1.36.0
2024-07-04 13:53:09,060:INFO:Preloading libraries
2024-07-04 13:53:09,077:INFO:Copying training dataset
2024-07-04 13:53:09,077:INFO:Plot type: auc
2024-07-04 13:53:09,218:INFO:Fitting Model
2024-07-04 13:53:09,218:INFO:Scoring test/hold-out set
2024-07-04 13:53:09,896:INFO:Visual Rendered Successfully
2024-07-04 13:53:10,081:INFO:plot_model() successfully completed......................................
2024-07-04 13:54:01,260:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'France'')
  warnings.warn(

2024-07-04 13:56:35,612:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'France'')
  warnings.warn(

2024-07-04 13:56:40,203:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'France'')
  warnings.warn(

2024-07-04 13:59:18,311:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 13:59:18,311:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 13:59:18,311:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 13:59:18,311:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 14:00:27,898:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'France'')
  warnings.warn(

2024-07-04 14:01:44,417:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'France'')
  warnings.warn(

2024-07-04 14:02:04,411:INFO:PyCaret ClassificationExperiment
2024-07-04 14:02:04,411:INFO:Logging name: clf-default-name
2024-07-04 14:02:04,411:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-04 14:02:04,411:INFO:version 3.3.2
2024-07-04 14:02:04,411:INFO:Initializing setup()
2024-07-04 14:02:04,411:INFO:self.USI: c724
2024-07-04 14:02:04,411:INFO:self._variable_keys: {'data', 'is_multiclass', 'memory', 'html_param', 'fix_imbalance', 'fold_generator', 'y', 'X_train', 'X_test', 'seed', 'exp_id', 'pipeline', '_available_plots', 'y_test', 'exp_name_log', '_ml_usecase', 'gpu_n_jobs_param', 'X', 'target_param', 'USI', 'n_jobs_param', 'log_plots_param', 'logging_param', 'fold_shuffle_param', 'idx', 'gpu_param', 'y_train', 'fold_groups_param'}
2024-07-04 14:02:04,411:INFO:Checking environment
2024-07-04 14:02:04,411:INFO:python_version: 3.11.3
2024-07-04 14:02:04,411:INFO:python_build: ('tags/v3.11.3:f3909b8', 'Apr  4 2023 23:49:59')
2024-07-04 14:02:04,411:INFO:machine: AMD64
2024-07-04 14:02:04,456:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-04 14:02:04,462:INFO:Memory: svmem(total=8179539968, available=1598742528, percent=80.5, used=6580797440, free=1598742528)
2024-07-04 14:02:04,462:INFO:Physical Core: 4
2024-07-04 14:02:04,463:INFO:Logical Core: 8
2024-07-04 14:02:04,463:INFO:Checking libraries
2024-07-04 14:02:04,463:INFO:System:
2024-07-04 14:02:04,463:INFO:    python: 3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]
2024-07-04 14:02:04,463:INFO:executable: C:\Program Files\Python311\python.exe
2024-07-04 14:02:04,463:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-04 14:02:04,463:INFO:PyCaret required dependencies:
2024-07-04 14:02:04,672:INFO:                 pip: 23.1.2
2024-07-04 14:02:04,672:INFO:          setuptools: 67.8.0
2024-07-04 14:02:04,672:INFO:             pycaret: 3.3.2
2024-07-04 14:02:04,672:INFO:             IPython: 8.14.0
2024-07-04 14:02:04,672:INFO:          ipywidgets: 8.0.6
2024-07-04 14:02:04,672:INFO:                tqdm: 4.65.0
2024-07-04 14:02:04,672:INFO:               numpy: 1.24.3
2024-07-04 14:02:04,672:INFO:              pandas: 2.1.4
2024-07-04 14:02:04,672:INFO:              jinja2: 3.1.2
2024-07-04 14:02:04,672:INFO:               scipy: 1.10.1
2024-07-04 14:02:04,672:INFO:              joblib: 1.3.2
2024-07-04 14:02:04,672:INFO:             sklearn: 1.4.2
2024-07-04 14:02:04,672:INFO:                pyod: 2.0.1
2024-07-04 14:02:04,672:INFO:            imblearn: 0.12.3
2024-07-04 14:02:04,673:INFO:   category_encoders: 2.6.3
2024-07-04 14:02:04,673:INFO:            lightgbm: 4.4.0
2024-07-04 14:02:04,673:INFO:               numba: 0.57.1
2024-07-04 14:02:04,673:INFO:            requests: 2.31.0
2024-07-04 14:02:04,673:INFO:          matplotlib: 3.7.5
2024-07-04 14:02:04,673:INFO:          scikitplot: 0.3.7
2024-07-04 14:02:04,673:INFO:         yellowbrick: 1.5
2024-07-04 14:02:04,673:INFO:              plotly: 5.15.0
2024-07-04 14:02:04,673:INFO:    plotly-resampler: Not installed
2024-07-04 14:02:04,673:INFO:             kaleido: 0.2.1
2024-07-04 14:02:04,673:INFO:           schemdraw: 0.15
2024-07-04 14:02:04,673:INFO:         statsmodels: 0.14.2
2024-07-04 14:02:04,673:INFO:              sktime: 0.26.0
2024-07-04 14:02:04,673:INFO:               tbats: 1.1.3
2024-07-04 14:02:04,673:INFO:            pmdarima: 2.0.4
2024-07-04 14:02:04,674:INFO:              psutil: 5.9.5
2024-07-04 14:02:04,674:INFO:          markupsafe: 2.1.3
2024-07-04 14:02:04,674:INFO:             pickle5: Not installed
2024-07-04 14:02:04,674:INFO:         cloudpickle: 3.0.0
2024-07-04 14:02:04,674:INFO:         deprecation: 2.1.0
2024-07-04 14:02:04,674:INFO:              xxhash: 3.4.1
2024-07-04 14:02:04,674:INFO:           wurlitzer: Not installed
2024-07-04 14:02:04,674:INFO:PyCaret optional dependencies:
2024-07-04 14:02:04,707:INFO:                shap: 0.45.1
2024-07-04 14:02:04,708:INFO:           interpret: Not installed
2024-07-04 14:02:04,708:INFO:                umap: Not installed
2024-07-04 14:02:04,708:INFO:     ydata_profiling: 4.8.3
2024-07-04 14:02:04,708:INFO:  explainerdashboard: Not installed
2024-07-04 14:02:04,708:INFO:             autoviz: Not installed
2024-07-04 14:02:04,708:INFO:           fairlearn: Not installed
2024-07-04 14:02:04,708:INFO:          deepchecks: Not installed
2024-07-04 14:02:04,708:INFO:             xgboost: Not installed
2024-07-04 14:02:04,708:INFO:            catboost: Not installed
2024-07-04 14:02:04,708:INFO:              kmodes: Not installed
2024-07-04 14:02:04,708:INFO:             mlxtend: Not installed
2024-07-04 14:02:04,709:INFO:       statsforecast: Not installed
2024-07-04 14:02:04,709:INFO:        tune_sklearn: Not installed
2024-07-04 14:02:04,709:INFO:                 ray: Not installed
2024-07-04 14:02:04,709:INFO:            hyperopt: Not installed
2024-07-04 14:02:04,709:INFO:              optuna: 3.2.0
2024-07-04 14:02:04,709:INFO:               skopt: 0.10.2
2024-07-04 14:02:04,709:INFO:              mlflow: Not installed
2024-07-04 14:02:04,709:INFO:              gradio: Not installed
2024-07-04 14:02:04,709:INFO:             fastapi: Not installed
2024-07-04 14:02:04,709:INFO:             uvicorn: Not installed
2024-07-04 14:02:04,710:INFO:              m2cgen: Not installed
2024-07-04 14:02:04,710:INFO:           evidently: Not installed
2024-07-04 14:02:04,710:INFO:               fugue: Not installed
2024-07-04 14:02:04,710:INFO:           streamlit: 1.36.0
2024-07-04 14:02:04,710:INFO:             prophet: Not installed
2024-07-04 14:02:04,710:INFO:None
2024-07-04 14:02:04,710:INFO:Set up data.
2024-07-04 14:02:04,728:INFO:Set up folding strategy.
2024-07-04 14:02:04,729:INFO:Set up train/test split.
2024-07-04 14:02:04,738:INFO:Set up index.
2024-07-04 14:02:04,738:INFO:Assigning column types.
2024-07-04 14:02:04,747:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-04 14:02:04,832:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-04 14:02:04,845:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-04 14:02:04,928:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:02:04,928:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:02:05,012:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-04 14:02:05,013:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-04 14:02:05,070:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:02:05,070:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:02:05,077:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-04 14:02:05,173:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-04 14:02:05,269:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:02:05,269:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:02:05,346:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-04 14:02:05,411:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:02:05,413:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:02:05,413:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-04 14:02:05,591:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:02:05,593:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:02:05,806:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:02:05,806:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:02:05,818:INFO:Preparing preprocessing pipeline...
2024-07-04 14:02:05,822:INFO:Set up simple imputation.
2024-07-04 14:02:05,832:INFO:Set up encoding of ordinal features.
2024-07-04 14:02:05,836:INFO:Set up encoding of categorical features.
2024-07-04 14:02:05,836:INFO:Set up imbalanced handling.
2024-07-04 14:02:05,837:INFO:Set up feature normalization.
2024-07-04 14:02:05,837:INFO:Set up feature selection.
2024-07-04 14:02:06,014:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:02:06,014:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:02:06,738:INFO:Finished creating preprocessing pipeline.
2024-07-04 14:02:06,803:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\PHYOSA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['customer_id', 'credit_score',
                                             'age', 'tenure', 'balance',
                                             'products_number', 'credit_card',
                                             'active_member',
                                             'estimated_salary', 'churn_x'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=N...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=2,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2024-07-04 14:02:06,804:INFO:Creating final display dataframe.
2024-07-04 14:02:07,329:INFO:Setup _display_container:                     Description             Value
0                    Session id              4533
1                        Target           churn_y
2                   Target type            Binary
3           Original data shape       (10000, 13)
4        Transformed data shape        (14148, 3)
5   Transformed train set shape        (11148, 3)
6    Transformed test set shape         (3000, 3)
7              Numeric features                10
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation            median
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17                    Normalize              True
18             Normalize method            robust
19            Feature selection              True
20     Feature selection method           classic
21  Feature selection estimator          lightgbm
22  Number of features selected               0.2
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              c724
2024-07-04 14:02:07,489:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:02:07,489:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:02:07,704:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:02:07,704:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:02:07,720:INFO:setup() successfully completed in 3.39s...............
2024-07-04 14:02:07,735:INFO:Initializing compare_models()
2024-07-04 14:02:07,735:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012D478DB150>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000012D478DB150>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-07-04 14:02:07,735:INFO:Checking exceptions
2024-07-04 14:02:07,745:INFO:Preparing display monitor
2024-07-04 14:02:07,745:INFO:Initializing Logistic Regression
2024-07-04 14:02:07,745:INFO:Total runtime is 0.0 minutes
2024-07-04 14:02:07,745:INFO:SubProcess create_model() called ==================================
2024-07-04 14:02:07,745:INFO:Initializing create_model()
2024-07-04 14:02:07,745:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012D478DB150>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012D6893D190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:02:07,745:INFO:Checking exceptions
2024-07-04 14:02:07,745:INFO:Importing libraries
2024-07-04 14:02:07,745:INFO:Copying training dataset
2024-07-04 14:02:07,775:INFO:Defining folds
2024-07-04 14:02:07,775:INFO:Declaring metric variables
2024-07-04 14:02:07,775:INFO:Importing untrained model
2024-07-04 14:02:07,777:INFO:Logistic Regression Imported successfully
2024-07-04 14:02:07,778:INFO:Starting cross validation
2024-07-04 14:02:07,789:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:02:20,163:INFO:Calculating mean and std
2024-07-04 14:02:20,163:INFO:Creating metrics dataframe
2024-07-04 14:02:20,163:INFO:Uploading results into container
2024-07-04 14:02:20,163:INFO:Uploading model into container now
2024-07-04 14:02:20,163:INFO:_master_model_container: 1
2024-07-04 14:02:20,163:INFO:_display_container: 2
2024-07-04 14:02:20,163:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4533, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-04 14:02:20,163:INFO:create_model() successfully completed......................................
2024-07-04 14:02:20,395:INFO:SubProcess create_model() end ==================================
2024-07-04 14:02:20,395:INFO:Creating metrics dataframe
2024-07-04 14:02:20,395:INFO:Initializing K Neighbors Classifier
2024-07-04 14:02:20,395:INFO:Total runtime is 0.21083375215530395 minutes
2024-07-04 14:02:20,410:INFO:SubProcess create_model() called ==================================
2024-07-04 14:02:20,412:INFO:Initializing create_model()
2024-07-04 14:02:20,412:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012D478DB150>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012D6893D190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:02:20,413:INFO:Checking exceptions
2024-07-04 14:02:20,413:INFO:Importing libraries
2024-07-04 14:02:20,413:INFO:Copying training dataset
2024-07-04 14:02:20,424:INFO:Defining folds
2024-07-04 14:02:20,424:INFO:Declaring metric variables
2024-07-04 14:02:20,425:INFO:Importing untrained model
2024-07-04 14:02:20,425:INFO:K Neighbors Classifier Imported successfully
2024-07-04 14:02:20,426:INFO:Starting cross validation
2024-07-04 14:02:20,441:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:02:22,627:INFO:Calculating mean and std
2024-07-04 14:02:22,627:INFO:Creating metrics dataframe
2024-07-04 14:02:22,627:INFO:Uploading results into container
2024-07-04 14:02:22,627:INFO:Uploading model into container now
2024-07-04 14:02:22,627:INFO:_master_model_container: 2
2024-07-04 14:02:22,627:INFO:_display_container: 2
2024-07-04 14:02:22,627:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-04 14:02:22,627:INFO:create_model() successfully completed......................................
2024-07-04 14:02:22,844:INFO:SubProcess create_model() end ==================================
2024-07-04 14:02:22,844:INFO:Creating metrics dataframe
2024-07-04 14:02:22,859:INFO:Initializing Naive Bayes
2024-07-04 14:02:22,859:INFO:Total runtime is 0.25190253257751466 minutes
2024-07-04 14:02:22,859:INFO:SubProcess create_model() called ==================================
2024-07-04 14:02:22,859:INFO:Initializing create_model()
2024-07-04 14:02:22,859:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012D478DB150>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012D6893D190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:02:22,859:INFO:Checking exceptions
2024-07-04 14:02:22,859:INFO:Importing libraries
2024-07-04 14:02:22,859:INFO:Copying training dataset
2024-07-04 14:02:22,874:INFO:Defining folds
2024-07-04 14:02:22,874:INFO:Declaring metric variables
2024-07-04 14:02:22,874:INFO:Importing untrained model
2024-07-04 14:02:22,874:INFO:Naive Bayes Imported successfully
2024-07-04 14:02:22,874:INFO:Starting cross validation
2024-07-04 14:02:22,892:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:02:24,524:INFO:Calculating mean and std
2024-07-04 14:02:24,524:INFO:Creating metrics dataframe
2024-07-04 14:02:24,524:INFO:Uploading results into container
2024-07-04 14:02:24,524:INFO:Uploading model into container now
2024-07-04 14:02:24,524:INFO:_master_model_container: 3
2024-07-04 14:02:24,524:INFO:_display_container: 2
2024-07-04 14:02:24,524:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-04 14:02:24,524:INFO:create_model() successfully completed......................................
2024-07-04 14:02:24,705:INFO:SubProcess create_model() end ==================================
2024-07-04 14:02:24,705:INFO:Creating metrics dataframe
2024-07-04 14:02:24,724:INFO:Initializing Decision Tree Classifier
2024-07-04 14:02:24,724:INFO:Total runtime is 0.2829750259717306 minutes
2024-07-04 14:02:24,724:INFO:SubProcess create_model() called ==================================
2024-07-04 14:02:24,724:INFO:Initializing create_model()
2024-07-04 14:02:24,724:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012D478DB150>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012D6893D190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:02:24,724:INFO:Checking exceptions
2024-07-04 14:02:24,724:INFO:Importing libraries
2024-07-04 14:02:24,724:INFO:Copying training dataset
2024-07-04 14:02:24,747:INFO:Defining folds
2024-07-04 14:02:24,747:INFO:Declaring metric variables
2024-07-04 14:02:24,747:INFO:Importing untrained model
2024-07-04 14:02:24,747:INFO:Decision Tree Classifier Imported successfully
2024-07-04 14:02:24,747:INFO:Starting cross validation
2024-07-04 14:02:24,755:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:02:27,119:INFO:Calculating mean and std
2024-07-04 14:02:27,121:INFO:Creating metrics dataframe
2024-07-04 14:02:27,121:INFO:Uploading results into container
2024-07-04 14:02:27,121:INFO:Uploading model into container now
2024-07-04 14:02:27,121:INFO:_master_model_container: 4
2024-07-04 14:02:27,121:INFO:_display_container: 2
2024-07-04 14:02:27,121:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=4533, splitter='best')
2024-07-04 14:02:27,121:INFO:create_model() successfully completed......................................
2024-07-04 14:02:27,304:INFO:SubProcess create_model() end ==================================
2024-07-04 14:02:27,304:INFO:Creating metrics dataframe
2024-07-04 14:02:27,304:INFO:Initializing SVM - Linear Kernel
2024-07-04 14:02:27,304:INFO:Total runtime is 0.32598255077997845 minutes
2024-07-04 14:02:27,319:INFO:SubProcess create_model() called ==================================
2024-07-04 14:02:27,319:INFO:Initializing create_model()
2024-07-04 14:02:27,320:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012D478DB150>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012D6893D190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:02:27,321:INFO:Checking exceptions
2024-07-04 14:02:27,321:INFO:Importing libraries
2024-07-04 14:02:27,321:INFO:Copying training dataset
2024-07-04 14:02:27,335:INFO:Defining folds
2024-07-04 14:02:27,335:INFO:Declaring metric variables
2024-07-04 14:02:27,335:INFO:Importing untrained model
2024-07-04 14:02:27,337:INFO:SVM - Linear Kernel Imported successfully
2024-07-04 14:02:27,337:INFO:Starting cross validation
2024-07-04 14:02:27,337:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:02:28,907:INFO:Calculating mean and std
2024-07-04 14:02:28,907:INFO:Creating metrics dataframe
2024-07-04 14:02:28,907:INFO:Uploading results into container
2024-07-04 14:02:28,907:INFO:Uploading model into container now
2024-07-04 14:02:28,907:INFO:_master_model_container: 5
2024-07-04 14:02:28,907:INFO:_display_container: 2
2024-07-04 14:02:28,907:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=4533, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-04 14:02:28,907:INFO:create_model() successfully completed......................................
2024-07-04 14:02:29,118:INFO:SubProcess create_model() end ==================================
2024-07-04 14:02:29,118:INFO:Creating metrics dataframe
2024-07-04 14:02:29,119:INFO:Initializing Ridge Classifier
2024-07-04 14:02:29,119:INFO:Total runtime is 0.35623283783594767 minutes
2024-07-04 14:02:29,119:INFO:SubProcess create_model() called ==================================
2024-07-04 14:02:29,119:INFO:Initializing create_model()
2024-07-04 14:02:29,119:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012D478DB150>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012D6893D190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:02:29,119:INFO:Checking exceptions
2024-07-04 14:02:29,119:INFO:Importing libraries
2024-07-04 14:02:29,119:INFO:Copying training dataset
2024-07-04 14:02:29,134:INFO:Defining folds
2024-07-04 14:02:29,134:INFO:Declaring metric variables
2024-07-04 14:02:29,134:INFO:Importing untrained model
2024-07-04 14:02:29,134:INFO:Ridge Classifier Imported successfully
2024-07-04 14:02:29,134:INFO:Starting cross validation
2024-07-04 14:02:29,153:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:02:31,293:INFO:Calculating mean and std
2024-07-04 14:02:31,293:INFO:Creating metrics dataframe
2024-07-04 14:02:31,293:INFO:Uploading results into container
2024-07-04 14:02:31,293:INFO:Uploading model into container now
2024-07-04 14:02:31,298:INFO:_master_model_container: 6
2024-07-04 14:02:31,298:INFO:_display_container: 2
2024-07-04 14:02:31,299:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4533, solver='auto',
                tol=0.0001)
2024-07-04 14:02:31,299:INFO:create_model() successfully completed......................................
2024-07-04 14:02:31,481:INFO:SubProcess create_model() end ==================================
2024-07-04 14:02:31,481:INFO:Creating metrics dataframe
2024-07-04 14:02:31,498:INFO:Initializing Random Forest Classifier
2024-07-04 14:02:31,498:INFO:Total runtime is 0.3958838144938151 minutes
2024-07-04 14:02:31,498:INFO:SubProcess create_model() called ==================================
2024-07-04 14:02:31,498:INFO:Initializing create_model()
2024-07-04 14:02:31,498:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012D478DB150>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012D6893D190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:02:31,498:INFO:Checking exceptions
2024-07-04 14:02:31,498:INFO:Importing libraries
2024-07-04 14:02:31,498:INFO:Copying training dataset
2024-07-04 14:02:31,515:INFO:Defining folds
2024-07-04 14:02:31,515:INFO:Declaring metric variables
2024-07-04 14:02:31,515:INFO:Importing untrained model
2024-07-04 14:02:31,515:INFO:Random Forest Classifier Imported successfully
2024-07-04 14:02:31,515:INFO:Starting cross validation
2024-07-04 14:02:31,532:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:02:37,226:INFO:Calculating mean and std
2024-07-04 14:02:37,226:INFO:Creating metrics dataframe
2024-07-04 14:02:37,226:INFO:Uploading results into container
2024-07-04 14:02:37,226:INFO:Uploading model into container now
2024-07-04 14:02:37,226:INFO:_master_model_container: 7
2024-07-04 14:02:37,226:INFO:_display_container: 2
2024-07-04 14:02:37,226:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4533, verbose=0,
                       warm_start=False)
2024-07-04 14:02:37,226:INFO:create_model() successfully completed......................................
2024-07-04 14:02:37,475:INFO:SubProcess create_model() end ==================================
2024-07-04 14:02:37,475:INFO:Creating metrics dataframe
2024-07-04 14:02:37,475:INFO:Initializing Quadratic Discriminant Analysis
2024-07-04 14:02:37,475:INFO:Total runtime is 0.49550108114878333 minutes
2024-07-04 14:02:37,475:INFO:SubProcess create_model() called ==================================
2024-07-04 14:02:37,475:INFO:Initializing create_model()
2024-07-04 14:02:37,475:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012D478DB150>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012D6893D190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:02:37,475:INFO:Checking exceptions
2024-07-04 14:02:37,475:INFO:Importing libraries
2024-07-04 14:02:37,475:INFO:Copying training dataset
2024-07-04 14:02:37,504:INFO:Defining folds
2024-07-04 14:02:37,504:INFO:Declaring metric variables
2024-07-04 14:02:37,504:INFO:Importing untrained model
2024-07-04 14:02:37,504:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-04 14:02:37,504:INFO:Starting cross validation
2024-07-04 14:02:37,519:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:02:38,662:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 14:02:38,662:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 14:02:38,765:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:02:38,765:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:02:38,765:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 14:02:38,765:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:02:38,765:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:02:38,765:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 14:02:38,765:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:02:38,765:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:02:38,765:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 14:02:38,776:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:02:38,776:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:02:38,776:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 14:02:38,792:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 14:02:38,809:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:02:38,809:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:02:38,918:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 14:02:39,015:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:02:39,015:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:02:39,015:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 14:02:39,015:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:02:39,015:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:02:39,023:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 14:02:39,048:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 14:02:39,069:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:02:39,113:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 14:02:39,195:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:02:39,195:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:02:39,195:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 14:02:39,200:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:02:39,200:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:02:39,205:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 14:02:39,215:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 14:02:39,237:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:02:39,519:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 14:02:39,524:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 14:02:39,602:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:02:39,602:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:02:39,602:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:02:39,602:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 14:02:39,602:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:02:39,602:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 14:02:39,609:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:02:39,609:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:02:39,609:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:02:39,609:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:02:39,609:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 14:02:39,609:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 14:02:39,612:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 14:02:39,612:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 14:02:39,639:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:02:39,639:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:02:39,675:INFO:Calculating mean and std
2024-07-04 14:02:39,675:INFO:Creating metrics dataframe
2024-07-04 14:02:39,690:INFO:Uploading results into container
2024-07-04 14:02:39,690:INFO:Uploading model into container now
2024-07-04 14:02:39,690:INFO:_master_model_container: 8
2024-07-04 14:02:39,690:INFO:_display_container: 2
2024-07-04 14:02:39,690:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-04 14:02:39,690:INFO:create_model() successfully completed......................................
2024-07-04 14:02:39,953:INFO:SubProcess create_model() end ==================================
2024-07-04 14:02:39,953:INFO:Creating metrics dataframe
2024-07-04 14:02:39,957:INFO:Initializing Ada Boost Classifier
2024-07-04 14:02:39,957:INFO:Total runtime is 0.5368645350138346 minutes
2024-07-04 14:02:39,957:INFO:SubProcess create_model() called ==================================
2024-07-04 14:02:39,957:INFO:Initializing create_model()
2024-07-04 14:02:39,957:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012D478DB150>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012D6893D190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:02:39,957:INFO:Checking exceptions
2024-07-04 14:02:39,957:INFO:Importing libraries
2024-07-04 14:02:39,957:INFO:Copying training dataset
2024-07-04 14:02:39,972:INFO:Defining folds
2024-07-04 14:02:39,972:INFO:Declaring metric variables
2024-07-04 14:02:39,972:INFO:Importing untrained model
2024-07-04 14:02:39,972:INFO:Ada Boost Classifier Imported successfully
2024-07-04 14:02:39,972:INFO:Starting cross validation
2024-07-04 14:02:39,989:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:02:41,345:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 14:02:41,355:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 14:02:41,441:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 14:02:41,504:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 14:02:41,604:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 14:02:42,020:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 14:02:42,037:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 14:02:42,205:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 14:02:43,023:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 14:02:43,072:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 14:02:43,616:INFO:Calculating mean and std
2024-07-04 14:02:43,620:INFO:Creating metrics dataframe
2024-07-04 14:02:43,625:INFO:Uploading results into container
2024-07-04 14:02:43,626:INFO:Uploading model into container now
2024-07-04 14:02:43,627:INFO:_master_model_container: 9
2024-07-04 14:02:43,627:INFO:_display_container: 2
2024-07-04 14:02:43,628:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4533)
2024-07-04 14:02:43,628:INFO:create_model() successfully completed......................................
2024-07-04 14:02:43,835:INFO:SubProcess create_model() end ==================================
2024-07-04 14:02:43,835:INFO:Creating metrics dataframe
2024-07-04 14:02:43,851:INFO:Initializing Gradient Boosting Classifier
2024-07-04 14:02:43,851:INFO:Total runtime is 0.6017703493436177 minutes
2024-07-04 14:02:43,851:INFO:SubProcess create_model() called ==================================
2024-07-04 14:02:43,851:INFO:Initializing create_model()
2024-07-04 14:02:43,851:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012D478DB150>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012D6893D190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:02:43,851:INFO:Checking exceptions
2024-07-04 14:02:43,851:INFO:Importing libraries
2024-07-04 14:02:43,851:INFO:Copying training dataset
2024-07-04 14:02:43,870:INFO:Defining folds
2024-07-04 14:02:43,870:INFO:Declaring metric variables
2024-07-04 14:02:43,870:INFO:Importing untrained model
2024-07-04 14:02:43,870:INFO:Gradient Boosting Classifier Imported successfully
2024-07-04 14:02:43,870:INFO:Starting cross validation
2024-07-04 14:02:43,880:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:02:49,568:INFO:Calculating mean and std
2024-07-04 14:02:49,568:INFO:Creating metrics dataframe
2024-07-04 14:02:49,572:INFO:Uploading results into container
2024-07-04 14:02:49,576:INFO:Uploading model into container now
2024-07-04 14:02:49,576:INFO:_master_model_container: 10
2024-07-04 14:02:49,576:INFO:_display_container: 2
2024-07-04 14:02:49,578:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4533, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-04 14:02:49,578:INFO:create_model() successfully completed......................................
2024-07-04 14:02:49,812:INFO:SubProcess create_model() end ==================================
2024-07-04 14:02:49,812:INFO:Creating metrics dataframe
2024-07-04 14:02:49,827:INFO:Initializing Linear Discriminant Analysis
2024-07-04 14:02:49,827:INFO:Total runtime is 0.7013663490613301 minutes
2024-07-04 14:02:49,827:INFO:SubProcess create_model() called ==================================
2024-07-04 14:02:49,827:INFO:Initializing create_model()
2024-07-04 14:02:49,827:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012D478DB150>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012D6893D190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:02:49,827:INFO:Checking exceptions
2024-07-04 14:02:49,827:INFO:Importing libraries
2024-07-04 14:02:49,827:INFO:Copying training dataset
2024-07-04 14:02:49,851:INFO:Defining folds
2024-07-04 14:02:49,851:INFO:Declaring metric variables
2024-07-04 14:02:49,851:INFO:Importing untrained model
2024-07-04 14:02:49,851:INFO:Linear Discriminant Analysis Imported successfully
2024-07-04 14:02:49,851:INFO:Starting cross validation
2024-07-04 14:02:49,864:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:02:53,276:INFO:Calculating mean and std
2024-07-04 14:02:53,276:INFO:Creating metrics dataframe
2024-07-04 14:02:53,280:INFO:Uploading results into container
2024-07-04 14:02:53,280:INFO:Uploading model into container now
2024-07-04 14:02:53,280:INFO:_master_model_container: 11
2024-07-04 14:02:53,280:INFO:_display_container: 2
2024-07-04 14:02:53,280:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-04 14:02:53,280:INFO:create_model() successfully completed......................................
2024-07-04 14:02:53,518:INFO:SubProcess create_model() end ==================================
2024-07-04 14:02:53,518:INFO:Creating metrics dataframe
2024-07-04 14:02:53,525:INFO:Initializing Extra Trees Classifier
2024-07-04 14:02:53,525:INFO:Total runtime is 0.7629905502001444 minutes
2024-07-04 14:02:53,525:INFO:SubProcess create_model() called ==================================
2024-07-04 14:02:53,525:INFO:Initializing create_model()
2024-07-04 14:02:53,525:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012D478DB150>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012D6893D190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:02:53,525:INFO:Checking exceptions
2024-07-04 14:02:53,525:INFO:Importing libraries
2024-07-04 14:02:53,525:INFO:Copying training dataset
2024-07-04 14:02:53,542:INFO:Defining folds
2024-07-04 14:02:53,550:INFO:Declaring metric variables
2024-07-04 14:02:53,550:INFO:Importing untrained model
2024-07-04 14:02:53,550:INFO:Extra Trees Classifier Imported successfully
2024-07-04 14:02:53,550:INFO:Starting cross validation
2024-07-04 14:02:53,566:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:02:58,895:INFO:Calculating mean and std
2024-07-04 14:02:58,897:INFO:Creating metrics dataframe
2024-07-04 14:02:58,904:INFO:Uploading results into container
2024-07-04 14:02:58,904:INFO:Uploading model into container now
2024-07-04 14:02:58,904:INFO:_master_model_container: 12
2024-07-04 14:02:58,904:INFO:_display_container: 2
2024-07-04 14:02:58,904:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=4533, verbose=0,
                     warm_start=False)
2024-07-04 14:02:58,904:INFO:create_model() successfully completed......................................
2024-07-04 14:02:59,164:INFO:SubProcess create_model() end ==================================
2024-07-04 14:02:59,164:INFO:Creating metrics dataframe
2024-07-04 14:02:59,164:INFO:Initializing Light Gradient Boosting Machine
2024-07-04 14:02:59,164:INFO:Total runtime is 0.8569811503092447 minutes
2024-07-04 14:02:59,164:INFO:SubProcess create_model() called ==================================
2024-07-04 14:02:59,164:INFO:Initializing create_model()
2024-07-04 14:02:59,164:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012D478DB150>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012D6893D190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:02:59,164:INFO:Checking exceptions
2024-07-04 14:02:59,164:INFO:Importing libraries
2024-07-04 14:02:59,164:INFO:Copying training dataset
2024-07-04 14:02:59,195:INFO:Defining folds
2024-07-04 14:02:59,195:INFO:Declaring metric variables
2024-07-04 14:02:59,195:INFO:Importing untrained model
2024-07-04 14:02:59,195:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-04 14:02:59,195:INFO:Starting cross validation
2024-07-04 14:02:59,206:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:03:02,699:INFO:Calculating mean and std
2024-07-04 14:03:02,699:INFO:Creating metrics dataframe
2024-07-04 14:03:02,699:INFO:Uploading results into container
2024-07-04 14:03:02,699:INFO:Uploading model into container now
2024-07-04 14:03:02,699:INFO:_master_model_container: 13
2024-07-04 14:03:02,699:INFO:_display_container: 2
2024-07-04 14:03:02,699:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4533, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-04 14:03:02,699:INFO:create_model() successfully completed......................................
2024-07-04 14:03:02,968:INFO:SubProcess create_model() end ==================================
2024-07-04 14:03:02,968:INFO:Creating metrics dataframe
2024-07-04 14:03:02,976:INFO:Initializing Dummy Classifier
2024-07-04 14:03:02,977:INFO:Total runtime is 0.9205290675163268 minutes
2024-07-04 14:03:02,977:INFO:SubProcess create_model() called ==================================
2024-07-04 14:03:02,978:INFO:Initializing create_model()
2024-07-04 14:03:02,979:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012D478DB150>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012D6893D190>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:03:02,979:INFO:Checking exceptions
2024-07-04 14:03:02,979:INFO:Importing libraries
2024-07-04 14:03:02,980:INFO:Copying training dataset
2024-07-04 14:03:02,998:INFO:Defining folds
2024-07-04 14:03:02,998:INFO:Declaring metric variables
2024-07-04 14:03:02,998:INFO:Importing untrained model
2024-07-04 14:03:02,998:INFO:Dummy Classifier Imported successfully
2024-07-04 14:03:02,998:INFO:Starting cross validation
2024-07-04 14:03:03,015:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:03:04,437:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:03:04,447:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:03:04,490:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:03:04,531:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:03:04,769:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:03:04,847:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:03:04,899:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:03:04,931:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:03:05,280:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:03:05,280:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:03:05,312:INFO:Calculating mean and std
2024-07-04 14:03:05,312:INFO:Creating metrics dataframe
2024-07-04 14:03:05,312:INFO:Uploading results into container
2024-07-04 14:03:05,312:INFO:Uploading model into container now
2024-07-04 14:03:05,312:INFO:_master_model_container: 14
2024-07-04 14:03:05,312:INFO:_display_container: 2
2024-07-04 14:03:05,312:INFO:DummyClassifier(constant=None, random_state=4533, strategy='prior')
2024-07-04 14:03:05,312:INFO:create_model() successfully completed......................................
2024-07-04 14:03:05,591:INFO:SubProcess create_model() end ==================================
2024-07-04 14:03:05,591:INFO:Creating metrics dataframe
2024-07-04 14:03:05,613:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-07-04 14:03:05,613:INFO:Initializing create_model()
2024-07-04 14:03:05,613:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012D478DB150>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4533, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:03:05,613:INFO:Checking exceptions
2024-07-04 14:03:05,613:INFO:Importing libraries
2024-07-04 14:03:05,613:INFO:Copying training dataset
2024-07-04 14:03:05,645:INFO:Defining folds
2024-07-04 14:03:05,645:INFO:Declaring metric variables
2024-07-04 14:03:05,645:INFO:Importing untrained model
2024-07-04 14:03:05,645:INFO:Declaring custom model
2024-07-04 14:03:05,645:INFO:Random Forest Classifier Imported successfully
2024-07-04 14:03:05,660:INFO:Cross validation set to False
2024-07-04 14:03:05,660:INFO:Fitting Model
2024-07-04 14:03:05,927:INFO:[LightGBM] [Info] Number of positive: 5574, number of negative: 5574
2024-07-04 14:03:05,927:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000874 seconds.
2024-07-04 14:03:05,927:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-04 14:03:05,927:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-04 14:03:05,927:INFO:[LightGBM] [Info] Total Bins 3318
2024-07-04 14:03:05,927:INFO:[LightGBM] [Info] Number of data points in the train set: 11148, number of used features: 14
2024-07-04 14:03:05,927:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-07-04 14:03:05,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:05,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:03:06,924:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4533, verbose=0,
                       warm_start=False)
2024-07-04 14:03:06,924:INFO:create_model() successfully completed......................................
2024-07-04 14:03:07,242:INFO:_master_model_container: 14
2024-07-04 14:03:07,242:INFO:_display_container: 2
2024-07-04 14:03:07,242:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4533, verbose=0,
                       warm_start=False)
2024-07-04 14:03:07,242:INFO:compare_models() successfully completed......................................
2024-07-04 14:03:07,283:INFO:Initializing tune_model()
2024-07-04 14:03:07,283:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012D478DB150>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4533, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=bayesian, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-04 14:03:07,283:INFO:Checking exceptions
2024-07-04 14:03:07,283:INFO:Soft dependency imported: skopt: 0.10.2
2024-07-04 14:03:07,371:INFO:Copying training dataset
2024-07-04 14:03:07,383:INFO:Checking base model
2024-07-04 14:03:07,384:INFO:Base model : Random Forest Classifier
2024-07-04 14:03:07,386:INFO:Declaring metric variables
2024-07-04 14:03:07,386:INFO:Defining Hyperparameters
2024-07-04 14:03:07,708:INFO:Tuning with n_jobs=-1
2024-07-04 14:03:07,726:INFO:Initializing skopt.BayesSearchCV
2024-07-04 14:04:18,176:INFO:best_params: OrderedDict([('actual_estimator__bootstrap', False), ('actual_estimator__class_weight', None), ('actual_estimator__criterion', 'entropy'), ('actual_estimator__max_depth', 3), ('actual_estimator__max_features', 0.43684839740936343), ('actual_estimator__min_impurity_decrease', 1.2169714716986524e-07), ('actual_estimator__min_samples_leaf', 3), ('actual_estimator__min_samples_split', 7), ('actual_estimator__n_estimators', 128)])
2024-07-04 14:04:18,176:INFO:Hyperparameter search completed
2024-07-04 14:04:18,176:INFO:SubProcess create_model() called ==================================
2024-07-04 14:04:18,176:INFO:Initializing create_model()
2024-07-04 14:04:18,176:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012D478DB150>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4533, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000012D6A1E7390>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'bootstrap': False, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 3, 'max_features': 0.43684839740936343, 'min_impurity_decrease': 1.2169714716986524e-07, 'min_samples_leaf': 3, 'min_samples_split': 7, 'n_estimators': 128})
2024-07-04 14:04:18,176:INFO:Checking exceptions
2024-07-04 14:04:18,176:INFO:Importing libraries
2024-07-04 14:04:18,176:INFO:Copying training dataset
2024-07-04 14:04:18,191:INFO:Defining folds
2024-07-04 14:04:18,191:INFO:Declaring metric variables
2024-07-04 14:04:18,191:INFO:Importing untrained model
2024-07-04 14:04:18,191:INFO:Declaring custom model
2024-07-04 14:04:18,191:INFO:Random Forest Classifier Imported successfully
2024-07-04 14:04:18,191:INFO:Starting cross validation
2024-07-04 14:04:18,206:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:04:23,500:INFO:Calculating mean and std
2024-07-04 14:04:23,503:INFO:Creating metrics dataframe
2024-07-04 14:04:23,503:INFO:Finalizing model
2024-07-04 14:04:23,742:INFO:[LightGBM] [Info] Number of positive: 5574, number of negative: 5574
2024-07-04 14:04:23,742:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000659 seconds.
2024-07-04 14:04:23,742:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-04 14:04:23,751:INFO:[LightGBM] [Info] Total Bins 3318
2024-07-04 14:04:23,751:INFO:[LightGBM] [Info] Number of data points in the train set: 11148, number of used features: 14
2024-07-04 14:04:23,751:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-07-04 14:04:23,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,795:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:23,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:24,328:INFO:Uploading results into container
2024-07-04 14:04:24,328:INFO:Uploading model into container now
2024-07-04 14:04:24,328:INFO:_master_model_container: 15
2024-07-04 14:04:24,328:INFO:_display_container: 3
2024-07-04 14:04:24,328:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                       criterion='entropy', max_depth=3,
                       max_features=0.43684839740936343, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=1.2169714716986524e-07,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=128, n_jobs=-1, oob_score=False,
                       random_state=4533, verbose=0, warm_start=False)
2024-07-04 14:04:24,328:INFO:create_model() successfully completed......................................
2024-07-04 14:04:24,574:INFO:SubProcess create_model() end ==================================
2024-07-04 14:04:24,574:INFO:choose_better activated
2024-07-04 14:04:24,574:INFO:SubProcess create_model() called ==================================
2024-07-04 14:04:24,574:INFO:Initializing create_model()
2024-07-04 14:04:24,574:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012D478DB150>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4533, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:04:24,574:INFO:Checking exceptions
2024-07-04 14:04:24,574:INFO:Importing libraries
2024-07-04 14:04:24,581:INFO:Copying training dataset
2024-07-04 14:04:24,590:INFO:Defining folds
2024-07-04 14:04:24,590:INFO:Declaring metric variables
2024-07-04 14:04:24,590:INFO:Importing untrained model
2024-07-04 14:04:24,590:INFO:Declaring custom model
2024-07-04 14:04:24,590:INFO:Random Forest Classifier Imported successfully
2024-07-04 14:04:24,590:INFO:Starting cross validation
2024-07-04 14:04:24,607:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:04:32,340:INFO:Calculating mean and std
2024-07-04 14:04:32,341:INFO:Creating metrics dataframe
2024-07-04 14:04:32,341:INFO:Finalizing model
2024-07-04 14:04:32,590:INFO:[LightGBM] [Info] Number of positive: 5574, number of negative: 5574
2024-07-04 14:04:32,590:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001737 seconds.
2024-07-04 14:04:32,590:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-04 14:04:32,590:INFO:[LightGBM] [Info] Total Bins 3318
2024-07-04 14:04:32,590:INFO:[LightGBM] [Info] Number of data points in the train set: 11148, number of used features: 14
2024-07-04 14:04:32,590:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-07-04 14:04:32,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:32,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:04:33,622:INFO:Uploading results into container
2024-07-04 14:04:33,631:INFO:Uploading model into container now
2024-07-04 14:04:33,633:INFO:_master_model_container: 16
2024-07-04 14:04:33,633:INFO:_display_container: 4
2024-07-04 14:04:33,634:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4533, verbose=0,
                       warm_start=False)
2024-07-04 14:04:33,634:INFO:create_model() successfully completed......................................
2024-07-04 14:04:33,898:INFO:SubProcess create_model() end ==================================
2024-07-04 14:04:33,898:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4533, verbose=0,
                       warm_start=False) result for Accuracy is 0.7749
2024-07-04 14:04:33,898:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                       criterion='entropy', max_depth=3,
                       max_features=0.43684839740936343, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=1.2169714716986524e-07,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=128, n_jobs=-1, oob_score=False,
                       random_state=4533, verbose=0, warm_start=False) result for Accuracy is 0.799
2024-07-04 14:04:33,898:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                       criterion='entropy', max_depth=3,
                       max_features=0.43684839740936343, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=1.2169714716986524e-07,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=128, n_jobs=-1, oob_score=False,
                       random_state=4533, verbose=0, warm_start=False) is best model
2024-07-04 14:04:33,913:INFO:choose_better completed
2024-07-04 14:04:33,947:INFO:_master_model_container: 16
2024-07-04 14:04:33,947:INFO:_display_container: 3
2024-07-04 14:04:33,947:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                       criterion='entropy', max_depth=3,
                       max_features=0.43684839740936343, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=1.2169714716986524e-07,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=128, n_jobs=-1, oob_score=False,
                       random_state=4533, verbose=0, warm_start=False)
2024-07-04 14:04:33,947:INFO:tune_model() successfully completed......................................
2024-07-04 14:04:34,205:INFO:Initializing plot_model()
2024-07-04 14:04:34,205:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012D478DB150>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                       criterion='entropy', max_depth=3,
                       max_features=0.43684839740936343, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=1.2169714716986524e-07,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=128, n_jobs=-1, oob_score=False,
                       random_state=4533, verbose=0, warm_start=False), plot=class_report, scale=0.75, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2024-07-04 14:04:34,205:INFO:Checking exceptions
2024-07-04 14:04:34,205:INFO:Soft dependency imported: streamlit: 1.36.0
2024-07-04 14:04:34,274:INFO:Preloading libraries
2024-07-04 14:04:34,305:INFO:Copying training dataset
2024-07-04 14:04:34,305:INFO:Plot type: class_report
2024-07-04 14:04:34,948:INFO:Fitting Model
2024-07-04 14:04:34,956:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2024-07-04 14:04:34,956:INFO:Scoring test/hold-out set
2024-07-04 14:04:35,845:INFO:Visual Rendered Successfully
2024-07-04 14:04:36,054:INFO:plot_model() successfully completed......................................
2024-07-04 14:04:36,055:INFO:Initializing plot_model()
2024-07-04 14:04:36,057:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012D478DB150>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                       criterion='entropy', max_depth=3,
                       max_features=0.43684839740936343, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=1.2169714716986524e-07,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=128, n_jobs=-1, oob_score=False,
                       random_state=4533, verbose=0, warm_start=False), plot=confusion_matrix, scale=0.75, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2024-07-04 14:04:36,057:INFO:Checking exceptions
2024-07-04 14:04:36,057:INFO:Soft dependency imported: streamlit: 1.36.0
2024-07-04 14:04:36,112:INFO:Preloading libraries
2024-07-04 14:04:36,136:INFO:Copying training dataset
2024-07-04 14:04:36,136:INFO:Plot type: confusion_matrix
2024-07-04 14:04:36,311:INFO:Fitting Model
2024-07-04 14:04:36,311:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2024-07-04 14:04:36,311:INFO:Scoring test/hold-out set
2024-07-04 14:04:37,039:INFO:Visual Rendered Successfully
2024-07-04 14:04:37,255:INFO:plot_model() successfully completed......................................
2024-07-04 14:04:37,256:INFO:Initializing plot_model()
2024-07-04 14:04:37,257:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000012D478DB150>, estimator=RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                       criterion='entropy', max_depth=3,
                       max_features=0.43684839740936343, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=1.2169714716986524e-07,
                       min_samples_leaf=3, min_samples_split=7,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=128, n_jobs=-1, oob_score=False,
                       random_state=4533, verbose=0, warm_start=False), plot=auc, scale=0.75, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2024-07-04 14:04:37,258:INFO:Checking exceptions
2024-07-04 14:04:37,258:INFO:Soft dependency imported: streamlit: 1.36.0
2024-07-04 14:04:37,305:INFO:Preloading libraries
2024-07-04 14:04:37,355:INFO:Copying training dataset
2024-07-04 14:04:37,355:INFO:Plot type: auc
2024-07-04 14:04:37,504:INFO:Fitting Model
2024-07-04 14:04:37,504:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2024-07-04 14:04:37,505:INFO:Scoring test/hold-out set
2024-07-04 14:04:38,147:INFO:Visual Rendered Successfully
2024-07-04 14:04:38,395:INFO:plot_model() successfully completed......................................
2024-07-04 14:27:35,554:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 14:27:35,554:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 14:27:35,554:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 14:27:35,554:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 14:31:49,735:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 14:31:49,735:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 14:31:49,736:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 14:31:49,736:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 14:35:46,944:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'France'')
  warnings.warn(

2024-07-04 14:40:12,667:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'France'')
  warnings.warn(

2024-07-04 14:40:37,980:INFO:PyCaret ClassificationExperiment
2024-07-04 14:40:37,980:INFO:Logging name: clf-default-name
2024-07-04 14:40:37,982:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-04 14:40:37,982:INFO:version 3.3.2
2024-07-04 14:40:37,983:INFO:Initializing setup()
2024-07-04 14:40:37,983:INFO:self.USI: 9db1
2024-07-04 14:40:37,984:INFO:self._variable_keys: {'log_plots_param', 'n_jobs_param', 'fix_imbalance', 'y_test', 'exp_id', 'seed', 'logging_param', 'X_train', 'fold_generator', 'gpu_param', 'data', 'y', 'exp_name_log', 'gpu_n_jobs_param', '_available_plots', 'X', 'X_test', 'y_train', 'html_param', 'memory', 'target_param', 'fold_groups_param', 'is_multiclass', 'idx', 'fold_shuffle_param', 'USI', 'pipeline', '_ml_usecase'}
2024-07-04 14:40:37,985:INFO:Checking environment
2024-07-04 14:40:37,985:INFO:python_version: 3.11.3
2024-07-04 14:40:37,985:INFO:python_build: ('tags/v3.11.3:f3909b8', 'Apr  4 2023 23:49:59')
2024-07-04 14:40:37,985:INFO:machine: AMD64
2024-07-04 14:40:38,010:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-04 14:40:38,016:INFO:Memory: svmem(total=8179539968, available=987209728, percent=87.9, used=7192330240, free=987209728)
2024-07-04 14:40:38,016:INFO:Physical Core: 4
2024-07-04 14:40:38,016:INFO:Logical Core: 8
2024-07-04 14:40:38,016:INFO:Checking libraries
2024-07-04 14:40:38,016:INFO:System:
2024-07-04 14:40:38,016:INFO:    python: 3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]
2024-07-04 14:40:38,016:INFO:executable: C:\Program Files\Python311\python.exe
2024-07-04 14:40:38,016:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-04 14:40:38,016:INFO:PyCaret required dependencies:
2024-07-04 14:40:38,183:INFO:                 pip: 23.1.2
2024-07-04 14:40:38,183:INFO:          setuptools: 67.8.0
2024-07-04 14:40:38,183:INFO:             pycaret: 3.3.2
2024-07-04 14:40:38,183:INFO:             IPython: 8.14.0
2024-07-04 14:40:38,183:INFO:          ipywidgets: 8.0.6
2024-07-04 14:40:38,183:INFO:                tqdm: 4.65.0
2024-07-04 14:40:38,183:INFO:               numpy: 1.24.3
2024-07-04 14:40:38,183:INFO:              pandas: 2.1.4
2024-07-04 14:40:38,183:INFO:              jinja2: 3.1.2
2024-07-04 14:40:38,183:INFO:               scipy: 1.10.1
2024-07-04 14:40:38,183:INFO:              joblib: 1.3.2
2024-07-04 14:40:38,183:INFO:             sklearn: 1.4.2
2024-07-04 14:40:38,183:INFO:                pyod: 2.0.1
2024-07-04 14:40:38,183:INFO:            imblearn: 0.12.3
2024-07-04 14:40:38,183:INFO:   category_encoders: 2.6.3
2024-07-04 14:40:38,183:INFO:            lightgbm: 4.4.0
2024-07-04 14:40:38,183:INFO:               numba: 0.57.1
2024-07-04 14:40:38,183:INFO:            requests: 2.31.0
2024-07-04 14:40:38,183:INFO:          matplotlib: 3.7.5
2024-07-04 14:40:38,183:INFO:          scikitplot: 0.3.7
2024-07-04 14:40:38,183:INFO:         yellowbrick: 1.5
2024-07-04 14:40:38,183:INFO:              plotly: 5.15.0
2024-07-04 14:40:38,183:INFO:    plotly-resampler: Not installed
2024-07-04 14:40:38,183:INFO:             kaleido: 0.2.1
2024-07-04 14:40:38,183:INFO:           schemdraw: 0.15
2024-07-04 14:40:38,183:INFO:         statsmodels: 0.14.2
2024-07-04 14:40:38,183:INFO:              sktime: 0.26.0
2024-07-04 14:40:38,183:INFO:               tbats: 1.1.3
2024-07-04 14:40:38,183:INFO:            pmdarima: 2.0.4
2024-07-04 14:40:38,183:INFO:              psutil: 5.9.5
2024-07-04 14:40:38,183:INFO:          markupsafe: 2.1.3
2024-07-04 14:40:38,183:INFO:             pickle5: Not installed
2024-07-04 14:40:38,183:INFO:         cloudpickle: 3.0.0
2024-07-04 14:40:38,183:INFO:         deprecation: 2.1.0
2024-07-04 14:40:38,183:INFO:              xxhash: 3.4.1
2024-07-04 14:40:38,183:INFO:           wurlitzer: Not installed
2024-07-04 14:40:38,183:INFO:PyCaret optional dependencies:
2024-07-04 14:40:38,198:INFO:                shap: 0.45.1
2024-07-04 14:40:38,198:INFO:           interpret: Not installed
2024-07-04 14:40:38,198:INFO:                umap: Not installed
2024-07-04 14:40:38,198:INFO:     ydata_profiling: 4.8.3
2024-07-04 14:40:38,198:INFO:  explainerdashboard: Not installed
2024-07-04 14:40:38,198:INFO:             autoviz: Not installed
2024-07-04 14:40:38,198:INFO:           fairlearn: Not installed
2024-07-04 14:40:38,198:INFO:          deepchecks: Not installed
2024-07-04 14:40:38,198:INFO:             xgboost: Not installed
2024-07-04 14:40:38,198:INFO:            catboost: Not installed
2024-07-04 14:40:38,198:INFO:              kmodes: Not installed
2024-07-04 14:40:38,198:INFO:             mlxtend: Not installed
2024-07-04 14:40:38,198:INFO:       statsforecast: Not installed
2024-07-04 14:40:38,198:INFO:        tune_sklearn: Not installed
2024-07-04 14:40:38,198:INFO:                 ray: Not installed
2024-07-04 14:40:38,198:INFO:            hyperopt: Not installed
2024-07-04 14:40:38,198:INFO:              optuna: 3.2.0
2024-07-04 14:40:38,198:INFO:               skopt: 0.10.2
2024-07-04 14:40:38,198:INFO:              mlflow: Not installed
2024-07-04 14:40:38,198:INFO:              gradio: Not installed
2024-07-04 14:40:38,198:INFO:             fastapi: Not installed
2024-07-04 14:40:38,198:INFO:             uvicorn: Not installed
2024-07-04 14:40:38,198:INFO:              m2cgen: Not installed
2024-07-04 14:40:38,198:INFO:           evidently: Not installed
2024-07-04 14:40:38,198:INFO:               fugue: Not installed
2024-07-04 14:40:38,198:INFO:           streamlit: 1.36.0
2024-07-04 14:40:38,198:INFO:             prophet: Not installed
2024-07-04 14:40:38,198:INFO:None
2024-07-04 14:40:38,198:INFO:Set up data.
2024-07-04 14:40:38,208:INFO:Set up folding strategy.
2024-07-04 14:40:38,208:INFO:Set up train/test split.
2024-07-04 14:40:38,224:INFO:Set up index.
2024-07-04 14:40:38,224:INFO:Assigning column types.
2024-07-04 14:40:38,234:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-04 14:40:38,288:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-04 14:40:38,296:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-04 14:40:38,358:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:40:38,359:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:40:38,456:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-04 14:40:38,457:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-04 14:40:38,509:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:40:38,509:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:40:38,513:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-04 14:40:38,594:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-04 14:40:38,657:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:40:38,657:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:40:38,741:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-04 14:40:38,776:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:40:38,776:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:40:38,783:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-04 14:40:38,904:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:40:38,904:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:40:39,023:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:40:39,023:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:40:39,023:INFO:Preparing preprocessing pipeline...
2024-07-04 14:40:39,034:INFO:Set up simple imputation.
2024-07-04 14:40:39,039:INFO:Set up encoding of ordinal features.
2024-07-04 14:40:39,039:INFO:Set up encoding of categorical features.
2024-07-04 14:40:39,039:INFO:Set up imbalanced handling.
2024-07-04 14:40:39,039:INFO:Set up feature normalization.
2024-07-04 14:40:39,039:INFO:Set up feature selection.
2024-07-04 14:40:39,186:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:40:39,186:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:40:40,449:INFO:Finished creating preprocessing pipeline.
2024-07-04 14:40:40,503:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\PHYOSA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['customer_id', 'credit_score',
                                             'age', 'tenure', 'balance',
                                             'products_number', 'credit_card',
                                             'active_member',
                                             'estimated_salary', 'churn_x'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=N...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=2,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2024-07-04 14:40:40,503:INFO:Creating final display dataframe.
2024-07-04 14:40:41,322:INFO:Setup _display_container:                     Description             Value
0                    Session id              3037
1                        Target           churn_y
2                   Target type            Binary
3           Original data shape       (10000, 13)
4        Transformed data shape        (14148, 3)
5   Transformed train set shape        (11148, 3)
6    Transformed test set shape         (3000, 3)
7              Numeric features                10
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation            median
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15                Fix imbalance              True
16         Fix imbalance method             SMOTE
17                    Normalize              True
18             Normalize method            robust
19            Feature selection              True
20     Feature selection method           classic
21  Feature selection estimator          lightgbm
22  Number of features selected               0.2
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              9db1
2024-07-04 14:40:41,494:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:40:41,496:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:40:41,640:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:40:41,640:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 14:40:41,645:INFO:setup() successfully completed in 3.79s...............
2024-07-04 14:40:41,654:INFO:Initializing compare_models()
2024-07-04 14:40:41,654:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8C283FE50>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001D8C283FE50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-07-04 14:40:41,654:INFO:Checking exceptions
2024-07-04 14:40:41,665:INFO:Preparing display monitor
2024-07-04 14:40:41,668:INFO:Initializing Logistic Regression
2024-07-04 14:40:41,668:INFO:Total runtime is 0.0 minutes
2024-07-04 14:40:41,668:INFO:SubProcess create_model() called ==================================
2024-07-04 14:40:41,669:INFO:Initializing create_model()
2024-07-04 14:40:41,669:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8C283FE50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D8CCD88D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:40:41,669:INFO:Checking exceptions
2024-07-04 14:40:41,669:INFO:Importing libraries
2024-07-04 14:40:41,669:INFO:Copying training dataset
2024-07-04 14:40:41,678:INFO:Defining folds
2024-07-04 14:40:41,679:INFO:Declaring metric variables
2024-07-04 14:40:41,679:INFO:Importing untrained model
2024-07-04 14:40:41,679:INFO:Logistic Regression Imported successfully
2024-07-04 14:40:41,680:INFO:Starting cross validation
2024-07-04 14:40:41,688:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:41:06,304:INFO:Calculating mean and std
2024-07-04 14:41:06,309:INFO:Creating metrics dataframe
2024-07-04 14:41:06,322:INFO:Uploading results into container
2024-07-04 14:41:06,324:INFO:Uploading model into container now
2024-07-04 14:41:06,326:INFO:_master_model_container: 1
2024-07-04 14:41:06,326:INFO:_display_container: 2
2024-07-04 14:41:06,328:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3037, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-04 14:41:06,328:INFO:create_model() successfully completed......................................
2024-07-04 14:41:06,694:INFO:SubProcess create_model() end ==================================
2024-07-04 14:41:06,695:INFO:Creating metrics dataframe
2024-07-04 14:41:06,704:INFO:Initializing K Neighbors Classifier
2024-07-04 14:41:06,704:INFO:Total runtime is 0.4172626535097758 minutes
2024-07-04 14:41:06,705:INFO:SubProcess create_model() called ==================================
2024-07-04 14:41:06,705:INFO:Initializing create_model()
2024-07-04 14:41:06,705:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8C283FE50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D8CCD88D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:41:06,705:INFO:Checking exceptions
2024-07-04 14:41:06,705:INFO:Importing libraries
2024-07-04 14:41:06,705:INFO:Copying training dataset
2024-07-04 14:41:06,725:INFO:Defining folds
2024-07-04 14:41:06,725:INFO:Declaring metric variables
2024-07-04 14:41:06,726:INFO:Importing untrained model
2024-07-04 14:41:06,727:INFO:K Neighbors Classifier Imported successfully
2024-07-04 14:41:06,728:INFO:Starting cross validation
2024-07-04 14:41:06,745:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:41:11,449:INFO:Calculating mean and std
2024-07-04 14:41:11,451:INFO:Creating metrics dataframe
2024-07-04 14:41:11,456:INFO:Uploading results into container
2024-07-04 14:41:11,457:INFO:Uploading model into container now
2024-07-04 14:41:11,460:INFO:_master_model_container: 2
2024-07-04 14:41:11,460:INFO:_display_container: 2
2024-07-04 14:41:11,461:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-04 14:41:11,461:INFO:create_model() successfully completed......................................
2024-07-04 14:41:11,771:INFO:SubProcess create_model() end ==================================
2024-07-04 14:41:11,772:INFO:Creating metrics dataframe
2024-07-04 14:41:11,784:INFO:Initializing Naive Bayes
2024-07-04 14:41:11,784:INFO:Total runtime is 0.5019368171691895 minutes
2024-07-04 14:41:11,785:INFO:SubProcess create_model() called ==================================
2024-07-04 14:41:11,786:INFO:Initializing create_model()
2024-07-04 14:41:11,786:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8C283FE50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D8CCD88D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:41:11,786:INFO:Checking exceptions
2024-07-04 14:41:11,786:INFO:Importing libraries
2024-07-04 14:41:11,786:INFO:Copying training dataset
2024-07-04 14:41:11,822:INFO:Defining folds
2024-07-04 14:41:11,823:INFO:Declaring metric variables
2024-07-04 14:41:11,824:INFO:Importing untrained model
2024-07-04 14:41:11,825:INFO:Naive Bayes Imported successfully
2024-07-04 14:41:11,827:INFO:Starting cross validation
2024-07-04 14:41:11,849:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:41:17,493:INFO:Calculating mean and std
2024-07-04 14:41:17,494:INFO:Creating metrics dataframe
2024-07-04 14:41:17,497:INFO:Uploading results into container
2024-07-04 14:41:17,499:INFO:Uploading model into container now
2024-07-04 14:41:17,500:INFO:_master_model_container: 3
2024-07-04 14:41:17,500:INFO:_display_container: 2
2024-07-04 14:41:17,500:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-04 14:41:17,501:INFO:create_model() successfully completed......................................
2024-07-04 14:41:17,765:INFO:SubProcess create_model() end ==================================
2024-07-04 14:41:17,766:INFO:Creating metrics dataframe
2024-07-04 14:41:17,776:INFO:Initializing Decision Tree Classifier
2024-07-04 14:41:17,777:INFO:Total runtime is 0.6018179853757223 minutes
2024-07-04 14:41:17,777:INFO:SubProcess create_model() called ==================================
2024-07-04 14:41:17,778:INFO:Initializing create_model()
2024-07-04 14:41:17,778:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8C283FE50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D8CCD88D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:41:17,778:INFO:Checking exceptions
2024-07-04 14:41:17,778:INFO:Importing libraries
2024-07-04 14:41:17,779:INFO:Copying training dataset
2024-07-04 14:41:17,806:INFO:Defining folds
2024-07-04 14:41:17,806:INFO:Declaring metric variables
2024-07-04 14:41:17,807:INFO:Importing untrained model
2024-07-04 14:41:17,808:INFO:Decision Tree Classifier Imported successfully
2024-07-04 14:41:17,809:INFO:Starting cross validation
2024-07-04 14:41:17,825:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:41:23,886:INFO:Calculating mean and std
2024-07-04 14:41:23,892:INFO:Creating metrics dataframe
2024-07-04 14:41:23,904:INFO:Uploading results into container
2024-07-04 14:41:23,909:INFO:Uploading model into container now
2024-07-04 14:41:23,909:INFO:_master_model_container: 4
2024-07-04 14:41:23,910:INFO:_display_container: 2
2024-07-04 14:41:23,910:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=3037, splitter='best')
2024-07-04 14:41:23,910:INFO:create_model() successfully completed......................................
2024-07-04 14:41:24,387:INFO:SubProcess create_model() end ==================================
2024-07-04 14:41:24,387:INFO:Creating metrics dataframe
2024-07-04 14:41:24,408:INFO:Initializing SVM - Linear Kernel
2024-07-04 14:41:24,409:INFO:Total runtime is 0.7123473048210145 minutes
2024-07-04 14:41:24,410:INFO:SubProcess create_model() called ==================================
2024-07-04 14:41:24,414:INFO:Initializing create_model()
2024-07-04 14:41:24,414:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8C283FE50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D8CCD88D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:41:24,414:INFO:Checking exceptions
2024-07-04 14:41:24,415:INFO:Importing libraries
2024-07-04 14:41:24,415:INFO:Copying training dataset
2024-07-04 14:41:24,472:INFO:Defining folds
2024-07-04 14:41:24,473:INFO:Declaring metric variables
2024-07-04 14:41:24,473:INFO:Importing untrained model
2024-07-04 14:41:24,474:INFO:SVM - Linear Kernel Imported successfully
2024-07-04 14:41:24,475:INFO:Starting cross validation
2024-07-04 14:41:24,502:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:41:29,432:INFO:Calculating mean and std
2024-07-04 14:41:29,435:INFO:Creating metrics dataframe
2024-07-04 14:41:29,447:INFO:Uploading results into container
2024-07-04 14:41:29,450:INFO:Uploading model into container now
2024-07-04 14:41:29,452:INFO:_master_model_container: 5
2024-07-04 14:41:29,452:INFO:_display_container: 2
2024-07-04 14:41:29,454:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3037, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-04 14:41:29,455:INFO:create_model() successfully completed......................................
2024-07-04 14:41:29,813:INFO:SubProcess create_model() end ==================================
2024-07-04 14:41:29,813:INFO:Creating metrics dataframe
2024-07-04 14:41:29,826:INFO:Initializing Ridge Classifier
2024-07-04 14:41:29,826:INFO:Total runtime is 0.802629590034485 minutes
2024-07-04 14:41:29,826:INFO:SubProcess create_model() called ==================================
2024-07-04 14:41:29,826:INFO:Initializing create_model()
2024-07-04 14:41:29,826:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8C283FE50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D8CCD88D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:41:29,826:INFO:Checking exceptions
2024-07-04 14:41:29,826:INFO:Importing libraries
2024-07-04 14:41:29,826:INFO:Copying training dataset
2024-07-04 14:41:29,863:INFO:Defining folds
2024-07-04 14:41:29,863:INFO:Declaring metric variables
2024-07-04 14:41:29,864:INFO:Importing untrained model
2024-07-04 14:41:29,865:INFO:Ridge Classifier Imported successfully
2024-07-04 14:41:29,866:INFO:Starting cross validation
2024-07-04 14:41:29,881:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:41:34,272:INFO:Calculating mean and std
2024-07-04 14:41:34,273:INFO:Creating metrics dataframe
2024-07-04 14:41:34,279:INFO:Uploading results into container
2024-07-04 14:41:34,280:INFO:Uploading model into container now
2024-07-04 14:41:34,281:INFO:_master_model_container: 6
2024-07-04 14:41:34,281:INFO:_display_container: 2
2024-07-04 14:41:34,282:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3037, solver='auto',
                tol=0.0001)
2024-07-04 14:41:34,282:INFO:create_model() successfully completed......................................
2024-07-04 14:41:34,611:INFO:SubProcess create_model() end ==================================
2024-07-04 14:41:34,611:INFO:Creating metrics dataframe
2024-07-04 14:41:34,622:INFO:Initializing Random Forest Classifier
2024-07-04 14:41:34,623:INFO:Total runtime is 0.8825911124547323 minutes
2024-07-04 14:41:34,624:INFO:SubProcess create_model() called ==================================
2024-07-04 14:41:34,625:INFO:Initializing create_model()
2024-07-04 14:41:34,626:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8C283FE50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D8CCD88D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:41:34,626:INFO:Checking exceptions
2024-07-04 14:41:34,627:INFO:Importing libraries
2024-07-04 14:41:34,627:INFO:Copying training dataset
2024-07-04 14:41:34,653:INFO:Defining folds
2024-07-04 14:41:34,653:INFO:Declaring metric variables
2024-07-04 14:41:34,654:INFO:Importing untrained model
2024-07-04 14:41:34,657:INFO:Random Forest Classifier Imported successfully
2024-07-04 14:41:34,658:INFO:Starting cross validation
2024-07-04 14:41:34,680:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:41:48,105:INFO:Calculating mean and std
2024-07-04 14:41:48,105:INFO:Creating metrics dataframe
2024-07-04 14:41:48,114:INFO:Uploading results into container
2024-07-04 14:41:48,115:INFO:Uploading model into container now
2024-07-04 14:41:48,117:INFO:_master_model_container: 7
2024-07-04 14:41:48,117:INFO:_display_container: 2
2024-07-04 14:41:48,119:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3037, verbose=0,
                       warm_start=False)
2024-07-04 14:41:48,123:INFO:create_model() successfully completed......................................
2024-07-04 14:41:48,397:INFO:SubProcess create_model() end ==================================
2024-07-04 14:41:48,397:INFO:Creating metrics dataframe
2024-07-04 14:41:48,408:INFO:Initializing Quadratic Discriminant Analysis
2024-07-04 14:41:48,408:INFO:Total runtime is 1.112333631515503 minutes
2024-07-04 14:41:48,409:INFO:SubProcess create_model() called ==================================
2024-07-04 14:41:48,410:INFO:Initializing create_model()
2024-07-04 14:41:48,410:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8C283FE50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D8CCD88D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:41:48,410:INFO:Checking exceptions
2024-07-04 14:41:48,410:INFO:Importing libraries
2024-07-04 14:41:48,410:INFO:Copying training dataset
2024-07-04 14:41:48,437:INFO:Defining folds
2024-07-04 14:41:48,437:INFO:Declaring metric variables
2024-07-04 14:41:48,437:INFO:Importing untrained model
2024-07-04 14:41:48,441:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-04 14:41:48,441:INFO:Starting cross validation
2024-07-04 14:41:48,455:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:41:50,916:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 14:41:50,930:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 14:41:51,038:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:41:51,038:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:41:51,038:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 14:41:51,043:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:41:51,043:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:41:51,043:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 14:41:51,052:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:41:51,053:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:41:51,053:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 14:41:51,059:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 14:41:51,077:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:41:51,077:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:41:51,077:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 14:41:51,087:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 14:41:51,107:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:41:51,108:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:41:51,210:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 14:41:51,297:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:41:51,297:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:41:51,297:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 14:41:51,304:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:41:51,304:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:41:51,304:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 14:41:51,343:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 14:41:51,360:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:41:51,464:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 14:41:51,544:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 14:41:51,585:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:41:51,585:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:41:51,586:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 14:41:51,590:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:41:51,591:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:41:51,591:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 14:41:51,603:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 14:41:51,629:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:41:51,633:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:41:51,638:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:41:51,638:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 14:41:51,643:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:41:51,643:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:41:51,643:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 14:41:51,653:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 14:41:51,672:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:41:51,916:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 14:41:51,925:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 14:41:51,995:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:41:51,995:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:41:51,995:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 14:41:52,000:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:41:52,000:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:41:52,001:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 14:41:52,014:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 14:41:52,014:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:41:52,014:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:41:52,014:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 14:41:52,025:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:41:52,025:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 14:41:52,025:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 14:41:52,032:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:41:52,033:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 14:41:52,047:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:41:52,067:INFO:Calculating mean and std
2024-07-04 14:41:52,067:INFO:Creating metrics dataframe
2024-07-04 14:41:52,067:INFO:Uploading results into container
2024-07-04 14:41:52,073:INFO:Uploading model into container now
2024-07-04 14:41:52,073:INFO:_master_model_container: 8
2024-07-04 14:41:52,073:INFO:_display_container: 2
2024-07-04 14:41:52,073:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-04 14:41:52,073:INFO:create_model() successfully completed......................................
2024-07-04 14:41:52,315:INFO:SubProcess create_model() end ==================================
2024-07-04 14:41:52,315:INFO:Creating metrics dataframe
2024-07-04 14:41:52,326:INFO:Initializing Ada Boost Classifier
2024-07-04 14:41:52,326:INFO:Total runtime is 1.177632745107015 minutes
2024-07-04 14:41:52,326:INFO:SubProcess create_model() called ==================================
2024-07-04 14:41:52,326:INFO:Initializing create_model()
2024-07-04 14:41:52,326:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8C283FE50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D8CCD88D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:41:52,326:INFO:Checking exceptions
2024-07-04 14:41:52,326:INFO:Importing libraries
2024-07-04 14:41:52,326:INFO:Copying training dataset
2024-07-04 14:41:52,373:INFO:Defining folds
2024-07-04 14:41:52,373:INFO:Declaring metric variables
2024-07-04 14:41:52,373:INFO:Importing untrained model
2024-07-04 14:41:52,373:INFO:Ada Boost Classifier Imported successfully
2024-07-04 14:41:52,373:INFO:Starting cross validation
2024-07-04 14:41:52,391:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:41:53,815:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 14:41:53,847:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 14:41:53,858:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 14:41:53,913:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 14:41:54,055:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 14:41:54,333:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 14:41:54,626:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 14:41:54,865:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 14:41:55,765:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 14:41:55,798:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 14:41:56,084:INFO:Calculating mean and std
2024-07-04 14:41:56,087:INFO:Creating metrics dataframe
2024-07-04 14:41:56,092:INFO:Uploading results into container
2024-07-04 14:41:56,093:INFO:Uploading model into container now
2024-07-04 14:41:56,093:INFO:_master_model_container: 9
2024-07-04 14:41:56,093:INFO:_display_container: 2
2024-07-04 14:41:56,093:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3037)
2024-07-04 14:41:56,093:INFO:create_model() successfully completed......................................
2024-07-04 14:41:56,314:INFO:SubProcess create_model() end ==================================
2024-07-04 14:41:56,314:INFO:Creating metrics dataframe
2024-07-04 14:41:56,326:INFO:Initializing Gradient Boosting Classifier
2024-07-04 14:41:56,326:INFO:Total runtime is 1.244301394621531 minutes
2024-07-04 14:41:56,326:INFO:SubProcess create_model() called ==================================
2024-07-04 14:41:56,326:INFO:Initializing create_model()
2024-07-04 14:41:56,326:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8C283FE50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D8CCD88D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:41:56,326:INFO:Checking exceptions
2024-07-04 14:41:56,326:INFO:Importing libraries
2024-07-04 14:41:56,326:INFO:Copying training dataset
2024-07-04 14:41:56,351:INFO:Defining folds
2024-07-04 14:41:56,351:INFO:Declaring metric variables
2024-07-04 14:41:56,352:INFO:Importing untrained model
2024-07-04 14:41:56,353:INFO:Gradient Boosting Classifier Imported successfully
2024-07-04 14:41:56,354:INFO:Starting cross validation
2024-07-04 14:41:56,372:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:46:05,770:INFO:Calculating mean and std
2024-07-04 14:46:05,773:INFO:Creating metrics dataframe
2024-07-04 14:46:05,777:INFO:Uploading results into container
2024-07-04 14:46:05,778:INFO:Uploading model into container now
2024-07-04 14:46:05,779:INFO:_master_model_container: 10
2024-07-04 14:46:05,779:INFO:_display_container: 2
2024-07-04 14:46:05,780:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3037, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-04 14:46:05,780:INFO:create_model() successfully completed......................................
2024-07-04 14:46:06,027:INFO:SubProcess create_model() end ==================================
2024-07-04 14:46:06,028:INFO:Creating metrics dataframe
2024-07-04 14:46:06,033:INFO:Initializing Linear Discriminant Analysis
2024-07-04 14:46:06,033:INFO:Total runtime is 5.406079196929932 minutes
2024-07-04 14:46:06,033:INFO:SubProcess create_model() called ==================================
2024-07-04 14:46:06,034:INFO:Initializing create_model()
2024-07-04 14:46:06,034:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8C283FE50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D8CCD88D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:46:06,034:INFO:Checking exceptions
2024-07-04 14:46:06,034:INFO:Importing libraries
2024-07-04 14:46:06,034:INFO:Copying training dataset
2024-07-04 14:46:06,053:INFO:Defining folds
2024-07-04 14:46:06,053:INFO:Declaring metric variables
2024-07-04 14:46:06,053:INFO:Importing untrained model
2024-07-04 14:46:06,054:INFO:Linear Discriminant Analysis Imported successfully
2024-07-04 14:46:06,054:INFO:Starting cross validation
2024-07-04 14:46:06,067:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:46:08,420:INFO:Calculating mean and std
2024-07-04 14:46:08,421:INFO:Creating metrics dataframe
2024-07-04 14:46:08,423:INFO:Uploading results into container
2024-07-04 14:46:08,424:INFO:Uploading model into container now
2024-07-04 14:46:08,424:INFO:_master_model_container: 11
2024-07-04 14:46:08,424:INFO:_display_container: 2
2024-07-04 14:46:08,425:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-04 14:46:08,425:INFO:create_model() successfully completed......................................
2024-07-04 14:46:08,618:INFO:SubProcess create_model() end ==================================
2024-07-04 14:46:08,619:INFO:Creating metrics dataframe
2024-07-04 14:46:08,627:INFO:Initializing Extra Trees Classifier
2024-07-04 14:46:08,628:INFO:Total runtime is 5.4493310491244005 minutes
2024-07-04 14:46:08,629:INFO:SubProcess create_model() called ==================================
2024-07-04 14:46:08,629:INFO:Initializing create_model()
2024-07-04 14:46:08,629:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8C283FE50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D8CCD88D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:46:08,630:INFO:Checking exceptions
2024-07-04 14:46:08,630:INFO:Importing libraries
2024-07-04 14:46:08,630:INFO:Copying training dataset
2024-07-04 14:46:08,647:INFO:Defining folds
2024-07-04 14:46:08,647:INFO:Declaring metric variables
2024-07-04 14:46:08,647:INFO:Importing untrained model
2024-07-04 14:46:08,649:INFO:Extra Trees Classifier Imported successfully
2024-07-04 14:46:08,649:INFO:Starting cross validation
2024-07-04 14:46:08,663:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:46:15,235:INFO:Calculating mean and std
2024-07-04 14:46:15,238:INFO:Creating metrics dataframe
2024-07-04 14:46:15,243:INFO:Uploading results into container
2024-07-04 14:46:15,244:INFO:Uploading model into container now
2024-07-04 14:46:15,246:INFO:_master_model_container: 12
2024-07-04 14:46:15,246:INFO:_display_container: 2
2024-07-04 14:46:15,247:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=3037, verbose=0,
                     warm_start=False)
2024-07-04 14:46:15,247:INFO:create_model() successfully completed......................................
2024-07-04 14:46:15,475:INFO:SubProcess create_model() end ==================================
2024-07-04 14:46:15,476:INFO:Creating metrics dataframe
2024-07-04 14:46:15,482:INFO:Initializing Light Gradient Boosting Machine
2024-07-04 14:46:15,482:INFO:Total runtime is 5.563567972183228 minutes
2024-07-04 14:46:15,482:INFO:SubProcess create_model() called ==================================
2024-07-04 14:46:15,483:INFO:Initializing create_model()
2024-07-04 14:46:15,483:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8C283FE50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D8CCD88D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:46:15,483:INFO:Checking exceptions
2024-07-04 14:46:15,483:INFO:Importing libraries
2024-07-04 14:46:15,483:INFO:Copying training dataset
2024-07-04 14:46:15,502:INFO:Defining folds
2024-07-04 14:46:15,502:INFO:Declaring metric variables
2024-07-04 14:46:15,503:INFO:Importing untrained model
2024-07-04 14:46:15,503:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-04 14:46:15,504:INFO:Starting cross validation
2024-07-04 14:46:15,514:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:46:19,338:INFO:Calculating mean and std
2024-07-04 14:46:19,340:INFO:Creating metrics dataframe
2024-07-04 14:46:19,343:INFO:Uploading results into container
2024-07-04 14:46:19,344:INFO:Uploading model into container now
2024-07-04 14:46:19,345:INFO:_master_model_container: 13
2024-07-04 14:46:19,345:INFO:_display_container: 2
2024-07-04 14:46:19,346:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3037, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-04 14:46:19,346:INFO:create_model() successfully completed......................................
2024-07-04 14:46:19,553:INFO:SubProcess create_model() end ==================================
2024-07-04 14:46:19,555:INFO:Creating metrics dataframe
2024-07-04 14:46:19,562:INFO:Initializing Dummy Classifier
2024-07-04 14:46:19,562:INFO:Total runtime is 5.631572492917379 minutes
2024-07-04 14:46:19,563:INFO:SubProcess create_model() called ==================================
2024-07-04 14:46:19,563:INFO:Initializing create_model()
2024-07-04 14:46:19,563:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8C283FE50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D8CCD88D50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:46:19,563:INFO:Checking exceptions
2024-07-04 14:46:19,563:INFO:Importing libraries
2024-07-04 14:46:19,563:INFO:Copying training dataset
2024-07-04 14:46:19,584:INFO:Defining folds
2024-07-04 14:46:19,584:INFO:Declaring metric variables
2024-07-04 14:46:19,584:INFO:Importing untrained model
2024-07-04 14:46:19,585:INFO:Dummy Classifier Imported successfully
2024-07-04 14:46:19,587:INFO:Starting cross validation
2024-07-04 14:46:19,597:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:46:22,842:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:46:22,858:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:46:22,889:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:46:22,934:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:46:23,127:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:46:23,284:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:46:23,383:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:46:23,429:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:46:24,054:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:46:24,064:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 14:46:24,089:INFO:Calculating mean and std
2024-07-04 14:46:24,091:INFO:Creating metrics dataframe
2024-07-04 14:46:24,098:INFO:Uploading results into container
2024-07-04 14:46:24,101:INFO:Uploading model into container now
2024-07-04 14:46:24,102:INFO:_master_model_container: 14
2024-07-04 14:46:24,102:INFO:_display_container: 2
2024-07-04 14:46:24,104:INFO:DummyClassifier(constant=None, random_state=3037, strategy='prior')
2024-07-04 14:46:24,104:INFO:create_model() successfully completed......................................
2024-07-04 14:46:24,413:INFO:SubProcess create_model() end ==================================
2024-07-04 14:46:24,416:INFO:Creating metrics dataframe
2024-07-04 14:46:24,437:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-07-04 14:46:24,446:INFO:Initializing create_model()
2024-07-04 14:46:24,446:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8C283FE50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3037, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:46:24,446:INFO:Checking exceptions
2024-07-04 14:46:24,449:INFO:Importing libraries
2024-07-04 14:46:24,449:INFO:Copying training dataset
2024-07-04 14:46:24,481:INFO:Defining folds
2024-07-04 14:46:24,484:INFO:Declaring metric variables
2024-07-04 14:46:24,485:INFO:Importing untrained model
2024-07-04 14:46:24,485:INFO:Declaring custom model
2024-07-04 14:46:24,487:INFO:Random Forest Classifier Imported successfully
2024-07-04 14:46:24,498:INFO:Cross validation set to False
2024-07-04 14:46:24,499:INFO:Fitting Model
2024-07-04 14:46:24,901:INFO:[LightGBM] [Info] Number of positive: 5574, number of negative: 5574
2024-07-04 14:46:24,903:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001169 seconds.
2024-07-04 14:46:24,904:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-04 14:46:24,904:INFO:[LightGBM] [Info] Total Bins 3318
2024-07-04 14:46:24,904:INFO:[LightGBM] [Info] Number of data points in the train set: 11148, number of used features: 14
2024-07-04 14:46:24,905:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-07-04 14:46:24,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:24,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:46:25,763:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3037, verbose=0,
                       warm_start=False)
2024-07-04 14:46:25,763:INFO:create_model() successfully completed......................................
2024-07-04 14:46:26,127:INFO:_master_model_container: 14
2024-07-04 14:46:26,127:INFO:_display_container: 2
2024-07-04 14:46:26,128:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3037, verbose=0,
                       warm_start=False)
2024-07-04 14:46:26,129:INFO:compare_models() successfully completed......................................
2024-07-04 14:46:26,158:INFO:Initializing tune_model()
2024-07-04 14:46:26,159:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8C283FE50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3037, verbose=0,
                       warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=bayesian, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-04 14:46:26,160:INFO:Checking exceptions
2024-07-04 14:46:26,160:INFO:Soft dependency imported: skopt: 0.10.2
2024-07-04 14:46:26,342:INFO:Copying training dataset
2024-07-04 14:46:26,364:INFO:Checking base model
2024-07-04 14:46:26,365:INFO:Base model : Random Forest Classifier
2024-07-04 14:46:26,367:INFO:Declaring metric variables
2024-07-04 14:46:26,368:INFO:Defining Hyperparameters
2024-07-04 14:46:26,660:INFO:Tuning with n_jobs=-1
2024-07-04 14:46:26,687:INFO:Initializing skopt.BayesSearchCV
2024-07-04 14:50:57,624:INFO:best_params: OrderedDict([('actual_estimator__bootstrap', True), ('actual_estimator__class_weight', 'balanced'), ('actual_estimator__criterion', 'entropy'), ('actual_estimator__max_depth', 11), ('actual_estimator__max_features', 0.8663053030406835), ('actual_estimator__min_impurity_decrease', 0.0004773783125886137), ('actual_estimator__min_samples_leaf', 3), ('actual_estimator__min_samples_split', 6), ('actual_estimator__n_estimators', 18)])
2024-07-04 14:50:57,627:INFO:Hyperparameter search completed
2024-07-04 14:50:57,627:INFO:SubProcess create_model() called ==================================
2024-07-04 14:50:57,627:INFO:Initializing create_model()
2024-07-04 14:50:57,627:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8C283FE50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3037, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D8CC69FF90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'bootstrap': True, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 11, 'max_features': 0.8663053030406835, 'min_impurity_decrease': 0.0004773783125886137, 'min_samples_leaf': 3, 'min_samples_split': 6, 'n_estimators': 18})
2024-07-04 14:50:57,627:INFO:Checking exceptions
2024-07-04 14:50:57,627:INFO:Importing libraries
2024-07-04 14:50:57,627:INFO:Copying training dataset
2024-07-04 14:50:57,634:INFO:Defining folds
2024-07-04 14:50:57,634:INFO:Declaring metric variables
2024-07-04 14:50:57,634:INFO:Importing untrained model
2024-07-04 14:50:57,634:INFO:Declaring custom model
2024-07-04 14:50:57,634:INFO:Random Forest Classifier Imported successfully
2024-07-04 14:50:57,634:INFO:Starting cross validation
2024-07-04 14:50:57,644:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:51:00,430:INFO:Calculating mean and std
2024-07-04 14:51:00,430:INFO:Creating metrics dataframe
2024-07-04 14:51:00,434:INFO:Finalizing model
2024-07-04 14:51:00,624:INFO:[LightGBM] [Info] Number of positive: 5574, number of negative: 5574
2024-07-04 14:51:00,627:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001575 seconds.
2024-07-04 14:51:00,627:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-04 14:51:00,627:INFO:[LightGBM] [Info] Total Bins 3318
2024-07-04 14:51:00,628:INFO:[LightGBM] [Info] Number of data points in the train set: 11148, number of used features: 14
2024-07-04 14:51:00,628:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-07-04 14:51:00,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:00,798:INFO:Uploading results into container
2024-07-04 14:51:00,799:INFO:Uploading model into container now
2024-07-04 14:51:00,799:INFO:_master_model_container: 15
2024-07-04 14:51:00,799:INFO:_display_container: 3
2024-07-04 14:51:00,799:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11,
                       max_features=0.8663053030406835, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=0.0004773783125886137,
                       min_samples_leaf=3, min_samples_split=6,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=18, n_jobs=-1, oob_score=False,
                       random_state=3037, verbose=0, warm_start=False)
2024-07-04 14:51:00,799:INFO:create_model() successfully completed......................................
2024-07-04 14:51:00,964:INFO:SubProcess create_model() end ==================================
2024-07-04 14:51:00,964:INFO:choose_better activated
2024-07-04 14:51:00,964:INFO:SubProcess create_model() called ==================================
2024-07-04 14:51:00,964:INFO:Initializing create_model()
2024-07-04 14:51:00,964:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8C283FE50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3037, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 14:51:00,964:INFO:Checking exceptions
2024-07-04 14:51:00,969:INFO:Importing libraries
2024-07-04 14:51:00,969:INFO:Copying training dataset
2024-07-04 14:51:00,974:INFO:Defining folds
2024-07-04 14:51:00,974:INFO:Declaring metric variables
2024-07-04 14:51:00,974:INFO:Importing untrained model
2024-07-04 14:51:00,974:INFO:Declaring custom model
2024-07-04 14:51:00,974:INFO:Random Forest Classifier Imported successfully
2024-07-04 14:51:00,984:INFO:Starting cross validation
2024-07-04 14:51:00,990:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 14:51:08,034:INFO:Calculating mean and std
2024-07-04 14:51:08,034:INFO:Creating metrics dataframe
2024-07-04 14:51:08,034:INFO:Finalizing model
2024-07-04 14:51:08,246:INFO:[LightGBM] [Info] Number of positive: 5574, number of negative: 5574
2024-07-04 14:51:08,248:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000925 seconds.
2024-07-04 14:51:08,248:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-04 14:51:08,248:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-04 14:51:08,248:INFO:[LightGBM] [Info] Total Bins 3318
2024-07-04 14:51:08,248:INFO:[LightGBM] [Info] Number of data points in the train set: 11148, number of used features: 14
2024-07-04 14:51:08,248:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-07-04 14:51:08,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 14:51:08,740:INFO:Uploading results into container
2024-07-04 14:51:08,740:INFO:Uploading model into container now
2024-07-04 14:51:08,744:INFO:_master_model_container: 16
2024-07-04 14:51:08,744:INFO:_display_container: 4
2024-07-04 14:51:08,744:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3037, verbose=0,
                       warm_start=False)
2024-07-04 14:51:08,744:INFO:create_model() successfully completed......................................
2024-07-04 14:51:08,899:INFO:SubProcess create_model() end ==================================
2024-07-04 14:51:08,901:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3037, verbose=0,
                       warm_start=False) result for Accuracy is 0.866
2024-07-04 14:51:08,901:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=11,
                       max_features=0.8663053030406835, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=0.0004773783125886137,
                       min_samples_leaf=3, min_samples_split=6,
                       min_weight_fraction_leaf=0.0, monotonic_cst=None,
                       n_estimators=18, n_jobs=-1, oob_score=False,
                       random_state=3037, verbose=0, warm_start=False) result for Accuracy is 0.8404
2024-07-04 14:51:08,904:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3037, verbose=0,
                       warm_start=False) is best model
2024-07-04 14:51:08,904:INFO:choose_better completed
2024-07-04 14:51:08,904:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-04 14:51:08,929:INFO:_master_model_container: 16
2024-07-04 14:51:08,929:INFO:_display_container: 3
2024-07-04 14:51:08,930:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3037, verbose=0,
                       warm_start=False)
2024-07-04 14:51:08,930:INFO:tune_model() successfully completed......................................
2024-07-04 14:51:09,104:INFO:Initializing plot_model()
2024-07-04 14:51:09,104:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8C283FE50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3037, verbose=0,
                       warm_start=False), plot=class_report, scale=0.75, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2024-07-04 14:51:09,104:INFO:Checking exceptions
2024-07-04 14:51:09,104:INFO:Soft dependency imported: streamlit: 1.36.0
2024-07-04 14:51:09,157:INFO:Preloading libraries
2024-07-04 14:51:09,165:INFO:Copying training dataset
2024-07-04 14:51:09,165:INFO:Plot type: class_report
2024-07-04 14:51:09,304:INFO:Fitting Model
2024-07-04 14:51:09,304:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2024-07-04 14:51:09,304:INFO:Scoring test/hold-out set
2024-07-04 14:51:09,779:INFO:Visual Rendered Successfully
2024-07-04 14:51:09,914:INFO:plot_model() successfully completed......................................
2024-07-04 14:51:09,918:INFO:Initializing plot_model()
2024-07-04 14:51:09,918:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8C283FE50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3037, verbose=0,
                       warm_start=False), plot=confusion_matrix, scale=0.75, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2024-07-04 14:51:09,918:INFO:Checking exceptions
2024-07-04 14:51:09,918:INFO:Soft dependency imported: streamlit: 1.36.0
2024-07-04 14:51:09,954:INFO:Preloading libraries
2024-07-04 14:51:09,964:INFO:Copying training dataset
2024-07-04 14:51:09,964:INFO:Plot type: confusion_matrix
2024-07-04 14:51:10,076:INFO:Fitting Model
2024-07-04 14:51:10,076:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2024-07-04 14:51:10,076:INFO:Scoring test/hold-out set
2024-07-04 14:51:10,613:INFO:Visual Rendered Successfully
2024-07-04 14:51:10,754:INFO:plot_model() successfully completed......................................
2024-07-04 14:51:10,754:INFO:Initializing plot_model()
2024-07-04 14:51:10,754:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8C283FE50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3037, verbose=0,
                       warm_start=False), plot=auc, scale=0.75, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2024-07-04 14:51:10,754:INFO:Checking exceptions
2024-07-04 14:51:10,754:INFO:Soft dependency imported: streamlit: 1.36.0
2024-07-04 14:51:10,786:INFO:Preloading libraries
2024-07-04 14:51:10,796:INFO:Copying training dataset
2024-07-04 14:51:10,796:INFO:Plot type: auc
2024-07-04 14:51:10,909:INFO:Fitting Model
2024-07-04 14:51:10,910:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2024-07-04 14:51:10,910:INFO:Scoring test/hold-out set
2024-07-04 14:51:11,324:INFO:Visual Rendered Successfully
2024-07-04 14:51:11,454:INFO:plot_model() successfully completed......................................
2024-07-04 14:57:36,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 14:57:36,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 14:57:36,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 14:57:36,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 14:57:52,550:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x000001C412D92F10, file "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 164>')
  warnings.warn(

2024-07-04 14:58:33,928:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x000001C412D92F10, file "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 164>')
  warnings.warn(

2024-07-04 14:58:45,834:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x000001C412D92F10, file "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 164>')
  warnings.warn(

2024-07-04 14:59:44,108:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x000001C412D92F10, file "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 164>')
  warnings.warn(

2024-07-04 14:59:45,472:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x000001C412D92F10, file "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 164>')
  warnings.warn(

2024-07-04 15:00:35,062:INFO:PyCaret ClassificationExperiment
2024-07-04 15:00:35,062:INFO:Logging name: clf-default-name
2024-07-04 15:00:35,062:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-04 15:00:35,062:INFO:version 3.3.2
2024-07-04 15:00:35,063:INFO:Initializing setup()
2024-07-04 15:00:35,063:INFO:self.USI: 0dcf
2024-07-04 15:00:35,063:INFO:self._variable_keys: {'html_param', 'fix_imbalance', 'X_train', 'USI', 'gpu_param', 'n_jobs_param', 'log_plots_param', 'fold_generator', 'gpu_n_jobs_param', 'fold_shuffle_param', 'memory', 'X_test', 'fold_groups_param', 'exp_id', 'pipeline', 'logging_param', 'target_param', 'X', 'data', 'y', '_available_plots', 'y_train', 'exp_name_log', 'seed', '_ml_usecase', 'is_multiclass', 'idx', 'y_test'}
2024-07-04 15:00:35,063:INFO:Checking environment
2024-07-04 15:00:35,063:INFO:python_version: 3.11.3
2024-07-04 15:00:35,063:INFO:python_build: ('tags/v3.11.3:f3909b8', 'Apr  4 2023 23:49:59')
2024-07-04 15:00:35,064:INFO:machine: AMD64
2024-07-04 15:00:35,074:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-04 15:00:35,081:INFO:Memory: svmem(total=8179539968, available=1222819840, percent=85.1, used=6956720128, free=1222819840)
2024-07-04 15:00:35,082:INFO:Physical Core: 4
2024-07-04 15:00:35,082:INFO:Logical Core: 8
2024-07-04 15:00:35,082:INFO:Checking libraries
2024-07-04 15:00:35,082:INFO:System:
2024-07-04 15:00:35,082:INFO:    python: 3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]
2024-07-04 15:00:35,082:INFO:executable: C:\Program Files\Python311\python.exe
2024-07-04 15:00:35,082:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-04 15:00:35,082:INFO:PyCaret required dependencies:
2024-07-04 15:00:35,312:INFO:                 pip: 23.1.2
2024-07-04 15:00:35,313:INFO:          setuptools: 67.8.0
2024-07-04 15:00:35,313:INFO:             pycaret: 3.3.2
2024-07-04 15:00:35,313:INFO:             IPython: 8.14.0
2024-07-04 15:00:35,313:INFO:          ipywidgets: 8.0.6
2024-07-04 15:00:35,313:INFO:                tqdm: 4.65.0
2024-07-04 15:00:35,313:INFO:               numpy: 1.24.3
2024-07-04 15:00:35,313:INFO:              pandas: 2.1.4
2024-07-04 15:00:35,314:INFO:              jinja2: 3.1.2
2024-07-04 15:00:35,314:INFO:               scipy: 1.10.1
2024-07-04 15:00:35,314:INFO:              joblib: 1.3.2
2024-07-04 15:00:35,314:INFO:             sklearn: 1.4.2
2024-07-04 15:00:35,314:INFO:                pyod: 2.0.1
2024-07-04 15:00:35,314:INFO:            imblearn: 0.12.3
2024-07-04 15:00:35,314:INFO:   category_encoders: 2.6.3
2024-07-04 15:00:35,314:INFO:            lightgbm: 4.4.0
2024-07-04 15:00:35,315:INFO:               numba: 0.57.1
2024-07-04 15:00:35,315:INFO:            requests: 2.31.0
2024-07-04 15:00:35,315:INFO:          matplotlib: 3.7.5
2024-07-04 15:00:35,315:INFO:          scikitplot: 0.3.7
2024-07-04 15:00:35,315:INFO:         yellowbrick: 1.5
2024-07-04 15:00:35,315:INFO:              plotly: 5.15.0
2024-07-04 15:00:35,315:INFO:    plotly-resampler: Not installed
2024-07-04 15:00:35,315:INFO:             kaleido: 0.2.1
2024-07-04 15:00:35,315:INFO:           schemdraw: 0.15
2024-07-04 15:00:35,315:INFO:         statsmodels: 0.14.2
2024-07-04 15:00:35,316:INFO:              sktime: 0.26.0
2024-07-04 15:00:35,316:INFO:               tbats: 1.1.3
2024-07-04 15:00:35,316:INFO:            pmdarima: 2.0.4
2024-07-04 15:00:35,316:INFO:              psutil: 5.9.5
2024-07-04 15:00:35,316:INFO:          markupsafe: 2.1.3
2024-07-04 15:00:35,316:INFO:             pickle5: Not installed
2024-07-04 15:00:35,316:INFO:         cloudpickle: 3.0.0
2024-07-04 15:00:35,316:INFO:         deprecation: 2.1.0
2024-07-04 15:00:35,316:INFO:              xxhash: 3.4.1
2024-07-04 15:00:35,316:INFO:           wurlitzer: Not installed
2024-07-04 15:00:35,316:INFO:PyCaret optional dependencies:
2024-07-04 15:00:35,343:INFO:                shap: 0.45.1
2024-07-04 15:00:35,343:INFO:           interpret: Not installed
2024-07-04 15:00:35,343:INFO:                umap: Not installed
2024-07-04 15:00:35,343:INFO:     ydata_profiling: 4.8.3
2024-07-04 15:00:35,343:INFO:  explainerdashboard: Not installed
2024-07-04 15:00:35,343:INFO:             autoviz: Not installed
2024-07-04 15:00:35,343:INFO:           fairlearn: Not installed
2024-07-04 15:00:35,344:INFO:          deepchecks: Not installed
2024-07-04 15:00:35,344:INFO:             xgboost: Not installed
2024-07-04 15:00:35,344:INFO:            catboost: Not installed
2024-07-04 15:00:35,344:INFO:              kmodes: Not installed
2024-07-04 15:00:35,344:INFO:             mlxtend: Not installed
2024-07-04 15:00:35,344:INFO:       statsforecast: Not installed
2024-07-04 15:00:35,344:INFO:        tune_sklearn: Not installed
2024-07-04 15:00:35,344:INFO:                 ray: Not installed
2024-07-04 15:00:35,344:INFO:            hyperopt: Not installed
2024-07-04 15:00:35,344:INFO:              optuna: 3.2.0
2024-07-04 15:00:35,344:INFO:               skopt: 0.10.2
2024-07-04 15:00:35,344:INFO:              mlflow: Not installed
2024-07-04 15:00:35,344:INFO:              gradio: Not installed
2024-07-04 15:00:35,344:INFO:             fastapi: Not installed
2024-07-04 15:00:35,346:INFO:             uvicorn: Not installed
2024-07-04 15:00:35,346:INFO:              m2cgen: Not installed
2024-07-04 15:00:35,346:INFO:           evidently: Not installed
2024-07-04 15:00:35,346:INFO:               fugue: Not installed
2024-07-04 15:00:35,346:INFO:           streamlit: 1.36.0
2024-07-04 15:00:35,346:INFO:             prophet: Not installed
2024-07-04 15:00:35,346:INFO:None
2024-07-04 15:00:35,346:INFO:Set up data.
2024-07-04 15:00:35,364:INFO:Set up folding strategy.
2024-07-04 15:00:35,364:INFO:Set up train/test split.
2024-07-04 15:00:35,378:INFO:Set up index.
2024-07-04 15:00:35,379:INFO:Assigning column types.
2024-07-04 15:00:35,389:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-04 15:00:35,485:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-04 15:00:35,491:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-04 15:00:35,560:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:00:35,561:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:00:35,655:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-04 15:00:35,656:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-04 15:00:35,714:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:00:35,715:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:00:35,717:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-04 15:00:35,824:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-04 15:00:35,889:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:00:35,890:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:00:35,997:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-04 15:00:36,045:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:00:36,046:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:00:36,047:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-04 15:00:36,232:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:00:36,232:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:00:36,412:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:00:36,412:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:00:36,416:INFO:Preparing preprocessing pipeline...
2024-07-04 15:00:36,416:INFO:Set up simple imputation.
2024-07-04 15:00:36,433:INFO:Set up encoding of ordinal features.
2024-07-04 15:00:36,436:INFO:Set up encoding of categorical features.
2024-07-04 15:00:36,436:INFO:Set up imbalanced handling.
2024-07-04 15:00:36,436:INFO:Set up feature normalization.
2024-07-04 15:00:36,436:INFO:Set up feature selection.
2024-07-04 15:00:36,639:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:00:36,639:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:00:37,309:INFO:Finished creating preprocessing pipeline.
2024-07-04 15:00:37,357:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\PHYOSA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Survived_x',
                                             'Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='median'...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=2,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2024-07-04 15:00:37,357:INFO:Creating final display dataframe.
2024-07-04 15:00:38,292:INFO:Setup _display_container:                     Description             Value
0                    Session id              5227
1                        Target        Survived_y
2                   Target type            Binary
3           Original data shape         (891, 13)
4        Transformed data shape         (1036, 3)
5   Transformed train set shape          (768, 3)
6    Transformed test set shape          (268, 3)
7              Numeric features                 7
8          Categorical features                 5
9      Rows with missing values             79.5%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation            median
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                Fix imbalance              True
17         Fix imbalance method             SMOTE
18                    Normalize              True
19             Normalize method            robust
20            Feature selection              True
21     Feature selection method           classic
22  Feature selection estimator          lightgbm
23  Number of features selected               0.2
24               Fold Generator   StratifiedKFold
25                  Fold Number                10
26                     CPU Jobs                -1
27                      Use GPU             False
28               Log Experiment             False
29              Experiment Name  clf-default-name
30                          USI              0dcf
2024-07-04 15:00:38,492:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:00:38,492:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:00:38,587:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:00:38,587:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:00:38,587:INFO:setup() successfully completed in 3.65s...............
2024-07-04 15:00:38,603:INFO:Initializing compare_models()
2024-07-04 15:00:38,603:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C422988890>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001C422988890>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-07-04 15:00:38,603:INFO:Checking exceptions
2024-07-04 15:00:38,611:INFO:Preparing display monitor
2024-07-04 15:00:38,616:INFO:Initializing Logistic Regression
2024-07-04 15:00:38,616:INFO:Total runtime is 0.0 minutes
2024-07-04 15:00:38,616:INFO:SubProcess create_model() called ==================================
2024-07-04 15:00:38,616:INFO:Initializing create_model()
2024-07-04 15:00:38,616:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C422988890>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C4229C1B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:00:38,616:INFO:Checking exceptions
2024-07-04 15:00:38,616:INFO:Importing libraries
2024-07-04 15:00:38,616:INFO:Copying training dataset
2024-07-04 15:00:38,616:INFO:Defining folds
2024-07-04 15:00:38,616:INFO:Declaring metric variables
2024-07-04 15:00:38,616:INFO:Importing untrained model
2024-07-04 15:00:38,616:INFO:Logistic Regression Imported successfully
2024-07-04 15:00:38,616:INFO:Starting cross validation
2024-07-04 15:00:38,638:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:00:52,691:INFO:Calculating mean and std
2024-07-04 15:00:52,694:INFO:Creating metrics dataframe
2024-07-04 15:00:52,699:INFO:Uploading results into container
2024-07-04 15:00:52,700:INFO:Uploading model into container now
2024-07-04 15:00:52,701:INFO:_master_model_container: 1
2024-07-04 15:00:52,701:INFO:_display_container: 2
2024-07-04 15:00:52,702:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5227, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-04 15:00:52,702:INFO:create_model() successfully completed......................................
2024-07-04 15:00:52,956:INFO:SubProcess create_model() end ==================================
2024-07-04 15:00:52,956:INFO:Creating metrics dataframe
2024-07-04 15:00:52,956:INFO:Initializing K Neighbors Classifier
2024-07-04 15:00:52,956:INFO:Total runtime is 0.23899763425191242 minutes
2024-07-04 15:00:52,956:INFO:SubProcess create_model() called ==================================
2024-07-04 15:00:52,956:INFO:Initializing create_model()
2024-07-04 15:00:52,956:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C422988890>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C4229C1B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:00:52,956:INFO:Checking exceptions
2024-07-04 15:00:52,956:INFO:Importing libraries
2024-07-04 15:00:52,956:INFO:Copying training dataset
2024-07-04 15:00:52,956:INFO:Defining folds
2024-07-04 15:00:52,956:INFO:Declaring metric variables
2024-07-04 15:00:52,956:INFO:Importing untrained model
2024-07-04 15:00:52,956:INFO:K Neighbors Classifier Imported successfully
2024-07-04 15:00:52,956:INFO:Starting cross validation
2024-07-04 15:00:52,972:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:00:54,281:INFO:Calculating mean and std
2024-07-04 15:00:54,281:INFO:Creating metrics dataframe
2024-07-04 15:00:54,281:INFO:Uploading results into container
2024-07-04 15:00:54,281:INFO:Uploading model into container now
2024-07-04 15:00:54,281:INFO:_master_model_container: 2
2024-07-04 15:00:54,281:INFO:_display_container: 2
2024-07-04 15:00:54,281:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-04 15:00:54,281:INFO:create_model() successfully completed......................................
2024-07-04 15:00:54,503:INFO:SubProcess create_model() end ==================================
2024-07-04 15:00:54,503:INFO:Creating metrics dataframe
2024-07-04 15:00:54,510:INFO:Initializing Naive Bayes
2024-07-04 15:00:54,511:INFO:Total runtime is 0.26491328875223796 minutes
2024-07-04 15:00:54,511:INFO:SubProcess create_model() called ==================================
2024-07-04 15:00:54,511:INFO:Initializing create_model()
2024-07-04 15:00:54,511:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C422988890>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C4229C1B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:00:54,512:INFO:Checking exceptions
2024-07-04 15:00:54,512:INFO:Importing libraries
2024-07-04 15:00:54,512:INFO:Copying training dataset
2024-07-04 15:00:54,519:INFO:Defining folds
2024-07-04 15:00:54,519:INFO:Declaring metric variables
2024-07-04 15:00:54,519:INFO:Importing untrained model
2024-07-04 15:00:54,520:INFO:Naive Bayes Imported successfully
2024-07-04 15:00:54,520:INFO:Starting cross validation
2024-07-04 15:00:54,530:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:00:55,685:INFO:Calculating mean and std
2024-07-04 15:00:55,685:INFO:Creating metrics dataframe
2024-07-04 15:00:55,689:INFO:Uploading results into container
2024-07-04 15:00:55,689:INFO:Uploading model into container now
2024-07-04 15:00:55,689:INFO:_master_model_container: 3
2024-07-04 15:00:55,689:INFO:_display_container: 2
2024-07-04 15:00:55,689:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-04 15:00:55,689:INFO:create_model() successfully completed......................................
2024-07-04 15:00:55,864:INFO:SubProcess create_model() end ==================================
2024-07-04 15:00:55,864:INFO:Creating metrics dataframe
2024-07-04 15:00:55,871:INFO:Initializing Decision Tree Classifier
2024-07-04 15:00:55,871:INFO:Total runtime is 0.2875839233398438 minutes
2024-07-04 15:00:55,871:INFO:SubProcess create_model() called ==================================
2024-07-04 15:00:55,871:INFO:Initializing create_model()
2024-07-04 15:00:55,871:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C422988890>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C4229C1B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:00:55,871:INFO:Checking exceptions
2024-07-04 15:00:55,871:INFO:Importing libraries
2024-07-04 15:00:55,871:INFO:Copying training dataset
2024-07-04 15:00:55,888:INFO:Defining folds
2024-07-04 15:00:55,888:INFO:Declaring metric variables
2024-07-04 15:00:55,888:INFO:Importing untrained model
2024-07-04 15:00:55,889:INFO:Decision Tree Classifier Imported successfully
2024-07-04 15:00:55,890:INFO:Starting cross validation
2024-07-04 15:00:55,902:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:00:57,072:INFO:Calculating mean and std
2024-07-04 15:00:57,072:INFO:Creating metrics dataframe
2024-07-04 15:00:57,072:INFO:Uploading results into container
2024-07-04 15:00:57,078:INFO:Uploading model into container now
2024-07-04 15:00:57,078:INFO:_master_model_container: 4
2024-07-04 15:00:57,078:INFO:_display_container: 2
2024-07-04 15:00:57,078:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=5227, splitter='best')
2024-07-04 15:00:57,078:INFO:create_model() successfully completed......................................
2024-07-04 15:00:57,251:INFO:SubProcess create_model() end ==================================
2024-07-04 15:00:57,251:INFO:Creating metrics dataframe
2024-07-04 15:00:57,270:INFO:Initializing SVM - Linear Kernel
2024-07-04 15:00:57,270:INFO:Total runtime is 0.31089427073796594 minutes
2024-07-04 15:00:57,270:INFO:SubProcess create_model() called ==================================
2024-07-04 15:00:57,270:INFO:Initializing create_model()
2024-07-04 15:00:57,270:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C422988890>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C4229C1B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:00:57,270:INFO:Checking exceptions
2024-07-04 15:00:57,270:INFO:Importing libraries
2024-07-04 15:00:57,270:INFO:Copying training dataset
2024-07-04 15:00:57,289:INFO:Defining folds
2024-07-04 15:00:57,289:INFO:Declaring metric variables
2024-07-04 15:00:57,289:INFO:Importing untrained model
2024-07-04 15:00:57,290:INFO:SVM - Linear Kernel Imported successfully
2024-07-04 15:00:57,290:INFO:Starting cross validation
2024-07-04 15:00:57,298:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:00:59,777:INFO:Calculating mean and std
2024-07-04 15:00:59,777:INFO:Creating metrics dataframe
2024-07-04 15:00:59,777:INFO:Uploading results into container
2024-07-04 15:00:59,777:INFO:Uploading model into container now
2024-07-04 15:00:59,777:INFO:_master_model_container: 5
2024-07-04 15:00:59,777:INFO:_display_container: 2
2024-07-04 15:00:59,777:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5227, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-04 15:00:59,777:INFO:create_model() successfully completed......................................
2024-07-04 15:00:59,985:INFO:SubProcess create_model() end ==================================
2024-07-04 15:00:59,985:INFO:Creating metrics dataframe
2024-07-04 15:00:59,997:INFO:Initializing Ridge Classifier
2024-07-04 15:00:59,997:INFO:Total runtime is 0.35634257793426516 minutes
2024-07-04 15:00:59,997:INFO:SubProcess create_model() called ==================================
2024-07-04 15:00:59,997:INFO:Initializing create_model()
2024-07-04 15:00:59,997:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C422988890>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C4229C1B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:00:59,997:INFO:Checking exceptions
2024-07-04 15:00:59,997:INFO:Importing libraries
2024-07-04 15:00:59,997:INFO:Copying training dataset
2024-07-04 15:01:00,028:INFO:Defining folds
2024-07-04 15:01:00,028:INFO:Declaring metric variables
2024-07-04 15:01:00,029:INFO:Importing untrained model
2024-07-04 15:01:00,029:INFO:Ridge Classifier Imported successfully
2024-07-04 15:01:00,029:INFO:Starting cross validation
2024-07-04 15:01:00,038:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:01:01,551:INFO:Calculating mean and std
2024-07-04 15:01:01,553:INFO:Creating metrics dataframe
2024-07-04 15:01:01,557:INFO:Uploading results into container
2024-07-04 15:01:01,559:INFO:Uploading model into container now
2024-07-04 15:01:01,560:INFO:_master_model_container: 6
2024-07-04 15:01:01,560:INFO:_display_container: 2
2024-07-04 15:01:01,561:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5227, solver='auto',
                tol=0.0001)
2024-07-04 15:01:01,561:INFO:create_model() successfully completed......................................
2024-07-04 15:01:01,816:INFO:SubProcess create_model() end ==================================
2024-07-04 15:01:01,816:INFO:Creating metrics dataframe
2024-07-04 15:01:01,834:INFO:Initializing Random Forest Classifier
2024-07-04 15:01:01,834:INFO:Total runtime is 0.38695696989695233 minutes
2024-07-04 15:01:01,834:INFO:SubProcess create_model() called ==================================
2024-07-04 15:01:01,834:INFO:Initializing create_model()
2024-07-04 15:01:01,834:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C422988890>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C4229C1B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:01:01,834:INFO:Checking exceptions
2024-07-04 15:01:01,834:INFO:Importing libraries
2024-07-04 15:01:01,834:INFO:Copying training dataset
2024-07-04 15:01:01,850:INFO:Defining folds
2024-07-04 15:01:01,850:INFO:Declaring metric variables
2024-07-04 15:01:01,850:INFO:Importing untrained model
2024-07-04 15:01:01,850:INFO:Random Forest Classifier Imported successfully
2024-07-04 15:01:01,850:INFO:Starting cross validation
2024-07-04 15:01:01,866:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:01:05,399:INFO:Calculating mean and std
2024-07-04 15:01:05,399:INFO:Creating metrics dataframe
2024-07-04 15:01:05,399:INFO:Uploading results into container
2024-07-04 15:01:05,399:INFO:Uploading model into container now
2024-07-04 15:01:05,399:INFO:_master_model_container: 7
2024-07-04 15:01:05,399:INFO:_display_container: 2
2024-07-04 15:01:05,399:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=5227, verbose=0,
                       warm_start=False)
2024-07-04 15:01:05,399:INFO:create_model() successfully completed......................................
2024-07-04 15:01:05,627:INFO:SubProcess create_model() end ==================================
2024-07-04 15:01:05,627:INFO:Creating metrics dataframe
2024-07-04 15:01:05,627:INFO:Initializing Quadratic Discriminant Analysis
2024-07-04 15:01:05,627:INFO:Total runtime is 0.45018235445022586 minutes
2024-07-04 15:01:05,627:INFO:SubProcess create_model() called ==================================
2024-07-04 15:01:05,627:INFO:Initializing create_model()
2024-07-04 15:01:05,627:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C422988890>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C4229C1B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:01:05,627:INFO:Checking exceptions
2024-07-04 15:01:05,627:INFO:Importing libraries
2024-07-04 15:01:05,627:INFO:Copying training dataset
2024-07-04 15:01:05,645:INFO:Defining folds
2024-07-04 15:01:05,645:INFO:Declaring metric variables
2024-07-04 15:01:05,645:INFO:Importing untrained model
2024-07-04 15:01:05,645:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-04 15:01:05,645:INFO:Starting cross validation
2024-07-04 15:01:05,660:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:01:06,314:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 15:01:06,329:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 15:01:06,346:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 15:01:06,406:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 15:01:06,437:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,437:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,437:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:01:06,448:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,448:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,448:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:01:06,448:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,448:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,448:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:01:06,469:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 15:01:06,469:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,469:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,469:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:01:06,469:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,469:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,469:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:01:06,479:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,479:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,479:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:01:06,479:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 15:01:06,479:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:01:06,494:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 15:01:06,500:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:01:06,511:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:01:06,526:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,526:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,529:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:01:06,531:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,531:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,531:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:01:06,551:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 15:01:06,561:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 15:01:06,562:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:01:06,613:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 15:01:06,659:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,659:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,659:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:01:06,665:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,665:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,665:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:01:06,678:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 15:01:06,695:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:01:06,715:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,716:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,716:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:01:06,721:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,722:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,722:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:01:06,735:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 15:01:06,739:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 15:01:06,750:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 15:01:06,759:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:01:06,871:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,871:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,871:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:01:06,871:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,873:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,873:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:01:06,878:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,880:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,880:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:01:06,881:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,881:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:06,881:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:01:06,881:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 15:01:06,912:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 15:01:06,912:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:01:06,932:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:01:06,984:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 15:01:06,995:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 15:01:07,056:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:07,056:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:07,056:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:01:07,059:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:07,059:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:07,059:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:01:07,067:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 15:01:07,067:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:07,067:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:07,067:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:01:07,067:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:07,067:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:01:07,067:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:01:07,067:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:01:07,077:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 15:01:07,077:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:01:07,098:INFO:Calculating mean and std
2024-07-04 15:01:07,098:INFO:Creating metrics dataframe
2024-07-04 15:01:07,108:INFO:Uploading results into container
2024-07-04 15:01:07,109:INFO:Uploading model into container now
2024-07-04 15:01:07,109:INFO:_master_model_container: 8
2024-07-04 15:01:07,109:INFO:_display_container: 2
2024-07-04 15:01:07,109:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-04 15:01:07,109:INFO:create_model() successfully completed......................................
2024-07-04 15:01:07,375:INFO:SubProcess create_model() end ==================================
2024-07-04 15:01:07,375:INFO:Creating metrics dataframe
2024-07-04 15:01:07,375:INFO:Initializing Ada Boost Classifier
2024-07-04 15:01:07,375:INFO:Total runtime is 0.4793207128842672 minutes
2024-07-04 15:01:07,375:INFO:SubProcess create_model() called ==================================
2024-07-04 15:01:07,375:INFO:Initializing create_model()
2024-07-04 15:01:07,375:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C422988890>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C4229C1B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:01:07,375:INFO:Checking exceptions
2024-07-04 15:01:07,375:INFO:Importing libraries
2024-07-04 15:01:07,375:INFO:Copying training dataset
2024-07-04 15:01:07,392:INFO:Defining folds
2024-07-04 15:01:07,392:INFO:Declaring metric variables
2024-07-04 15:01:07,392:INFO:Importing untrained model
2024-07-04 15:01:07,392:INFO:Ada Boost Classifier Imported successfully
2024-07-04 15:01:07,392:INFO:Starting cross validation
2024-07-04 15:01:07,412:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:01:08,299:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 15:01:08,309:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 15:01:08,319:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 15:01:08,319:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 15:01:08,506:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 15:01:08,537:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 15:01:08,643:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 15:01:08,713:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 15:01:08,912:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 15:01:08,949:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 15:01:09,087:INFO:Calculating mean and std
2024-07-04 15:01:09,092:INFO:Creating metrics dataframe
2024-07-04 15:01:09,092:INFO:Uploading results into container
2024-07-04 15:01:09,092:INFO:Uploading model into container now
2024-07-04 15:01:09,092:INFO:_master_model_container: 9
2024-07-04 15:01:09,092:INFO:_display_container: 2
2024-07-04 15:01:09,092:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5227)
2024-07-04 15:01:09,092:INFO:create_model() successfully completed......................................
2024-07-04 15:01:09,358:INFO:SubProcess create_model() end ==================================
2024-07-04 15:01:09,358:INFO:Creating metrics dataframe
2024-07-04 15:01:09,358:INFO:Initializing Gradient Boosting Classifier
2024-07-04 15:01:09,358:INFO:Total runtime is 0.5123698989550273 minutes
2024-07-04 15:01:09,372:INFO:SubProcess create_model() called ==================================
2024-07-04 15:01:09,373:INFO:Initializing create_model()
2024-07-04 15:01:09,373:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C422988890>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C4229C1B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:01:09,373:INFO:Checking exceptions
2024-07-04 15:01:09,373:INFO:Importing libraries
2024-07-04 15:01:09,373:INFO:Copying training dataset
2024-07-04 15:01:09,375:INFO:Defining folds
2024-07-04 15:01:09,375:INFO:Declaring metric variables
2024-07-04 15:01:09,375:INFO:Importing untrained model
2024-07-04 15:01:09,375:INFO:Gradient Boosting Classifier Imported successfully
2024-07-04 15:01:09,375:INFO:Starting cross validation
2024-07-04 15:01:09,389:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:01:11,748:INFO:Calculating mean and std
2024-07-04 15:01:11,748:INFO:Creating metrics dataframe
2024-07-04 15:01:11,754:INFO:Uploading results into container
2024-07-04 15:01:11,754:INFO:Uploading model into container now
2024-07-04 15:01:11,754:INFO:_master_model_container: 10
2024-07-04 15:01:11,754:INFO:_display_container: 2
2024-07-04 15:01:11,754:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5227, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-04 15:01:11,754:INFO:create_model() successfully completed......................................
2024-07-04 15:01:11,972:INFO:SubProcess create_model() end ==================================
2024-07-04 15:01:11,972:INFO:Creating metrics dataframe
2024-07-04 15:01:11,987:INFO:Initializing Linear Discriminant Analysis
2024-07-04 15:01:11,987:INFO:Total runtime is 0.5561798572540283 minutes
2024-07-04 15:01:11,987:INFO:SubProcess create_model() called ==================================
2024-07-04 15:01:11,987:INFO:Initializing create_model()
2024-07-04 15:01:11,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C422988890>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C4229C1B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:01:11,987:INFO:Checking exceptions
2024-07-04 15:01:11,987:INFO:Importing libraries
2024-07-04 15:01:11,987:INFO:Copying training dataset
2024-07-04 15:01:12,005:INFO:Defining folds
2024-07-04 15:01:12,005:INFO:Declaring metric variables
2024-07-04 15:01:12,005:INFO:Importing untrained model
2024-07-04 15:01:12,005:INFO:Linear Discriminant Analysis Imported successfully
2024-07-04 15:01:12,005:INFO:Starting cross validation
2024-07-04 15:01:12,020:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:01:13,518:INFO:Calculating mean and std
2024-07-04 15:01:13,519:INFO:Creating metrics dataframe
2024-07-04 15:01:13,519:INFO:Uploading results into container
2024-07-04 15:01:13,519:INFO:Uploading model into container now
2024-07-04 15:01:13,519:INFO:_master_model_container: 11
2024-07-04 15:01:13,519:INFO:_display_container: 2
2024-07-04 15:01:13,519:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-04 15:01:13,519:INFO:create_model() successfully completed......................................
2024-07-04 15:01:13,785:INFO:SubProcess create_model() end ==================================
2024-07-04 15:01:13,785:INFO:Creating metrics dataframe
2024-07-04 15:01:13,785:INFO:Initializing Extra Trees Classifier
2024-07-04 15:01:13,785:INFO:Total runtime is 0.5861413915952046 minutes
2024-07-04 15:01:13,785:INFO:SubProcess create_model() called ==================================
2024-07-04 15:01:13,785:INFO:Initializing create_model()
2024-07-04 15:01:13,785:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C422988890>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C4229C1B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:01:13,785:INFO:Checking exceptions
2024-07-04 15:01:13,785:INFO:Importing libraries
2024-07-04 15:01:13,785:INFO:Copying training dataset
2024-07-04 15:01:13,801:INFO:Defining folds
2024-07-04 15:01:13,801:INFO:Declaring metric variables
2024-07-04 15:01:13,801:INFO:Importing untrained model
2024-07-04 15:01:13,801:INFO:Extra Trees Classifier Imported successfully
2024-07-04 15:01:13,801:INFO:Starting cross validation
2024-07-04 15:01:13,818:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:01:16,451:INFO:Calculating mean and std
2024-07-04 15:01:16,451:INFO:Creating metrics dataframe
2024-07-04 15:01:16,456:INFO:Uploading results into container
2024-07-04 15:01:16,456:INFO:Uploading model into container now
2024-07-04 15:01:16,456:INFO:_master_model_container: 12
2024-07-04 15:01:16,456:INFO:_display_container: 2
2024-07-04 15:01:16,456:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=5227, verbose=0,
                     warm_start=False)
2024-07-04 15:01:16,456:INFO:create_model() successfully completed......................................
2024-07-04 15:01:16,682:INFO:SubProcess create_model() end ==================================
2024-07-04 15:01:16,682:INFO:Creating metrics dataframe
2024-07-04 15:01:16,682:INFO:Initializing Light Gradient Boosting Machine
2024-07-04 15:01:16,682:INFO:Total runtime is 0.634423832098643 minutes
2024-07-04 15:01:16,682:INFO:SubProcess create_model() called ==================================
2024-07-04 15:01:16,682:INFO:Initializing create_model()
2024-07-04 15:01:16,682:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C422988890>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C4229C1B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:01:16,682:INFO:Checking exceptions
2024-07-04 15:01:16,682:INFO:Importing libraries
2024-07-04 15:01:16,682:INFO:Copying training dataset
2024-07-04 15:01:16,699:INFO:Defining folds
2024-07-04 15:01:16,699:INFO:Declaring metric variables
2024-07-04 15:01:16,699:INFO:Importing untrained model
2024-07-04 15:01:16,699:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-04 15:01:16,699:INFO:Starting cross validation
2024-07-04 15:01:16,716:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:01:18,963:INFO:Calculating mean and std
2024-07-04 15:01:18,966:INFO:Creating metrics dataframe
2024-07-04 15:01:18,966:INFO:Uploading results into container
2024-07-04 15:01:18,966:INFO:Uploading model into container now
2024-07-04 15:01:18,966:INFO:_master_model_container: 13
2024-07-04 15:01:18,966:INFO:_display_container: 2
2024-07-04 15:01:18,966:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5227, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-04 15:01:18,966:INFO:create_model() successfully completed......................................
2024-07-04 15:01:19,246:INFO:SubProcess create_model() end ==================================
2024-07-04 15:01:19,246:INFO:Creating metrics dataframe
2024-07-04 15:01:19,262:INFO:Initializing Dummy Classifier
2024-07-04 15:01:19,262:INFO:Total runtime is 0.677430005868276 minutes
2024-07-04 15:01:19,262:INFO:SubProcess create_model() called ==================================
2024-07-04 15:01:19,262:INFO:Initializing create_model()
2024-07-04 15:01:19,262:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C422988890>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C4229C1B10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:01:19,262:INFO:Checking exceptions
2024-07-04 15:01:19,262:INFO:Importing libraries
2024-07-04 15:01:19,262:INFO:Copying training dataset
2024-07-04 15:01:19,262:INFO:Defining folds
2024-07-04 15:01:19,262:INFO:Declaring metric variables
2024-07-04 15:01:19,262:INFO:Importing untrained model
2024-07-04 15:01:19,262:INFO:Dummy Classifier Imported successfully
2024-07-04 15:01:19,278:INFO:Starting cross validation
2024-07-04 15:01:19,279:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:01:20,512:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:01:20,533:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:01:20,533:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:01:20,605:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:01:20,698:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:01:20,790:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:01:20,852:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:01:20,929:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:01:21,069:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:01:21,069:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:01:21,100:INFO:Calculating mean and std
2024-07-04 15:01:21,100:INFO:Creating metrics dataframe
2024-07-04 15:01:21,100:INFO:Uploading results into container
2024-07-04 15:01:21,100:INFO:Uploading model into container now
2024-07-04 15:01:21,100:INFO:_master_model_container: 14
2024-07-04 15:01:21,100:INFO:_display_container: 2
2024-07-04 15:01:21,100:INFO:DummyClassifier(constant=None, random_state=5227, strategy='prior')
2024-07-04 15:01:21,100:INFO:create_model() successfully completed......................................
2024-07-04 15:01:21,376:INFO:SubProcess create_model() end ==================================
2024-07-04 15:01:21,376:INFO:Creating metrics dataframe
2024-07-04 15:01:21,394:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-07-04 15:01:21,394:INFO:Initializing create_model()
2024-07-04 15:01:21,394:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C422988890>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5227, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:01:21,394:INFO:Checking exceptions
2024-07-04 15:01:21,394:INFO:Importing libraries
2024-07-04 15:01:21,394:INFO:Copying training dataset
2024-07-04 15:01:21,410:INFO:Defining folds
2024-07-04 15:01:21,410:INFO:Declaring metric variables
2024-07-04 15:01:21,410:INFO:Importing untrained model
2024-07-04 15:01:21,410:INFO:Declaring custom model
2024-07-04 15:01:21,410:INFO:Logistic Regression Imported successfully
2024-07-04 15:01:21,427:INFO:Cross validation set to False
2024-07-04 15:01:21,427:INFO:Fitting Model
2024-07-04 15:01:21,627:INFO:[LightGBM] [Info] Number of positive: 384, number of negative: 384
2024-07-04 15:01:21,627:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000269 seconds.
2024-07-04 15:01:21,627:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-04 15:01:21,627:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-04 15:01:21,627:INFO:[LightGBM] [Info] Total Bins 809
2024-07-04 15:01:21,627:INFO:[LightGBM] [Info] Number of data points in the train set: 768, number of used features: 14
2024-07-04 15:01:21,627:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-07-04 15:01:21,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:21,694:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5227, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-04 15:01:21,694:INFO:create_model() successfully completed......................................
2024-07-04 15:01:21,928:INFO:_master_model_container: 14
2024-07-04 15:01:21,928:INFO:_display_container: 2
2024-07-04 15:01:21,928:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5227, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-04 15:01:21,928:INFO:compare_models() successfully completed......................................
2024-07-04 15:01:21,943:INFO:Initializing tune_model()
2024-07-04 15:01:21,943:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C422988890>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5227, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=bayesian, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-04 15:01:21,943:INFO:Checking exceptions
2024-07-04 15:01:21,943:INFO:Soft dependency imported: skopt: 0.10.2
2024-07-04 15:01:22,020:INFO:Copying training dataset
2024-07-04 15:01:22,028:INFO:Checking base model
2024-07-04 15:01:22,028:INFO:Base model : Logistic Regression
2024-07-04 15:01:22,029:INFO:Declaring metric variables
2024-07-04 15:01:22,029:INFO:Defining Hyperparameters
2024-07-04 15:01:22,307:INFO:Tuning with n_jobs=-1
2024-07-04 15:01:22,313:INFO:Initializing skopt.BayesSearchCV
2024-07-04 15:01:38,857:INFO:best_params: OrderedDict([('actual_estimator__C', 8.42863283416764), ('actual_estimator__class_weight', None)])
2024-07-04 15:01:38,857:INFO:Hyperparameter search completed
2024-07-04 15:01:38,857:INFO:SubProcess create_model() called ==================================
2024-07-04 15:01:38,874:INFO:Initializing create_model()
2024-07-04 15:01:38,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C422988890>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5227, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001C41E838490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'C': 8.42863283416764, 'class_weight': None})
2024-07-04 15:01:38,876:INFO:Checking exceptions
2024-07-04 15:01:38,876:INFO:Importing libraries
2024-07-04 15:01:38,876:INFO:Copying training dataset
2024-07-04 15:01:38,893:INFO:Defining folds
2024-07-04 15:01:38,893:INFO:Declaring metric variables
2024-07-04 15:01:38,894:INFO:Importing untrained model
2024-07-04 15:01:38,894:INFO:Declaring custom model
2024-07-04 15:01:38,896:INFO:Logistic Regression Imported successfully
2024-07-04 15:01:38,896:INFO:Starting cross validation
2024-07-04 15:01:38,910:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:01:40,332:INFO:Calculating mean and std
2024-07-04 15:01:40,332:INFO:Creating metrics dataframe
2024-07-04 15:01:40,339:INFO:Finalizing model
2024-07-04 15:01:40,573:INFO:[LightGBM] [Info] Number of positive: 384, number of negative: 384
2024-07-04 15:01:40,574:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000361 seconds.
2024-07-04 15:01:40,574:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-04 15:01:40,575:INFO:[LightGBM] [Info] Total Bins 809
2024-07-04 15:01:40,575:INFO:[LightGBM] [Info] Number of data points in the train set: 768, number of used features: 14
2024-07-04 15:01:40,575:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-07-04 15:01:40,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:40,623:INFO:Uploading results into container
2024-07-04 15:01:40,623:INFO:Uploading model into container now
2024-07-04 15:01:40,623:INFO:_master_model_container: 15
2024-07-04 15:01:40,623:INFO:_display_container: 3
2024-07-04 15:01:40,623:INFO:LogisticRegression(C=8.42863283416764, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5227, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-04 15:01:40,623:INFO:create_model() successfully completed......................................
2024-07-04 15:01:40,838:INFO:SubProcess create_model() end ==================================
2024-07-04 15:01:40,838:INFO:choose_better activated
2024-07-04 15:01:40,838:INFO:SubProcess create_model() called ==================================
2024-07-04 15:01:40,838:INFO:Initializing create_model()
2024-07-04 15:01:40,838:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C422988890>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5227, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:01:40,838:INFO:Checking exceptions
2024-07-04 15:01:40,838:INFO:Importing libraries
2024-07-04 15:01:40,838:INFO:Copying training dataset
2024-07-04 15:01:40,855:INFO:Defining folds
2024-07-04 15:01:40,855:INFO:Declaring metric variables
2024-07-04 15:01:40,855:INFO:Importing untrained model
2024-07-04 15:01:40,855:INFO:Declaring custom model
2024-07-04 15:01:40,855:INFO:Logistic Regression Imported successfully
2024-07-04 15:01:40,855:INFO:Starting cross validation
2024-07-04 15:01:40,873:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:01:42,363:INFO:Calculating mean and std
2024-07-04 15:01:42,366:INFO:Creating metrics dataframe
2024-07-04 15:01:42,372:INFO:Finalizing model
2024-07-04 15:01:42,603:INFO:[LightGBM] [Info] Number of positive: 384, number of negative: 384
2024-07-04 15:01:42,603:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000552 seconds.
2024-07-04 15:01:42,603:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-04 15:01:42,603:INFO:[LightGBM] [Info] Total Bins 809
2024-07-04 15:01:42,603:INFO:[LightGBM] [Info] Number of data points in the train set: 768, number of used features: 14
2024-07-04 15:01:42,603:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-07-04 15:01:42,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:01:42,669:INFO:Uploading results into container
2024-07-04 15:01:42,669:INFO:Uploading model into container now
2024-07-04 15:01:42,669:INFO:_master_model_container: 16
2024-07-04 15:01:42,669:INFO:_display_container: 4
2024-07-04 15:01:42,683:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5227, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-04 15:01:42,683:INFO:create_model() successfully completed......................................
2024-07-04 15:01:42,901:INFO:SubProcess create_model() end ==================================
2024-07-04 15:01:42,903:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5227, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 1.0
2024-07-04 15:01:42,905:INFO:LogisticRegression(C=8.42863283416764, class_weight=None, dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5227, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 1.0
2024-07-04 15:01:42,905:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5227, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2024-07-04 15:01:42,905:INFO:choose_better completed
2024-07-04 15:01:42,905:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-04 15:01:42,933:INFO:_master_model_container: 16
2024-07-04 15:01:42,933:INFO:_display_container: 3
2024-07-04 15:01:42,933:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5227, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-04 15:01:42,933:INFO:tune_model() successfully completed......................................
2024-07-04 15:01:43,210:INFO:Initializing plot_model()
2024-07-04 15:01:43,210:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C422988890>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5227, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=class_report, scale=0.75, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2024-07-04 15:01:43,211:INFO:Checking exceptions
2024-07-04 15:01:43,211:INFO:Soft dependency imported: streamlit: 1.36.0
2024-07-04 15:01:43,215:INFO:Preloading libraries
2024-07-04 15:01:43,215:INFO:Copying training dataset
2024-07-04 15:01:43,215:INFO:Plot type: class_report
2024-07-04 15:01:43,620:INFO:Fitting Model
2024-07-04 15:01:43,620:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2024-07-04 15:01:43,620:INFO:Scoring test/hold-out set
2024-07-04 15:01:44,269:INFO:Visual Rendered Successfully
2024-07-04 15:01:44,446:INFO:plot_model() successfully completed......................................
2024-07-04 15:01:44,446:INFO:Initializing plot_model()
2024-07-04 15:01:44,446:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C422988890>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5227, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=confusion_matrix, scale=0.75, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2024-07-04 15:01:44,446:INFO:Checking exceptions
2024-07-04 15:01:44,446:INFO:Soft dependency imported: streamlit: 1.36.0
2024-07-04 15:01:44,457:INFO:Preloading libraries
2024-07-04 15:01:44,458:INFO:Copying training dataset
2024-07-04 15:01:44,458:INFO:Plot type: confusion_matrix
2024-07-04 15:01:44,735:INFO:Fitting Model
2024-07-04 15:01:44,736:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2024-07-04 15:01:44,736:INFO:Scoring test/hold-out set
2024-07-04 15:01:45,338:INFO:Visual Rendered Successfully
2024-07-04 15:01:45,548:INFO:plot_model() successfully completed......................................
2024-07-04 15:01:45,549:INFO:Initializing plot_model()
2024-07-04 15:01:45,549:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C422988890>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5227, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=auc, scale=0.75, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2024-07-04 15:01:45,549:INFO:Checking exceptions
2024-07-04 15:01:45,549:INFO:Soft dependency imported: streamlit: 1.36.0
2024-07-04 15:01:45,551:INFO:Preloading libraries
2024-07-04 15:01:45,551:INFO:Copying training dataset
2024-07-04 15:01:45,551:INFO:Plot type: auc
2024-07-04 15:01:45,797:INFO:Fitting Model
2024-07-04 15:01:45,797:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2024-07-04 15:01:45,797:INFO:Scoring test/hold-out set
2024-07-04 15:01:46,475:INFO:Visual Rendered Successfully
2024-07-04 15:01:46,689:INFO:plot_model() successfully completed......................................
2024-07-04 15:01:46,693:INFO:Initializing predict_model()
2024-07-04 15:01:46,694:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001C422988890>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5227, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001C42026A5C0>)
2024-07-04 15:01:46,694:INFO:Checking exceptions
2024-07-04 15:01:46,694:INFO:Preloading libraries
2024-07-04 15:03:03,110:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x000001C412D92F10, file "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 164>')
  warnings.warn(

2024-07-04 15:07:16,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 15:07:16,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 15:07:16,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 15:07:16,371:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 15:08:24,595:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x00000248D5E5A550, file "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 164>')
  warnings.warn(

2024-07-04 15:09:28,281:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x00000248D5E5A550, file "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 164>')
  warnings.warn(

2024-07-04 15:09:48,475:INFO:PyCaret ClassificationExperiment
2024-07-04 15:09:48,475:INFO:Logging name: clf-default-name
2024-07-04 15:09:48,476:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-07-04 15:09:48,476:INFO:version 3.3.2
2024-07-04 15:09:48,476:INFO:Initializing setup()
2024-07-04 15:09:48,476:INFO:self.USI: 971f
2024-07-04 15:09:48,476:INFO:self._variable_keys: {'y', 'logging_param', 'pipeline', 'html_param', 'fold_shuffle_param', 'y_train', 'fold_generator', 'exp_name_log', 'is_multiclass', 'seed', 'idx', 'X_train', 'X_test', 'gpu_n_jobs_param', 'data', 'X', '_available_plots', 'log_plots_param', 'n_jobs_param', 'y_test', '_ml_usecase', 'target_param', 'exp_id', 'memory', 'fix_imbalance', 'USI', 'gpu_param', 'fold_groups_param'}
2024-07-04 15:09:48,476:INFO:Checking environment
2024-07-04 15:09:48,476:INFO:python_version: 3.11.3
2024-07-04 15:09:48,476:INFO:python_build: ('tags/v3.11.3:f3909b8', 'Apr  4 2023 23:49:59')
2024-07-04 15:09:48,476:INFO:machine: AMD64
2024-07-04 15:09:48,497:INFO:platform: Windows-10-10.0.22631-SP0
2024-07-04 15:09:48,507:INFO:Memory: svmem(total=8179539968, available=1355124736, percent=83.4, used=6824415232, free=1355124736)
2024-07-04 15:09:48,507:INFO:Physical Core: 4
2024-07-04 15:09:48,507:INFO:Logical Core: 8
2024-07-04 15:09:48,507:INFO:Checking libraries
2024-07-04 15:09:48,507:INFO:System:
2024-07-04 15:09:48,507:INFO:    python: 3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]
2024-07-04 15:09:48,507:INFO:executable: C:\Program Files\Python311\python.exe
2024-07-04 15:09:48,508:INFO:   machine: Windows-10-10.0.22631-SP0
2024-07-04 15:09:48,508:INFO:PyCaret required dependencies:
2024-07-04 15:09:48,723:INFO:                 pip: 23.1.2
2024-07-04 15:09:48,723:INFO:          setuptools: 67.8.0
2024-07-04 15:09:48,723:INFO:             pycaret: 3.3.2
2024-07-04 15:09:48,723:INFO:             IPython: 8.14.0
2024-07-04 15:09:48,723:INFO:          ipywidgets: 8.0.6
2024-07-04 15:09:48,723:INFO:                tqdm: 4.65.0
2024-07-04 15:09:48,723:INFO:               numpy: 1.24.3
2024-07-04 15:09:48,723:INFO:              pandas: 2.1.4
2024-07-04 15:09:48,723:INFO:              jinja2: 3.1.2
2024-07-04 15:09:48,723:INFO:               scipy: 1.10.1
2024-07-04 15:09:48,723:INFO:              joblib: 1.3.2
2024-07-04 15:09:48,723:INFO:             sklearn: 1.4.2
2024-07-04 15:09:48,723:INFO:                pyod: 2.0.1
2024-07-04 15:09:48,723:INFO:            imblearn: 0.12.3
2024-07-04 15:09:48,723:INFO:   category_encoders: 2.6.3
2024-07-04 15:09:48,723:INFO:            lightgbm: 4.4.0
2024-07-04 15:09:48,723:INFO:               numba: 0.57.1
2024-07-04 15:09:48,723:INFO:            requests: 2.31.0
2024-07-04 15:09:48,723:INFO:          matplotlib: 3.7.5
2024-07-04 15:09:48,723:INFO:          scikitplot: 0.3.7
2024-07-04 15:09:48,723:INFO:         yellowbrick: 1.5
2024-07-04 15:09:48,723:INFO:              plotly: 5.15.0
2024-07-04 15:09:48,723:INFO:    plotly-resampler: Not installed
2024-07-04 15:09:48,723:INFO:             kaleido: 0.2.1
2024-07-04 15:09:48,723:INFO:           schemdraw: 0.15
2024-07-04 15:09:48,723:INFO:         statsmodels: 0.14.2
2024-07-04 15:09:48,723:INFO:              sktime: 0.26.0
2024-07-04 15:09:48,723:INFO:               tbats: 1.1.3
2024-07-04 15:09:48,723:INFO:            pmdarima: 2.0.4
2024-07-04 15:09:48,723:INFO:              psutil: 5.9.5
2024-07-04 15:09:48,723:INFO:          markupsafe: 2.1.3
2024-07-04 15:09:48,723:INFO:             pickle5: Not installed
2024-07-04 15:09:48,723:INFO:         cloudpickle: 3.0.0
2024-07-04 15:09:48,723:INFO:         deprecation: 2.1.0
2024-07-04 15:09:48,723:INFO:              xxhash: 3.4.1
2024-07-04 15:09:48,723:INFO:           wurlitzer: Not installed
2024-07-04 15:09:48,723:INFO:PyCaret optional dependencies:
2024-07-04 15:09:48,748:INFO:                shap: 0.45.1
2024-07-04 15:09:48,748:INFO:           interpret: Not installed
2024-07-04 15:09:48,748:INFO:                umap: Not installed
2024-07-04 15:09:48,748:INFO:     ydata_profiling: 4.8.3
2024-07-04 15:09:48,749:INFO:  explainerdashboard: Not installed
2024-07-04 15:09:48,749:INFO:             autoviz: Not installed
2024-07-04 15:09:48,749:INFO:           fairlearn: Not installed
2024-07-04 15:09:48,749:INFO:          deepchecks: Not installed
2024-07-04 15:09:48,749:INFO:             xgboost: Not installed
2024-07-04 15:09:48,749:INFO:            catboost: Not installed
2024-07-04 15:09:48,749:INFO:              kmodes: Not installed
2024-07-04 15:09:48,749:INFO:             mlxtend: Not installed
2024-07-04 15:09:48,749:INFO:       statsforecast: Not installed
2024-07-04 15:09:48,749:INFO:        tune_sklearn: Not installed
2024-07-04 15:09:48,749:INFO:                 ray: Not installed
2024-07-04 15:09:48,750:INFO:            hyperopt: Not installed
2024-07-04 15:09:48,750:INFO:              optuna: 3.2.0
2024-07-04 15:09:48,750:INFO:               skopt: 0.10.2
2024-07-04 15:09:48,750:INFO:              mlflow: Not installed
2024-07-04 15:09:48,750:INFO:              gradio: Not installed
2024-07-04 15:09:48,750:INFO:             fastapi: Not installed
2024-07-04 15:09:48,750:INFO:             uvicorn: Not installed
2024-07-04 15:09:48,750:INFO:              m2cgen: Not installed
2024-07-04 15:09:48,750:INFO:           evidently: Not installed
2024-07-04 15:09:48,750:INFO:               fugue: Not installed
2024-07-04 15:09:48,750:INFO:           streamlit: 1.36.0
2024-07-04 15:09:48,750:INFO:             prophet: Not installed
2024-07-04 15:09:48,750:INFO:None
2024-07-04 15:09:48,750:INFO:Set up data.
2024-07-04 15:09:48,757:INFO:Set up folding strategy.
2024-07-04 15:09:48,757:INFO:Set up train/test split.
2024-07-04 15:09:48,763:INFO:Set up index.
2024-07-04 15:09:48,763:INFO:Assigning column types.
2024-07-04 15:09:48,767:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-07-04 15:09:48,843:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-04 15:09:48,849:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-04 15:09:48,914:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:09:48,914:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:09:48,993:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-07-04 15:09:48,995:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-04 15:09:49,057:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:09:49,057:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:09:49,058:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-07-04 15:09:49,155:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-04 15:09:49,201:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:09:49,202:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:09:49,306:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-07-04 15:09:49,359:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:09:49,360:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:09:49,360:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-07-04 15:09:49,484:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:09:49,485:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:09:49,618:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:09:49,618:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:09:49,623:INFO:Preparing preprocessing pipeline...
2024-07-04 15:09:49,625:INFO:Set up simple imputation.
2024-07-04 15:09:49,635:INFO:Set up encoding of ordinal features.
2024-07-04 15:09:49,635:INFO:Set up encoding of categorical features.
2024-07-04 15:09:49,635:INFO:Set up imbalanced handling.
2024-07-04 15:09:49,635:INFO:Set up feature normalization.
2024-07-04 15:09:49,635:INFO:Set up feature selection.
2024-07-04 15:09:49,768:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:09:49,768:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:09:50,447:INFO:Finished creating preprocessing pipeline.
2024-07-04 15:09:50,487:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\PHYOSA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Survived_x',
                                             'Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='median'...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=2,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2024-07-04 15:09:50,487:INFO:Creating final display dataframe.
2024-07-04 15:09:51,510:INFO:Setup _display_container:                     Description             Value
0                    Session id              5295
1                        Target        Survived_y
2                   Target type            Binary
3           Original data shape         (891, 13)
4        Transformed data shape         (1036, 3)
5   Transformed train set shape          (768, 3)
6    Transformed test set shape          (268, 3)
7              Numeric features                 7
8          Categorical features                 5
9      Rows with missing values             79.5%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation            median
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16                Fix imbalance              True
17         Fix imbalance method             SMOTE
18                    Normalize              True
19             Normalize method            robust
20            Feature selection              True
21     Feature selection method           classic
22  Feature selection estimator          lightgbm
23  Number of features selected               0.2
24               Fold Generator   StratifiedKFold
25                  Fold Number                10
26                     CPU Jobs                -1
27                      Use GPU             False
28               Log Experiment             False
29              Experiment Name  clf-default-name
30                          USI              971f
2024-07-04 15:09:51,688:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:09:51,688:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:09:51,831:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:09:51,831:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-07-04 15:09:51,831:INFO:setup() successfully completed in 3.56s...............
2024-07-04 15:09:51,831:INFO:Initializing compare_models()
2024-07-04 15:09:51,831:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248F4D24CD0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000248F4D24CD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2024-07-04 15:09:51,831:INFO:Checking exceptions
2024-07-04 15:09:51,854:INFO:Preparing display monitor
2024-07-04 15:09:51,857:INFO:Initializing Logistic Regression
2024-07-04 15:09:51,857:INFO:Total runtime is 0.0 minutes
2024-07-04 15:09:51,857:INFO:SubProcess create_model() called ==================================
2024-07-04 15:09:51,857:INFO:Initializing create_model()
2024-07-04 15:09:51,857:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248F4D24CD0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248F4D44610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:09:51,857:INFO:Checking exceptions
2024-07-04 15:09:51,857:INFO:Importing libraries
2024-07-04 15:09:51,857:INFO:Copying training dataset
2024-07-04 15:09:51,857:INFO:Defining folds
2024-07-04 15:09:51,857:INFO:Declaring metric variables
2024-07-04 15:09:51,857:INFO:Importing untrained model
2024-07-04 15:09:51,857:INFO:Logistic Regression Imported successfully
2024-07-04 15:09:51,857:INFO:Starting cross validation
2024-07-04 15:09:51,874:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:10:04,522:INFO:Calculating mean and std
2024-07-04 15:10:04,522:INFO:Creating metrics dataframe
2024-07-04 15:10:04,522:INFO:Uploading results into container
2024-07-04 15:10:04,522:INFO:Uploading model into container now
2024-07-04 15:10:04,522:INFO:_master_model_container: 1
2024-07-04 15:10:04,522:INFO:_display_container: 2
2024-07-04 15:10:04,532:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5295, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-04 15:10:04,532:INFO:create_model() successfully completed......................................
2024-07-04 15:10:04,807:INFO:SubProcess create_model() end ==================================
2024-07-04 15:10:04,808:INFO:Creating metrics dataframe
2024-07-04 15:10:04,812:INFO:Initializing K Neighbors Classifier
2024-07-04 15:10:04,812:INFO:Total runtime is 0.2159164547920227 minutes
2024-07-04 15:10:04,812:INFO:SubProcess create_model() called ==================================
2024-07-04 15:10:04,813:INFO:Initializing create_model()
2024-07-04 15:10:04,813:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248F4D24CD0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248F4D44610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:10:04,813:INFO:Checking exceptions
2024-07-04 15:10:04,813:INFO:Importing libraries
2024-07-04 15:10:04,814:INFO:Copying training dataset
2024-07-04 15:10:04,817:INFO:Defining folds
2024-07-04 15:10:04,817:INFO:Declaring metric variables
2024-07-04 15:10:04,817:INFO:Importing untrained model
2024-07-04 15:10:04,817:INFO:K Neighbors Classifier Imported successfully
2024-07-04 15:10:04,817:INFO:Starting cross validation
2024-07-04 15:10:04,833:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:10:06,734:INFO:Calculating mean and std
2024-07-04 15:10:06,734:INFO:Creating metrics dataframe
2024-07-04 15:10:06,740:INFO:Uploading results into container
2024-07-04 15:10:06,740:INFO:Uploading model into container now
2024-07-04 15:10:06,740:INFO:_master_model_container: 2
2024-07-04 15:10:06,740:INFO:_display_container: 2
2024-07-04 15:10:06,740:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-07-04 15:10:06,740:INFO:create_model() successfully completed......................................
2024-07-04 15:10:06,948:INFO:SubProcess create_model() end ==================================
2024-07-04 15:10:06,948:INFO:Creating metrics dataframe
2024-07-04 15:10:06,948:INFO:Initializing Naive Bayes
2024-07-04 15:10:06,948:INFO:Total runtime is 0.25152615308761594 minutes
2024-07-04 15:10:06,948:INFO:SubProcess create_model() called ==================================
2024-07-04 15:10:06,948:INFO:Initializing create_model()
2024-07-04 15:10:06,948:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248F4D24CD0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248F4D44610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:10:06,948:INFO:Checking exceptions
2024-07-04 15:10:06,948:INFO:Importing libraries
2024-07-04 15:10:06,948:INFO:Copying training dataset
2024-07-04 15:10:06,968:INFO:Defining folds
2024-07-04 15:10:06,968:INFO:Declaring metric variables
2024-07-04 15:10:06,969:INFO:Importing untrained model
2024-07-04 15:10:06,969:INFO:Naive Bayes Imported successfully
2024-07-04 15:10:06,969:INFO:Starting cross validation
2024-07-04 15:10:06,978:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:10:07,906:INFO:Calculating mean and std
2024-07-04 15:10:07,907:INFO:Creating metrics dataframe
2024-07-04 15:10:07,907:INFO:Uploading results into container
2024-07-04 15:10:07,907:INFO:Uploading model into container now
2024-07-04 15:10:07,907:INFO:_master_model_container: 3
2024-07-04 15:10:07,907:INFO:_display_container: 2
2024-07-04 15:10:07,907:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-07-04 15:10:07,907:INFO:create_model() successfully completed......................................
2024-07-04 15:10:08,103:INFO:SubProcess create_model() end ==================================
2024-07-04 15:10:08,103:INFO:Creating metrics dataframe
2024-07-04 15:10:08,108:INFO:Initializing Decision Tree Classifier
2024-07-04 15:10:08,108:INFO:Total runtime is 0.27084790070851644 minutes
2024-07-04 15:10:08,108:INFO:SubProcess create_model() called ==================================
2024-07-04 15:10:08,113:INFO:Initializing create_model()
2024-07-04 15:10:08,113:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248F4D24CD0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248F4D44610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:10:08,113:INFO:Checking exceptions
2024-07-04 15:10:08,113:INFO:Importing libraries
2024-07-04 15:10:08,113:INFO:Copying training dataset
2024-07-04 15:10:08,122:INFO:Defining folds
2024-07-04 15:10:08,122:INFO:Declaring metric variables
2024-07-04 15:10:08,123:INFO:Importing untrained model
2024-07-04 15:10:08,123:INFO:Decision Tree Classifier Imported successfully
2024-07-04 15:10:08,123:INFO:Starting cross validation
2024-07-04 15:10:08,129:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:10:09,149:INFO:Calculating mean and std
2024-07-04 15:10:09,149:INFO:Creating metrics dataframe
2024-07-04 15:10:09,149:INFO:Uploading results into container
2024-07-04 15:10:09,149:INFO:Uploading model into container now
2024-07-04 15:10:09,149:INFO:_master_model_container: 4
2024-07-04 15:10:09,149:INFO:_display_container: 2
2024-07-04 15:10:09,149:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=5295, splitter='best')
2024-07-04 15:10:09,149:INFO:create_model() successfully completed......................................
2024-07-04 15:10:09,329:INFO:SubProcess create_model() end ==================================
2024-07-04 15:10:09,329:INFO:Creating metrics dataframe
2024-07-04 15:10:09,329:INFO:Initializing SVM - Linear Kernel
2024-07-04 15:10:09,329:INFO:Total runtime is 0.2911988178888957 minutes
2024-07-04 15:10:09,329:INFO:SubProcess create_model() called ==================================
2024-07-04 15:10:09,329:INFO:Initializing create_model()
2024-07-04 15:10:09,329:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248F4D24CD0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248F4D44610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:10:09,329:INFO:Checking exceptions
2024-07-04 15:10:09,329:INFO:Importing libraries
2024-07-04 15:10:09,329:INFO:Copying training dataset
2024-07-04 15:10:09,338:INFO:Defining folds
2024-07-04 15:10:09,338:INFO:Declaring metric variables
2024-07-04 15:10:09,338:INFO:Importing untrained model
2024-07-04 15:10:09,338:INFO:SVM - Linear Kernel Imported successfully
2024-07-04 15:10:09,338:INFO:Starting cross validation
2024-07-04 15:10:09,354:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:10:11,169:INFO:Calculating mean and std
2024-07-04 15:10:11,169:INFO:Creating metrics dataframe
2024-07-04 15:10:11,169:INFO:Uploading results into container
2024-07-04 15:10:11,169:INFO:Uploading model into container now
2024-07-04 15:10:11,169:INFO:_master_model_container: 5
2024-07-04 15:10:11,169:INFO:_display_container: 2
2024-07-04 15:10:11,169:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5295, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-07-04 15:10:11,169:INFO:create_model() successfully completed......................................
2024-07-04 15:10:11,361:INFO:SubProcess create_model() end ==================================
2024-07-04 15:10:11,362:INFO:Creating metrics dataframe
2024-07-04 15:10:11,368:INFO:Initializing Ridge Classifier
2024-07-04 15:10:11,368:INFO:Total runtime is 0.32518954277038575 minutes
2024-07-04 15:10:11,368:INFO:SubProcess create_model() called ==================================
2024-07-04 15:10:11,369:INFO:Initializing create_model()
2024-07-04 15:10:11,369:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248F4D24CD0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248F4D44610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:10:11,369:INFO:Checking exceptions
2024-07-04 15:10:11,369:INFO:Importing libraries
2024-07-04 15:10:11,369:INFO:Copying training dataset
2024-07-04 15:10:11,383:INFO:Defining folds
2024-07-04 15:10:11,384:INFO:Declaring metric variables
2024-07-04 15:10:11,384:INFO:Importing untrained model
2024-07-04 15:10:11,385:INFO:Ridge Classifier Imported successfully
2024-07-04 15:10:11,386:INFO:Starting cross validation
2024-07-04 15:10:11,395:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:10:12,554:INFO:Calculating mean and std
2024-07-04 15:10:12,554:INFO:Creating metrics dataframe
2024-07-04 15:10:12,556:INFO:Uploading results into container
2024-07-04 15:10:12,559:INFO:Uploading model into container now
2024-07-04 15:10:12,559:INFO:_master_model_container: 6
2024-07-04 15:10:12,559:INFO:_display_container: 2
2024-07-04 15:10:12,559:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5295, solver='auto',
                tol=0.0001)
2024-07-04 15:10:12,559:INFO:create_model() successfully completed......................................
2024-07-04 15:10:12,724:INFO:SubProcess create_model() end ==================================
2024-07-04 15:10:12,724:INFO:Creating metrics dataframe
2024-07-04 15:10:12,733:INFO:Initializing Random Forest Classifier
2024-07-04 15:10:12,733:INFO:Total runtime is 0.3479325612386068 minutes
2024-07-04 15:10:12,733:INFO:SubProcess create_model() called ==================================
2024-07-04 15:10:12,733:INFO:Initializing create_model()
2024-07-04 15:10:12,733:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248F4D24CD0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248F4D44610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:10:12,733:INFO:Checking exceptions
2024-07-04 15:10:12,733:INFO:Importing libraries
2024-07-04 15:10:12,733:INFO:Copying training dataset
2024-07-04 15:10:12,733:INFO:Defining folds
2024-07-04 15:10:12,733:INFO:Declaring metric variables
2024-07-04 15:10:12,733:INFO:Importing untrained model
2024-07-04 15:10:12,733:INFO:Random Forest Classifier Imported successfully
2024-07-04 15:10:12,733:INFO:Starting cross validation
2024-07-04 15:10:12,748:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:10:15,150:INFO:Calculating mean and std
2024-07-04 15:10:15,150:INFO:Creating metrics dataframe
2024-07-04 15:10:15,156:INFO:Uploading results into container
2024-07-04 15:10:15,156:INFO:Uploading model into container now
2024-07-04 15:10:15,156:INFO:_master_model_container: 7
2024-07-04 15:10:15,156:INFO:_display_container: 2
2024-07-04 15:10:15,156:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=5295, verbose=0,
                       warm_start=False)
2024-07-04 15:10:15,156:INFO:create_model() successfully completed......................................
2024-07-04 15:10:15,363:INFO:SubProcess create_model() end ==================================
2024-07-04 15:10:15,363:INFO:Creating metrics dataframe
2024-07-04 15:10:15,363:INFO:Initializing Quadratic Discriminant Analysis
2024-07-04 15:10:15,363:INFO:Total runtime is 0.39176510175069174 minutes
2024-07-04 15:10:15,371:INFO:SubProcess create_model() called ==================================
2024-07-04 15:10:15,371:INFO:Initializing create_model()
2024-07-04 15:10:15,371:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248F4D24CD0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248F4D44610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:10:15,371:INFO:Checking exceptions
2024-07-04 15:10:15,371:INFO:Importing libraries
2024-07-04 15:10:15,371:INFO:Copying training dataset
2024-07-04 15:10:15,371:INFO:Defining folds
2024-07-04 15:10:15,387:INFO:Declaring metric variables
2024-07-04 15:10:15,388:INFO:Importing untrained model
2024-07-04 15:10:15,389:INFO:Quadratic Discriminant Analysis Imported successfully
2024-07-04 15:10:15,390:INFO:Starting cross validation
2024-07-04 15:10:15,400:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:10:16,087:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 15:10:16,087:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 15:10:16,094:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 15:10:16,094:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 15:10:16,146:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,146:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,146:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,146:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,146:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:10:16,156:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,156:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,156:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,156:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:10:16,156:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,156:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:10:16,156:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,156:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,156:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:10:16,161:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,161:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,161:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,161:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,161:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:10:16,161:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:10:16,166:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 15:10:16,172:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 15:10:16,172:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,172:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,172:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:10:16,176:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 15:10:16,176:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 15:10:16,176:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:10:16,176:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:10:16,191:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:10:16,193:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:10:16,220:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 15:10:16,229:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 15:10:16,290:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,290:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,290:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:10:16,290:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,290:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,290:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:10:16,304:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 15:10:16,304:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,304:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,304:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:10:16,313:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,313:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,313:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:10:16,315:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:10:16,321:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 15:10:16,337:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:10:16,351:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 15:10:16,372:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 15:10:16,444:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,444:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,444:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:10:16,444:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,444:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,444:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:10:16,455:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 15:10:16,455:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,455:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,455:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:10:16,469:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,469:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,470:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:10:16,476:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:10:16,476:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 15:10:16,492:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:10:16,527:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 15:10:16,535:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-07-04 15:10:16,600:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,600:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,600:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:10:16,602:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,602:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,603:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:10:16,605:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,605:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,606:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:10:16,611:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,611:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:960: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2024-07-04 15:10:16,612:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\discriminant_analysis.py:963: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2024-07-04 15:10:16,614:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 15:10:16,616:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_ranking.py", line 619, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 1049, in check_array
    _assert_all_finite(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\utils\validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-07-04 15:10:16,626:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:10:16,627:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:10:16,652:INFO:Calculating mean and std
2024-07-04 15:10:16,654:INFO:Creating metrics dataframe
2024-07-04 15:10:16,654:INFO:Uploading results into container
2024-07-04 15:10:16,654:INFO:Uploading model into container now
2024-07-04 15:10:16,654:INFO:_master_model_container: 8
2024-07-04 15:10:16,654:INFO:_display_container: 2
2024-07-04 15:10:16,654:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-07-04 15:10:16,654:INFO:create_model() successfully completed......................................
2024-07-04 15:10:16,905:INFO:SubProcess create_model() end ==================================
2024-07-04 15:10:16,905:INFO:Creating metrics dataframe
2024-07-04 15:10:16,921:INFO:Initializing Ada Boost Classifier
2024-07-04 15:10:16,921:INFO:Total runtime is 0.41773544549942015 minutes
2024-07-04 15:10:16,921:INFO:SubProcess create_model() called ==================================
2024-07-04 15:10:16,921:INFO:Initializing create_model()
2024-07-04 15:10:16,921:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248F4D24CD0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248F4D44610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:10:16,921:INFO:Checking exceptions
2024-07-04 15:10:16,921:INFO:Importing libraries
2024-07-04 15:10:16,921:INFO:Copying training dataset
2024-07-04 15:10:16,929:INFO:Defining folds
2024-07-04 15:10:16,929:INFO:Declaring metric variables
2024-07-04 15:10:16,929:INFO:Importing untrained model
2024-07-04 15:10:16,929:INFO:Ada Boost Classifier Imported successfully
2024-07-04 15:10:16,929:INFO:Starting cross validation
2024-07-04 15:10:16,945:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:10:17,614:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 15:10:17,625:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 15:10:17,630:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 15:10:17,649:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 15:10:17,821:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 15:10:17,831:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 15:10:17,957:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 15:10:18,015:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 15:10:18,152:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 15:10:18,176:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-07-04 15:10:18,291:INFO:Calculating mean and std
2024-07-04 15:10:18,291:INFO:Creating metrics dataframe
2024-07-04 15:10:18,301:INFO:Uploading results into container
2024-07-04 15:10:18,304:INFO:Uploading model into container now
2024-07-04 15:10:18,304:INFO:_master_model_container: 9
2024-07-04 15:10:18,304:INFO:_display_container: 2
2024-07-04 15:10:18,304:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5295)
2024-07-04 15:10:18,304:INFO:create_model() successfully completed......................................
2024-07-04 15:10:18,588:INFO:SubProcess create_model() end ==================================
2024-07-04 15:10:18,588:INFO:Creating metrics dataframe
2024-07-04 15:10:18,588:INFO:Initializing Gradient Boosting Classifier
2024-07-04 15:10:18,588:INFO:Total runtime is 0.445515239238739 minutes
2024-07-04 15:10:18,601:INFO:SubProcess create_model() called ==================================
2024-07-04 15:10:18,601:INFO:Initializing create_model()
2024-07-04 15:10:18,602:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248F4D24CD0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248F4D44610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:10:18,603:INFO:Checking exceptions
2024-07-04 15:10:18,603:INFO:Importing libraries
2024-07-04 15:10:18,604:INFO:Copying training dataset
2024-07-04 15:10:18,605:INFO:Defining folds
2024-07-04 15:10:18,605:INFO:Declaring metric variables
2024-07-04 15:10:18,617:INFO:Importing untrained model
2024-07-04 15:10:18,618:INFO:Gradient Boosting Classifier Imported successfully
2024-07-04 15:10:18,620:INFO:Starting cross validation
2024-07-04 15:10:18,620:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:11:03,073:INFO:Calculating mean and std
2024-07-04 15:11:03,073:INFO:Creating metrics dataframe
2024-07-04 15:11:03,073:INFO:Uploading results into container
2024-07-04 15:11:03,073:INFO:Uploading model into container now
2024-07-04 15:11:03,073:INFO:_master_model_container: 10
2024-07-04 15:11:03,073:INFO:_display_container: 2
2024-07-04 15:11:03,073:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5295, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-07-04 15:11:03,073:INFO:create_model() successfully completed......................................
2024-07-04 15:11:03,302:INFO:SubProcess create_model() end ==================================
2024-07-04 15:11:03,302:INFO:Creating metrics dataframe
2024-07-04 15:11:03,302:INFO:Initializing Linear Discriminant Analysis
2024-07-04 15:11:03,302:INFO:Total runtime is 1.1907568931579589 minutes
2024-07-04 15:11:03,302:INFO:SubProcess create_model() called ==================================
2024-07-04 15:11:03,302:INFO:Initializing create_model()
2024-07-04 15:11:03,302:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248F4D24CD0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248F4D44610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:11:03,302:INFO:Checking exceptions
2024-07-04 15:11:03,302:INFO:Importing libraries
2024-07-04 15:11:03,302:INFO:Copying training dataset
2024-07-04 15:11:03,321:INFO:Defining folds
2024-07-04 15:11:03,321:INFO:Declaring metric variables
2024-07-04 15:11:03,321:INFO:Importing untrained model
2024-07-04 15:11:03,321:INFO:Linear Discriminant Analysis Imported successfully
2024-07-04 15:11:03,321:INFO:Starting cross validation
2024-07-04 15:11:03,336:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:11:04,393:INFO:Calculating mean and std
2024-07-04 15:11:04,393:INFO:Creating metrics dataframe
2024-07-04 15:11:04,393:INFO:Uploading results into container
2024-07-04 15:11:04,393:INFO:Uploading model into container now
2024-07-04 15:11:04,393:INFO:_master_model_container: 11
2024-07-04 15:11:04,393:INFO:_display_container: 2
2024-07-04 15:11:04,393:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-07-04 15:11:04,393:INFO:create_model() successfully completed......................................
2024-07-04 15:11:04,591:INFO:SubProcess create_model() end ==================================
2024-07-04 15:11:04,591:INFO:Creating metrics dataframe
2024-07-04 15:11:04,600:INFO:Initializing Extra Trees Classifier
2024-07-04 15:11:04,600:INFO:Total runtime is 1.2123955885569253 minutes
2024-07-04 15:11:04,600:INFO:SubProcess create_model() called ==================================
2024-07-04 15:11:04,600:INFO:Initializing create_model()
2024-07-04 15:11:04,600:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248F4D24CD0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248F4D44610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:11:04,600:INFO:Checking exceptions
2024-07-04 15:11:04,600:INFO:Importing libraries
2024-07-04 15:11:04,600:INFO:Copying training dataset
2024-07-04 15:11:04,619:INFO:Defining folds
2024-07-04 15:11:04,619:INFO:Declaring metric variables
2024-07-04 15:11:04,619:INFO:Importing untrained model
2024-07-04 15:11:04,619:INFO:Extra Trees Classifier Imported successfully
2024-07-04 15:11:04,619:INFO:Starting cross validation
2024-07-04 15:11:04,636:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:11:06,931:INFO:Calculating mean and std
2024-07-04 15:11:06,933:INFO:Creating metrics dataframe
2024-07-04 15:11:06,933:INFO:Uploading results into container
2024-07-04 15:11:06,933:INFO:Uploading model into container now
2024-07-04 15:11:06,933:INFO:_master_model_container: 12
2024-07-04 15:11:06,933:INFO:_display_container: 2
2024-07-04 15:11:06,933:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=5295, verbose=0,
                     warm_start=False)
2024-07-04 15:11:06,933:INFO:create_model() successfully completed......................................
2024-07-04 15:11:07,115:INFO:SubProcess create_model() end ==================================
2024-07-04 15:11:07,115:INFO:Creating metrics dataframe
2024-07-04 15:11:07,131:INFO:Initializing Light Gradient Boosting Machine
2024-07-04 15:11:07,131:INFO:Total runtime is 1.2545718868573505 minutes
2024-07-04 15:11:07,131:INFO:SubProcess create_model() called ==================================
2024-07-04 15:11:07,131:INFO:Initializing create_model()
2024-07-04 15:11:07,131:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248F4D24CD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248F4D44610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:11:07,131:INFO:Checking exceptions
2024-07-04 15:11:07,131:INFO:Importing libraries
2024-07-04 15:11:07,131:INFO:Copying training dataset
2024-07-04 15:11:07,148:INFO:Defining folds
2024-07-04 15:11:07,148:INFO:Declaring metric variables
2024-07-04 15:11:07,148:INFO:Importing untrained model
2024-07-04 15:11:07,148:INFO:Light Gradient Boosting Machine Imported successfully
2024-07-04 15:11:07,148:INFO:Starting cross validation
2024-07-04 15:11:07,148:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:11:08,473:INFO:Calculating mean and std
2024-07-04 15:11:08,474:INFO:Creating metrics dataframe
2024-07-04 15:11:08,477:INFO:Uploading results into container
2024-07-04 15:11:08,477:INFO:Uploading model into container now
2024-07-04 15:11:08,478:INFO:_master_model_container: 13
2024-07-04 15:11:08,478:INFO:_display_container: 2
2024-07-04 15:11:08,479:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5295, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-07-04 15:11:08,479:INFO:create_model() successfully completed......................................
2024-07-04 15:11:08,646:INFO:SubProcess create_model() end ==================================
2024-07-04 15:11:08,646:INFO:Creating metrics dataframe
2024-07-04 15:11:08,665:INFO:Initializing Dummy Classifier
2024-07-04 15:11:08,665:INFO:Total runtime is 1.2801375031471252 minutes
2024-07-04 15:11:08,665:INFO:SubProcess create_model() called ==================================
2024-07-04 15:11:08,665:INFO:Initializing create_model()
2024-07-04 15:11:08,665:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248F4D24CD0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248F4D44610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:11:08,665:INFO:Checking exceptions
2024-07-04 15:11:08,665:INFO:Importing libraries
2024-07-04 15:11:08,665:INFO:Copying training dataset
2024-07-04 15:11:08,682:INFO:Defining folds
2024-07-04 15:11:08,682:INFO:Declaring metric variables
2024-07-04 15:11:08,682:INFO:Importing untrained model
2024-07-04 15:11:08,682:INFO:Dummy Classifier Imported successfully
2024-07-04 15:11:08,682:INFO:Starting cross validation
2024-07-04 15:11:08,694:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:11:09,358:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:11:09,362:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:11:09,380:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:11:09,441:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:11:09,535:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:11:09,607:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:11:09,680:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:11:09,720:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:11:09,900:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:11:09,937:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-07-04 15:11:09,957:INFO:Calculating mean and std
2024-07-04 15:11:09,957:INFO:Creating metrics dataframe
2024-07-04 15:11:09,964:INFO:Uploading results into container
2024-07-04 15:11:09,964:INFO:Uploading model into container now
2024-07-04 15:11:09,964:INFO:_master_model_container: 14
2024-07-04 15:11:09,964:INFO:_display_container: 2
2024-07-04 15:11:09,964:INFO:DummyClassifier(constant=None, random_state=5295, strategy='prior')
2024-07-04 15:11:09,964:INFO:create_model() successfully completed......................................
2024-07-04 15:11:10,162:INFO:SubProcess create_model() end ==================================
2024-07-04 15:11:10,162:INFO:Creating metrics dataframe
2024-07-04 15:11:10,180:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2024-07-04 15:11:10,180:INFO:Initializing create_model()
2024-07-04 15:11:10,180:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248F4D24CD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5295, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:11:10,180:INFO:Checking exceptions
2024-07-04 15:11:10,180:INFO:Importing libraries
2024-07-04 15:11:10,180:INFO:Copying training dataset
2024-07-04 15:11:10,193:INFO:Defining folds
2024-07-04 15:11:10,193:INFO:Declaring metric variables
2024-07-04 15:11:10,196:INFO:Importing untrained model
2024-07-04 15:11:10,196:INFO:Declaring custom model
2024-07-04 15:11:10,198:INFO:Logistic Regression Imported successfully
2024-07-04 15:11:10,213:INFO:Cross validation set to False
2024-07-04 15:11:10,213:INFO:Fitting Model
2024-07-04 15:11:10,346:INFO:[LightGBM] [Info] Number of positive: 384, number of negative: 384
2024-07-04 15:11:10,346:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.
2024-07-04 15:11:10,346:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-04 15:11:10,346:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-04 15:11:10,346:INFO:[LightGBM] [Info] Total Bins 814
2024-07-04 15:11:10,346:INFO:[LightGBM] [Info] Number of data points in the train set: 768, number of used features: 14
2024-07-04 15:11:10,346:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-07-04 15:11:10,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:10,414:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5295, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-04 15:11:10,414:INFO:create_model() successfully completed......................................
2024-07-04 15:11:10,612:INFO:_master_model_container: 14
2024-07-04 15:11:10,612:INFO:_display_container: 2
2024-07-04 15:11:10,612:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5295, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-04 15:11:10,612:INFO:compare_models() successfully completed......................................
2024-07-04 15:11:10,628:INFO:Initializing tune_model()
2024-07-04 15:11:10,628:INFO:tune_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248F4D24CD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5295, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=bayesian, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={})
2024-07-04 15:11:10,628:INFO:Checking exceptions
2024-07-04 15:11:10,628:INFO:Soft dependency imported: skopt: 0.10.2
2024-07-04 15:11:10,744:INFO:Copying training dataset
2024-07-04 15:11:10,749:INFO:Checking base model
2024-07-04 15:11:10,749:INFO:Base model : Logistic Regression
2024-07-04 15:11:10,750:INFO:Declaring metric variables
2024-07-04 15:11:10,750:INFO:Defining Hyperparameters
2024-07-04 15:11:11,070:INFO:Tuning with n_jobs=-1
2024-07-04 15:11:11,072:INFO:Initializing skopt.BayesSearchCV
2024-07-04 15:11:25,380:INFO:best_params: OrderedDict([('actual_estimator__C', 2.154059085821588), ('actual_estimator__class_weight', 'balanced')])
2024-07-04 15:11:25,380:INFO:Hyperparameter search completed
2024-07-04 15:11:25,380:INFO:SubProcess create_model() called ==================================
2024-07-04 15:11:25,380:INFO:Initializing create_model()
2024-07-04 15:11:25,380:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248F4D24CD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5295, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248F065C690>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'C': 2.154059085821588, 'class_weight': 'balanced'})
2024-07-04 15:11:25,393:INFO:Checking exceptions
2024-07-04 15:11:25,393:INFO:Importing libraries
2024-07-04 15:11:25,393:INFO:Copying training dataset
2024-07-04 15:11:25,395:INFO:Defining folds
2024-07-04 15:11:25,395:INFO:Declaring metric variables
2024-07-04 15:11:25,395:INFO:Importing untrained model
2024-07-04 15:11:25,395:INFO:Declaring custom model
2024-07-04 15:11:25,395:INFO:Logistic Regression Imported successfully
2024-07-04 15:11:25,395:INFO:Starting cross validation
2024-07-04 15:11:25,414:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:11:26,845:INFO:Calculating mean and std
2024-07-04 15:11:26,846:INFO:Creating metrics dataframe
2024-07-04 15:11:26,846:INFO:Finalizing model
2024-07-04 15:11:27,111:INFO:[LightGBM] [Info] Number of positive: 384, number of negative: 384
2024-07-04 15:11:27,111:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.
2024-07-04 15:11:27,111:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-07-04 15:11:27,111:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-07-04 15:11:27,111:INFO:[LightGBM] [Info] Total Bins 814
2024-07-04 15:11:27,111:INFO:[LightGBM] [Info] Number of data points in the train set: 768, number of used features: 14
2024-07-04 15:11:27,111:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-07-04 15:11:27,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:27,178:INFO:Uploading results into container
2024-07-04 15:11:27,191:INFO:Uploading model into container now
2024-07-04 15:11:27,192:INFO:_master_model_container: 15
2024-07-04 15:11:27,192:INFO:_display_container: 3
2024-07-04 15:11:27,192:INFO:LogisticRegression(C=2.154059085821588, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5295, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-04 15:11:27,192:INFO:create_model() successfully completed......................................
2024-07-04 15:11:27,408:INFO:SubProcess create_model() end ==================================
2024-07-04 15:11:27,408:INFO:choose_better activated
2024-07-04 15:11:27,408:INFO:SubProcess create_model() called ==================================
2024-07-04 15:11:27,408:INFO:Initializing create_model()
2024-07-04 15:11:27,408:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248F4D24CD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5295, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-07-04 15:11:27,408:INFO:Checking exceptions
2024-07-04 15:11:27,408:INFO:Importing libraries
2024-07-04 15:11:27,408:INFO:Copying training dataset
2024-07-04 15:11:27,422:INFO:Defining folds
2024-07-04 15:11:27,422:INFO:Declaring metric variables
2024-07-04 15:11:27,422:INFO:Importing untrained model
2024-07-04 15:11:27,422:INFO:Declaring custom model
2024-07-04 15:11:27,422:INFO:Logistic Regression Imported successfully
2024-07-04 15:11:27,426:INFO:Starting cross validation
2024-07-04 15:11:27,438:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-07-04 15:11:28,800:INFO:Calculating mean and std
2024-07-04 15:11:28,800:INFO:Creating metrics dataframe
2024-07-04 15:11:28,805:INFO:Finalizing model
2024-07-04 15:11:29,058:INFO:[LightGBM] [Info] Number of positive: 384, number of negative: 384
2024-07-04 15:11:29,058:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000495 seconds.
2024-07-04 15:11:29,058:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-07-04 15:11:29,058:INFO:[LightGBM] [Info] Total Bins 814
2024-07-04 15:11:29,058:INFO:[LightGBM] [Info] Number of data points in the train set: 768, number of used features: 14
2024-07-04 15:11:29,058:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
2024-07-04 15:11:29,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-07-04 15:11:29,126:INFO:Uploading results into container
2024-07-04 15:11:29,128:INFO:Uploading model into container now
2024-07-04 15:11:29,129:INFO:_master_model_container: 16
2024-07-04 15:11:29,129:INFO:_display_container: 4
2024-07-04 15:11:29,129:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5295, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-04 15:11:29,131:INFO:create_model() successfully completed......................................
2024-07-04 15:11:29,341:INFO:SubProcess create_model() end ==================================
2024-07-04 15:11:29,341:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5295, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 1.0
2024-07-04 15:11:29,341:INFO:LogisticRegression(C=2.154059085821588, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5295, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 1.0
2024-07-04 15:11:29,341:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5295, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2024-07-04 15:11:29,341:INFO:choose_better completed
2024-07-04 15:11:29,341:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-07-04 15:11:29,372:INFO:_master_model_container: 16
2024-07-04 15:11:29,372:INFO:_display_container: 3
2024-07-04 15:11:29,375:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5295, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-07-04 15:11:29,375:INFO:tune_model() successfully completed......................................
2024-07-04 15:11:29,584:INFO:Initializing plot_model()
2024-07-04 15:11:29,585:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248F4D24CD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5295, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=class_report, scale=0.75, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2024-07-04 15:11:29,585:INFO:Checking exceptions
2024-07-04 15:11:29,585:INFO:Soft dependency imported: streamlit: 1.36.0
2024-07-04 15:11:29,592:INFO:Preloading libraries
2024-07-04 15:11:29,592:INFO:Copying training dataset
2024-07-04 15:11:29,592:INFO:Plot type: class_report
2024-07-04 15:11:29,923:INFO:Fitting Model
2024-07-04 15:11:29,939:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2024-07-04 15:11:29,940:INFO:Scoring test/hold-out set
2024-07-04 15:11:30,722:INFO:Visual Rendered Successfully
2024-07-04 15:11:30,933:INFO:plot_model() successfully completed......................................
2024-07-04 15:11:30,933:INFO:Initializing plot_model()
2024-07-04 15:11:30,938:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248F4D24CD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5295, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=confusion_matrix, scale=0.75, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2024-07-04 15:11:30,938:INFO:Checking exceptions
2024-07-04 15:11:30,938:INFO:Soft dependency imported: streamlit: 1.36.0
2024-07-04 15:11:30,946:INFO:Preloading libraries
2024-07-04 15:11:30,947:INFO:Copying training dataset
2024-07-04 15:11:30,947:INFO:Plot type: confusion_matrix
2024-07-04 15:11:31,249:INFO:Fitting Model
2024-07-04 15:11:31,249:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2024-07-04 15:11:31,249:INFO:Scoring test/hold-out set
2024-07-04 15:11:31,807:INFO:Visual Rendered Successfully
2024-07-04 15:11:32,002:INFO:plot_model() successfully completed......................................
2024-07-04 15:11:32,003:INFO:Initializing plot_model()
2024-07-04 15:11:32,004:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248F4D24CD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5295, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=auc, scale=0.75, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2024-07-04 15:11:32,004:INFO:Checking exceptions
2024-07-04 15:11:32,005:INFO:Soft dependency imported: streamlit: 1.36.0
2024-07-04 15:11:32,010:INFO:Preloading libraries
2024-07-04 15:11:32,010:INFO:Copying training dataset
2024-07-04 15:11:32,011:INFO:Plot type: auc
2024-07-04 15:11:32,264:INFO:Fitting Model
2024-07-04 15:11:32,265:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2024-07-04 15:11:32,266:INFO:Scoring test/hold-out set
2024-07-04 15:11:32,836:INFO:Visual Rendered Successfully
2024-07-04 15:11:33,020:INFO:plot_model() successfully completed......................................
2024-07-04 15:11:33,025:INFO:Initializing predict_model()
2024-07-04 15:11:33,025:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248F4D24CD0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5295, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000248F076FBA0>)
2024-07-04 15:11:33,025:INFO:Checking exceptions
2024-07-04 15:11:33,025:INFO:Preloading libraries
2024-07-04 15:11:33,558:INFO:Initializing save_model()
2024-07-04 15:11:33,558:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5295, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=best_class_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\PHYOSA~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Survived_x',
                                             'Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='median'...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=None,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=2,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-07-04 15:11:33,563:INFO:Adding model into prep_pipe
2024-07-04 15:11:33,621:INFO:best_class_model.pkl saved in current working directory
2024-07-04 15:11:33,702:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Survived_x',
                                             'Pclass', 'Age', 'SibSp', 'Parch',
                                             'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='median'))),
                ('categorical_imputer',
                 TransformerWrapp...
                                                                importance_getter='auto',
                                                                max_features=2,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=5295,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-07-04 15:11:33,703:INFO:save_model() successfully completed......................................
2024-07-04 15:11:43,144:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x00000248D5E5A550, file "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 164>')
  warnings.warn(

2024-07-04 15:12:10,575:WARNING:C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x00000248D5E5A550, file "C:\Users\Phyo Sandar Win\AppData\Roaming\Python\Python311\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 164>')
  warnings.warn(

2024-07-04 15:17:16,378:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 15:17:16,378:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 15:17:16,378:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-07-04 15:17:16,378:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
